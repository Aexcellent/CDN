High-Throughput Semi-Honest Secure Three-Party Computation with an Honest Majority

Toshinori Araki
NEC Corporation, Japan
t-araki@ek.jp.nec.com

Jun Furukawa
NEC Corporation, Japan
j-furukawa@ay.jp.nec.com

Yehuda Lindell∗
Bar-Ilan University, Israel
lindell@biu.ac.il

Ariel Nof∗
Bar-Ilan University, Israel
nofdinar@gmail.com

Kazuma Ohara
NEC Corporation, Japan
k-ohara@ax.jp.nec.com

ABSTRACT
In this paper, we describe a new information-theoretic protocol (and a computationally-secure variant) for secure threeparty computation with an honest majority. The protocol has very minimal computation and communication; for Boolean circuits, each party sends only a single bit for every AND gate (and nothing is sent for XOR gates). Our protocol is (simulation-based) secure in the presence of semi-honest adversaries, and achieves privacy in the client/server model in the presence of malicious adversaries.
On a cluster of three 20-core servers with a 10Gbps connection, the implementation of our protocol carries out over 1.3 million AES computations per second, which involves processing over 7 billion gates per second. In addition, we developed a Kerberos extension that replaces the ticketgranting-ticket encryption on the Key Distribution Center (KDC) in MIT-Kerberos with our protocol, using keys/ passwords that are shared between the servers. This enables the use of Kerberos while protecting passwords. Our implementation is able to support a login storm of over 35,000 logins per second, which suﬃces even for very large organizations. Our work demonstrates that high-throughput secure computation is possible on standard hardware.
1. INTRODUCTION
1.1 Background
In the setting of secure computation, a set of parties with private inputs wish to compute a joint function of their inputs, without revealing anything but the output. Protocols for secure computation guarantee privacy (meaning
∗Supported by the European Research Council under the ERC consolidators grant agreement n. 615172 (HIPS) and by the BIU Center for Research in Applied Cryptography and Cyber Security in conjunction with the Israel National Cyber Bureau in the Prime Minister’s Oﬃce.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from Permissions@acm.org. CCS’16, October 24-28, 2016, Vienna, Austria
c 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00 DOI: http://dx.doi.org/10.1145/2976749.2978331

that the protocol reveals nothing but the output), correctness (meaning that the correct function is computed), and more. These security guarantees are to be provided in the presence of adversarial behavior. There are two classic adversary models that are typically considered: semi-honest (where the adversary follows the protocol speciﬁcation but may try to learn more than allowed from the protocol transcript) and malicious (where the adversary can run any arbitrary polynomial-time attack strategy). In the informationtheoretic model, security is obtained unconditionally and even in the presence of computationally unbounded adversaries. In contrast, in the computational model, security is obtained in the presence of polynomial-time adversaries and relies on cryptographic hardness assumptions.
Despite its stringent requirements, it has been shown that any polynomial-time functionality can be securely computed with computational security [25, 12, 3] and with informationtheoretic security [2, 8]. These results hold both for semihonest and malicious adversaries, but an honest majority must be assumed in order to obtain information-theoretic security even for semi-honest adversaries. There are two main approaches to secure computation protocols: the secret- sharing approach (followed by [2, 8, 12]) works by having the parties interact for every gate of the circuit, whereas the garbled-circuit approach (followed by [25, 3]) works by having the parties construct an encrypted version of the circuit which can be computed at once. Both approaches have importance and have settings where they perform better than the other. On the one hand, the garbled-circuit approach yields protocols with a constant number of rounds. Thus, in high-latency networks, they far outperform secret-sharing based protocols which have a number of rounds linear in the depth of the circuit being computed. On the other hand, protocols based on secret-sharing typically have low bandwidth and send small messages per gate, in contrast to garbled circuits that are large and costly in bandwidth. This limits the potential throughput of protocols following the garbled-circuit approach, even when run in very low-latency networks. Note that information-theoretic protocols typically rely on simple operations making them fast (but no constant-round protocol for this setting is known to exist and this is conjectured to be hard if not impossible [14]).
Another question determining the type of protocol to use is whether or not high throughput or low latency is the goal. If low latency is needed (and the circuit being computed is deep), then constant-round protocols like [25] outperform secret-sharing based protocols, even on very fast networks.

However, these same protocols fail to achieve high thoughput due to the large bandwidth incurred.
Due to this situation, it is important to develop protocols for low and high latency networks, with better response time and/or throughput.
1.2 Our Results
In this paper, we focus on the question of achieving secure computation with very high throughput on a fast network (without utilizing special-purpose hardware beyond the widespread Intel AES-NI and AVX instruction sets). The challenge in achieving this is both on the computational and network levels. Speciﬁcally, a protocol achieving very high throughput would need to both be very simple computationally and also utilize very little bandwidth. Achieving both of these tasks is challenging. The BGW protocol [2] for semi-honest adversaries requires each party to send 3 ﬁeld elements to each other party per multiplication gate (this translates to each party sending 12 bits per AND gate), whereas the Sharemind protocol [4, 5] (in its latest optimized version [16]) requires each party to send 5 bits per AND gate.1
A new protocol. We describe a new three-party protocol that is both extremely simple and has seemingly optimal bandwidth. Our protocol is suitable for arithmetic circuits over any ﬁeld or over the ring modulo 2n. Addition gates require local addition only, and multiplication gates require that each party send just a single ﬁeld/ring element to one other party. In the Boolean case, this means that each party transmits a single bit only per AND gate.2 Furthermore, the computation in our protocol is extraordinarily simple: in the case of Boolean circuits, each party carries out a single XOR operation per XOR gate, and 2 AND and 3 XOR operations per AND gate. Since all operations are merely XOR and AND, this also lends itself to parallelization on standard computers (in particular, XOR and AND over 128 bit registers can be carried out in the same time as for a single bit using Intel intrinsics).
Security. We prove that our protocol is secure in the presence of semi-honest adversaries with at most one corrupted party, under the standard simulation-based deﬁnitions. The basis of our protocol is information theoretic (and in fact perfectly secure). However, we save on communication by generating correlated randomness computationally, and therefore our overall protocol is computationally secure. (This combination enables us to achieve simple operations and save on additional bandwidth.) In addition to the above, we also consider a client/server model where any number of clients send shares of their inputs to 3 servers that carry out the computation for the clients and return the results to them (without learning anything). This model makes sense for “outsources secure computation services” and indeed is the business model of Cybernetica. We show that in this model, our protocol actually achieves privacy in the presence of malicious adversaries, meaning that a single malicious server cannot learn anything about the input or output. (We stress that this notion is strictly weaker than simulation-based security in the presence of malicious ad-
1In [16], they also describe a method whereby each party sends only 2 bits per AND gate. However, according to [16] this is slower in many cases due to the higher computational cost. 2This is “seemingly” optimal in terms of bandwidth, but this has not been proven and seems hard to do so; see [14].

versaries, and in particular, does not guarantee correctness. Nevertheless, it does guarantee that privacy is not breached even if one of the servers behaves maliciously.)
Number of parties. As in Sharemind [4, 5], our protocol is speciﬁcally designed for 3 parties with at most one corrupted. This is unlike BGW [2] that works for any number of parties with an honest majority. An important open question left by this paper is the design of a protocol with comparable complexity that works for any number of parties. This seems to be very challenging, based on attempts that we have made to extend our protocol.
Experimental results. We implemented our new protocol for Boolean circuits in C++ and using standard optimizations. In order to take advantage of the very simple operations required in our protocol, we used Intel intrinsics in order to carry out many executions in parallel. This is described in detail in Section 5.1. We ran our experiments on a cluster of three nodes, each with two 10-core Intel Xeon (E5-2650 v3) processors and 128GB RAM, connected via a 10Gbps Ethernet. (We remark that little RAM was utilized and thus this is not a parameter of importance here.) We carried out two main experiments, both based on securely computing the AES circuit on shared keys.
First, we computed AES in counter mode, with the aim of obtaining maximal throughput. Using the full power of the cluster (all cores), we computed over 1.3 million AES operations per second. Furthermore, utilizing a single core we achieved 100,000 AES operations per second, and utilizing 10 cores we achieved amost 1 million AES operations per second. As we will show below in Section 1.3, this way outperforms all previous protocols of this type.
Second, we wished to demonstrate that this type of protocol can be incorporated into a real system. We chose to integrate our protocol into a Kerberos KDC in order to carry out Ticket-Granting-Ticket encryption without any single server holding the encryption key (whether it be a server’s key or user’s hashed password). Such an architecture protects against administrators stealing passwords, or an attacker who breaches the network being able to steal all users’ passwords. (We stress that in Kerberos, the raw password is never used so once the hashed password is stolen the attacker can impersonate the user.) We obtained a latency of 110ms on the server and 232ms on the client (over a LAN) for the entire Kerberos login (excluding database lookup). Given that this is for the purpose of user authentication, this is well within the acceptable range. In addition, we are able to support a login storm of over 35,000 user authentications per second, which is suﬃcient even for very large organizations.
Our results demonstrate that secure computation can be used to solve large-scale problems in practice (at least, for the cases that semi-honest security or privacy for a malicious adversary suﬃces).
1.3 Related Work
We compare our results with previously reported results on secure AES computation for 3 parties with an honest majority and semi-honest adversaries; see Table 1.
We stress that this table gives only very partial information since diﬀerent hardware was used for each; we provide it to show the progress made and where we ﬁt into it. However, the setup used by us is almost the same as that of the latest Sharemind results in [22]. Nevertheless, to the best

of our understanding, although the latest Sharemind results use optimized code that was completely rewritten, it was not written to utilize the full parallelism available on their system. It is unclear what rates Sharemind would achieve, since it has higher bandwidth, as described above, as well as higher computational cost.

Year 2010 2012 2013 2016 2016 2016

Ref. [10] [18] [19] [23, Table 5.3] [22] this work

Latency 2000s
14.28ms 323ms 223ms
166ms

Throughput -
320 3450 25,000 90,000 1,324,117

Table 1: Reported times for semi-honest 3-party computation & honest majority; the throughput is measured in AES computations per second (the last two rows with similar conﬁgurations).

We remark that other work on garbled circuits (e.g., twoparty Yao with semi-honest adversaries) achieves much lower latency (e.g., 16ms reported in [13]). However, each garbled AES circuit is of size at least 1.3Mb (using the latest halfgates optimization [26]), not taking into account additional messages that are sent. It is therefore physically impossible to go beyond 7500 AES computations per second on a 10Gbps network (where we achieve 1.4 million). In addition, the two-party GMW approach using eﬃcient oblivious transfer (OT) extensions is blocked by the speed of the OTs (with two OTs required per gate). Considering the communication bottleneck, each OT requires transmitting a minimum of 128 bits. Thus, the communication is approximately the same as with a garbled circuit. (The fastest known implementation [15] can process 5 million OTs per second on a 1Gbps network giving under 500 AES computations per second. This is not far from optimal assuming linear scale-up on a 10Gbps network.) Of course, we require an additional server, in contrast to the Yao and GMW protocols.
2. THE NEW PROTOCOL
In this section, we describe our new protocol for three parties. Our protocol works for arithmetic circuits over the ring modulo 2n with Boolean circuits being a special case (with n = 1). The protocol uses only very simple ring addition and multiplication operations, which in the Boolean case reduces simply to bitwise AND and XOR. In addition, the protocol has very low communication: a single ring element is sent per multiplication gate and there is no communication for addition gates. In the Boolean case, we therefore have that the only communication is a single bit per AND gate.
Correlated randomness. Our protocol assumes that for every multiplication gate the three parties P1, P2, P3 are given correlated randomness in the form of random ring elements x1, x2, x3 under the constraint that x1 + x2 + x3 = 0. We show how this can be achieved in practice with great eﬃciency using AES. (Thus, our protocol is informationtheoretically secure with perfect correlated randomness, but the actual implementation is computationally secure due to the use of AES to generate the correlated randomness.)
2.1 Securely Computing Boolean Circuits
In order to simplify the exposition, we begin by describing the protocol for the special case of Boolean circuits with

AND and XOR gates. We assume that the parties P1, P2, P3 are able to obtain random x1, x2, x3 ∈ {0, 1} such that x1 ⊕ x2 ⊕ x3 = 0.

Secret sharing. We deﬁne a 2-out-of-3 secret sharing

scheme, denoted

3 2

-sharing,

as

follows.

In

order

to

share

a

bit v, the dealer chooses three random bits x1, x2, x3 ∈ {0, 1}

under the constraint that x1 ⊕ x2 ⊕ x3 = 0. Then:

• P1’s share is the pair (x1, a1) where a1 = x3 ⊕ v.

• P2’s share is the pair (x2, a2) where a2 = x1 ⊕ v.

• P3’s share is the pair (x3, a3) and a3 = x2 ⊕ v.

It is clear that no single party’s share reveals anything about

v. In addition, any two shares suﬃce to obtain v; e.g., given

x1, x2, a1, a2 we can compute v = a2 ⊕ x1.

XOR (addition) gates. Let (x1, a1), (x2, a2), (x3, a3) be

a secret sharing of v1, and let (y1, b1), (y2, b2), (y3, b3) be a

secret sharing of v2. Then, in order to compute a secret

sharing of v1 ⊕ v2, each Pi locally computes (zi, ci) with

zi = xi ⊕ yi and ci = ai ⊕ bi (no communication is needed).

In order to see that the result constitutes a valid

3 2

-

sharing of v1 ⊕ v2, observe ﬁrst that z1 ⊕ z2 ⊕ z3 = 0 (since

both x1 ⊕ x2 ⊕ x3 = 0 and y1 ⊕ y2 ⊕ y3 = 0). Next, observe

that for every i ∈ {1, 2, 3} it holds that ci = zi−1 ⊕ (v1 ⊕ v2)

where i−1 = 3 when i = 1; e.g., we have c1 = a1 ⊕b1 = x3 ⊕

v1 ⊕y3 ⊕v2 = (x3 ⊕y3)⊕(v1 ⊕v2) = z3 ⊕(v1 ⊕v2). Thus, this

constitutes a sharing of v1 ⊕ v2 with randomness z1, z2, z3.

AND (multiplication) gates. We now show how the par-

ties can compute AND (equivalently, multiplication) gates;

this subprotocol requires each party to send a single bit only.

The protocol works in two phases: in the ﬁrst phase the par-

ties compute a simple

3 3

XOR-sharing of the AND of the

input bits, and in the second phase they convert the

3 3

-

sharing into the above-deﬁned

3 2

-sharing.

Let (x1, a1), (x2, a2), (x3, a3) be a secret sharing of v1, and

let (y1, b1), (y2, b2), (y3, b3) be a secret sharing of v2. We as-

sume that the parties P1, P2, P3 hold correlated randomness

α, β, γ, respectively, where α ⊕ β ⊕ γ = 0. The parties com-

pute

3 2

-shares

of

v1 · v2

=

v1 ∧ v2

as

follows

(from

here

on,

we will denote multiplication of a and b by simply ab):

1. Step 1 – compute

3 3

-sharing:

(a) P1 computes r1 = x1y1⊕a1b1⊕α, and sends r1 to P2.

(b) P2 computes r2 = x2y2⊕a2b2⊕β, and sends r2 to P3.

(c) P3 computes r3 = x3y3⊕a3b3⊕γ, and sends r3 to P1.

These messages are computed and sent in parallel.

2. Step 2 – compute

3 2

-sharing:

In this step, the parties

construct a

3 2

-sharing

from

their

given

3 3

-sharing

and

the messages sent in the previous step. This requires local

computation only.

(a) P1 stores (z1, c1) where z1 = r1 ⊕ r3 and c1 = r1. (b) P2 stores (z2, c2) where z2 = r2 ⊕ r1 and c2 = r2. (c) P3 stores (z3, c3) where z3 = r3 ⊕ r2 and c3 = r3.

Explanation of Step 1: We now show that r1, r2, r3 de-

ﬁned in Step 1 are indeed a

3 3

sharing of v1v2, meaning

that r1 ⊕ r2 ⊕ r3 = v1 ∧ v2. Observe ﬁrst that:

a1b1 = (x3 ⊕ v1)(y3 ⊕ v2) = x3y3 ⊕ x3v2 ⊕ y3v1 ⊕ v1v2 (1)

and similarly a2b2 = x1y1 ⊕ x1v2 ⊕ y1v1 ⊕ v1v2, and a3b3 = x2y2 ⊕ x2v2 ⊕ y2v1 ⊕ v1v2. Thus,
r1 ⊕ r2 ⊕ r3 = (x1y1 ⊕ a1b1 ⊕ α) ⊕ (x2y2 ⊕ a2b2 ⊕ β) ⊕ (x3y3 ⊕ a3b3 ⊕ γ) = x1y1 ⊕ x2y2 ⊕ x3y3 ⊕ a1b1 ⊕ a2b2 ⊕ a3b3 = x1y1 ⊕ x2y2 ⊕ x3y3 ⊕ (x3y3 ⊕ x3v2 ⊕ y3v1 ⊕ v1v2) ⊕ (x1y1 ⊕ x1v2 ⊕ y1v1 ⊕ v1v2) ⊕ (x2y2 ⊕ x2v2 ⊕ y2v1 ⊕ v1v2) = (x1 ⊕ x2 ⊕ x3)v2 ⊕ (y1 ⊕ y2 ⊕ y3)v1 ⊕ v1v2 = v1v2

where the second equality is because α⊕β ⊕γ = 0, the third equality is from the equivalences of a1b1, a2b2, a3b3 above (see Eq. (1)), the fourth equality is by cancelling repeated values and rearranging the remainder, and the last equality is because x1 ⊕ x2 ⊕ x3 = y1 ⊕ y2 ⊕ y3 = 0.

Explanation of Step 2: In order to show that the result

is a valid

3 2

-sharing

of

v1v2

according

to

our

deﬁnition,

we

need to show that z1, z2, z3 are such that z1 ⊕ z2 ⊕ z3 = 0,

and that c1, c2, c3 are of the deﬁned form.

First, z1 ⊕ z2 ⊕ z3 = (r1 ⊕ r3) ⊕ (r2 ⊕ r1) ⊕ (r3 ⊕ r2) = 0.

Second, observe that since c1 ⊕ c2 ⊕ c3 = r1 ⊕ r2 ⊕ r3 = v1v2

(as shown above), it holds that c1 = r1 = v1v2 ⊕ r2 ⊕ r3.

However, r2 ⊕ r3 = z3 (by the protocol deﬁnition) and thus

c1 = v1v2 ⊕ z3, as required. A similar calculation shows the

equality for c2 and c3 as well.

The above explanation shows that the gate computation “works” in the sense that the invariant of the format of the shares is preserved after every gate is computed. The fact that the protocol is secure is proved later in Section 3.
The protocol. The full 3-party protocol works in the natural way. The parties ﬁrst share their inputs using the secret sharing method. They then compute each XOR and AND gate in the circuit according to a predetermined topological ordering fo the circuit. Finally, the parties reconstruct their output on the output wires. (In the client/server model, external clients send the three parties sharings of their input according, and the three parties then compute the circuit in the same way on the shares received.)
Observe that each party communicates with exactly one other party only. This property also holds for the protocol of Sharemind [4, 5]. However, our secret-sharing scheme and multiplication protocol are completely diﬀerent.

2.2 Generating Correlated Randomness
Our protocol relies on the fact that the parties hold random bits α, β, γ ∈ {0, 1} such that α ⊕ β ⊕ γ = 0 for every AND gate. In this section, we show how the parties can eﬃciently generate such α, β, γ.
Information-theoretic correlated randomness. It is possible to securely generate correlated randomness with perfect security by having each party Pi simply choose a random ρi ∈ {0, 1} and send it to Pi+1 (where P3 sends to P1). Then, each party takes its random bit to be the XOR of the bit it chose and the bit it received: P1 computes α = ρ3 ⊕ ρ1, P2 computes β = ρ1 ⊕ ρ2 and γ = ρ2 ⊕ ρ3. Observe that α + β + γ = 0 as required. In addition, if P1 is corrupted, then it knows nothing about β and γ except that β ⊕ γ = α. This is because β and γ both include ρ2 in their computation and this is unknown to P1. A similar argument holds for a corrupted P2 or P3. Despite the elegance and simplicity of this solution, we use a diﬀerent approach.

This is due to the fact that this would double the communication per AND gate; it is true that this is still very little communication. However, given that communication is the bottleneck, it would halve the throughput.
Computational correlated randomness. We now show how it is possible to securely compute correlated randomness computationally without any interaction beyond a short initial setup. This enables us to maintain the current situation where parties need only transmit a single bit per AND gate. This method is similar to that of the PRSS subprotocol in [9], but simpler since Shamir sharing is not needed. Let κ be the security parameter, and let F : {0, 1}κ × {0, 1}κ → {0, 1} be a pseudorandom function outputting a single bit.

1. Init:
(a) Each Pi chooses a random ki ∈ {0, 1}κ. (b) Party P1 sends k1 to P3, party P2 sends k2 to P1
and party P3 sends k3 to P2.

P1 holds k1, k2, P2 holds k2, k3 and P3 holds k3, k1. 2. GetNextBit: Given a unique identiﬁer id ∈ {0, 1}κ,

(a) P1 computes α = Fk1 (id) ⊕ Fk2 (id). (b) P2 computes β = Fk2 (id) ⊕ Fk3 (id). (c) P3 computes γ = Fk3 (id) ⊕ Fk1 (id).

Observe that α ⊕ β ⊕ γ = 0. Furthermore, P1 does not know k3 which is used to generate β and γ. Thus, β and γ are pseudorandom to P1, under the constraint that β ⊕ γ = α. In practice, the id can be a counter that all parties locally increment at every call to GetNextBit.

2.3 The Ring Modulo 2n and Fields

Our protocol above works for Boolean circuits. However,

in some cases arithmetic circuits are far more eﬃcient. In

this section, we show how to generalize the protocol above to the general case of the ring modulo 2n and arbitrary ﬁelds

of size greater than 2. We describe the protocol for the ring modulo 2n; it is clear that everything holds for arbitrary ﬁnite ﬁelds and rings in which 3−1 exists. (The only thing

that is needed is to be able to divide by 3 which is deﬁned by

adding the unity to itself 3 times. This is possible in the ring modulo 2n since gcd(3, 2n) = 1, and is always possible in a ﬁeld.) From here-on in this section, all arithmetic is mod2n.

We remark that when taking n = 1 we have that addition

(and subtraction) is the same as XOR, and multiplication is

the same as AND. In this case, the protocol here is exactly

that described in Section 2.1.

3 2

-secret

sharing.

In order to share an element v mod 2n

the dealer chooses three random elements x1, x2, x3 ∈ Z2n

under the constraint that x1 + x2 + x3 = 0. Then, P1’s share

is (x1, a1) where a1 = x3 − v, P2’s share is (x2, a2) where

a2 = x1 −v, and P3’s share is (x3, a3), where a3 = x2 −v. As

in the Boolean case, it is easy to see that each share reveals

nothing of v, and that any two shares suﬃce to reconstruct v.

We now show that each party’s share reveals nothing about

the secret. For simplicity, we show this for P1 (all others are shown in a similar way). Party P1’s share consists of the pair (a1, x1) where a1 = x3 − v. Since x1, x2, x3 are random under the constraint that x1 + x2 + x3 = 0, this is equivalent to x1 and x3 being chosen independently at random and then x2 being chosen to equal −x1 − x3. In this light, a1 in

P1’s share is a one-time pad encryption of v using random key x3, and x1 is an independent random value. Thus, P1’s share reveals nothing about v whatsoever. This implies:

Lemma 2.1. For any two values va, vb ∈ Z2n and any i ∈ {1, 2, 3}, the distribution over Pi’s share (xi, ai) of va is identical to the distribution over Pi’s share (yi, bi) of vb.

Addition gates. As in the Boolean case, addition gates are computed by locally adding the shares modulo 2n.

Multiplication gates: Let (x1, a1), (x2, a2), (x3, a3) be a

secret sharing of v1, and let (y1, b1), (y2, b2), (y3, b3) be a

secret sharing of v2, and assume the parties P1, P2, P3 hold

α, β, γ ∈ Z2n respectively, such that α + β + γ = 0. In order

to compute a

3 2

-sharing

of

the

product

of

two

values,

the

parties work as above with the following diﬀerences:

1.

P1

computes

r1

=

a1 b1 −x1 y1 +α 3

and

sends

r1

to

P2.

2.

P2

computes

r2

=

a2 b2 −x2 y2 +β 3

and

sends

r2

to

P3.

3.

P3

computes

r3

=

a3 b3 −x3 y3 +γ 3

and

sends

r3

to

P1.

4. P1 deﬁnes its share as z1 = r3 − r1 and c1 = −2r3 − r1.

5. P2 deﬁnes its share as z2 = r1 − r2 and c2 = −2r1 − r2.

6. P3 deﬁnes its share as z3 = r2 − r3 and c3 = −2r2 − r3.

We remark that the above computation is legal since 3 is relatively prime to 2n; thus 3 has an inverse. In addition,
the above all holds in ﬁnite ﬁelds with more than 3 elements.
In order to see that r1 + r2 + r3 = v1v2, ﬁrst observe that

a1b1 = (x3 − v1)(y3 − v2) = x3y3 − x3v2 − y3v1 + v1v2 (2)

and likewise a2b2 = x1y1 − x1v2 − y1v1 + v1v2 and a3b3 = x2y2 − x2v2 − y2v1 + v1v2. Then,

3(r1 + r2 + r3) = a1b1 − x1y1 + α + a2b2 − x2y2 + β + a3b3 − x3y3 + γ = a1b1 + a2b2 + a3b3 − x1y1 − x2y2 − x3y3 = 3v1v2 − v1(y1 + y2 + y3) − v2(x1 + x2 + x3) = 3v1v2

where the second equality holds since α + β + γ = 0 and

the third equality follows by plugging in the equivalences

of a1b1, a2b2, a3b3 above (see Eq. (2)) and rearranging the

elements, and the fourth equality follows from the fact that

x1 + x2 + x3 = y1 + y2 + y3 = 0. Since we can divide by 3 in

this ring (and in a ﬁeld) we have that r1 + r2 + r3 = v1v2.

Next, we show that the shares the parties hold are a valid

3 2

-sharing

of

v1v2

according

to

our

deﬁnition.

i.e,

that

the

shares are (z1, z3 − v1v2), (z2, z1 − v1v2) and (z3, z2 − v1v2)

such that z1 + z2 + z3 = 0 mod 2n. First, observe that the

sum of the ﬁrst elements of the shares is z1 + z2 + z3 = (r3 −

r1) + (r1 − r2) + (r2 − r3) = 0 as required. Second, for party

P1 it holds that, c1 = −2r3 − r1 = −r3 − r3 − r1 − r2 + r2 =

(r2 − r3) − (r1 + r2 + r3) = z3 − v1v2 as required (recall that

z3 = r2 − r3 in the protocol). Correctness for P2 and P3

follows similarly.

In the proof of security, we show that the secret is per-

fectly hidden by the resulting secret sharing. This hiding

follows from the use of the correlated randomness in the

computation. In particular, the random values α, β, γ that

the parties add in the local computation perfectly mask the

value on the wire.

Generating correlated randomness. The parties use the same (computational) method as described in Section 2.2, with the following diﬀerences. First, we assume that Fk is a pseudorandom function mapping strings into Z2n (or equivalently to {0, 1}n). Second, party P1 computes α = Fk1 (id) − Fk2 (id), party P2 computes β = Fk2 (id) − Fk3 (id), and party P3 computes γ = Fk3 (id) − Fk1 (id).
2.4 Protocol Efﬁciency and Comparison
In the case of arbitrary ﬁnite ﬁelds, Shamir’s secret-sharing [24] is “ideal”, meaning that the size of the share equals the size of the secret (which is minimum size), as long as the number of parties is less than the size of the ﬁeld. In our protocol, the secret sharing scheme is not ideal since it consists of two ring or ﬁeld elements instead of a single ﬁeld element. However, this is of little consequence when considering the eﬃciency of the protocol since our protocol requires only sending a single element per multiplication gate. In addition, the computation consists merely of two multiplications and two additions.
In comparison, the BGW protocol [2, 1] requires transmitting two ﬁeld elements per multiplication gate by each party when using [21] method (with a single round of communication). In addition, when considering Boolean circuits, at least two bits are needed per ﬁeld element, since there are 3 parties. Furthermore, the computation requires polynomial evaluations which are far more expensive.
In the Sharemind protocol [4, 5], the parties transmit ﬁve bits per AND gate over two communication rounds, and compute 3 multiplications and 8 additions. As noted in [16], Sharemind can use a similar method to ours for noninteractively generating correlated randomness in order to reduce the number of bits sent in the Sharemind protocol from 5 to 2 and to reduce the number of communication rounds to 1. However, they need to generate three times the amount of correlated randomness, and their experiments show that this can therefore actually be slower [16].
3. SECURITY FOR SEMI-HONEST ADVERSARIES
In this section, we prove that our protocol is secure in the presence of one semi-honest adversarial party (in Section 4 we prove that the protocol is private in the presence of one malicious adversary). Semi-honest security is suﬃcient when parties somewhat trust each other, but are concerned with inadvertent leakage or cannot share their raw information due to privacy regulations. It is also suﬃcient in cases where it is reasonable to assume that the parties running the protocol are unable to replace the installed code. Nevertheless, security against covert or malicious adversaries is preferable, providing far higher guarantees; we leave extensions of our protocol to these settings for future work.
Since the protocol for Boolean circuits is a special case of the protocol for the ring modulo 2n, we prove the security for the case of the ring modulo 2n. The proof is identical in the case of ﬁelds with more than 3 elements. Throughout, in order to simplify notation, when we use an index (say, i) to denote the ith party (with i ∈ {1, 2, 3}), we will write i − 1 and i + 1 to mean the “previous” and “subsequent” party, respectively. That is, when i = 1 then i − 1 = 3 and when i = 3 then i + 1 = 1.

3.1 Preliminaries
We use the deﬁnition of security in the presence of semihonest adversaries as in [6, 11], making the necessary changes to formalize perfect security as well.
Perfect security in the presence of semi-honest adversaries. Loosely speaking, a protocol is secure in the presence of one corrupted party if the view of the corrupted party in a real protocol execution can be generated by a simulator given only the corrupted party’s input and output. The view of party i during an execution of a protocol π on inputs x, denoted Viewπi (x), consists of its input xi, its internal random coins ri and the messages that were received by i in the execution. The output of all parties from an execution of π is denoted by Outputπ(x).
Definition 3.1. Let f : ({0, 1}∗)3 → ({0, 1}∗)3 be a probabilistic 3-ary functionality and let π be a protocol. We say that π computes f with perfect security in the presence of one semi-honest corrupted party for f if there exists a probabilistic polynomial-time algorithm S such that for every corrupted party i ∈ {1, 2, 3}, and every x ∈ ({0, 1}∗)3 where |x1| = |x2| = |x3|:
(S(xi, fi(x)), f (x)) ≡ (Viewπi (x), Outputπ(x)) (3)
If Eq. (3) holds with computational indistinguishability, then we say that π computes f with computational security in the presence of one semi-honest corrupted party.
The above deﬁnition is for the general case of probabilistic functionalities, where we consider the joint distribution of the output of S and of the parties. For the case of deterministic functionalities, however, we can separate the correctness and privacy requirements, and use a simpler and easier to prove deﬁnition. As shown in [11](see section 7.3.1), any probabilistic functionality can be privately computed in the presence of t corrupted parties using a general protocol which computes any deterministic functionality in the presence of t corrupted parties. Therefore, in order to prove the security of our protocol we can use the deﬁnition for deterministic functionalities stated below.
Definition 3.2. Let f : ({0, 1}∗)3 → ({0, 1}∗)3 be a deterministic 3-ary functionality and let π be a protocol. We say that π computes f with perfect security in the presence of one semi-honest corrupted party for f , if for every x ∈ ({0, 1}∗)3 where |x1| = |x2| = |x3|, the following two properties hold: (a) Outputπ(x) = f (x), and (b) there exists a probabilistic polynomial-time algorithm S such that for every corrupted party i ∈ {1, 2, 3}, and every x ∈ ({0, 1}∗)3 where |x1| = |x2| = |x3|:
{S(xi, fi(x))} ≡ {Viewπi (x)}
We prove the security of our protocols using the hybrid model, where parties run a protocol with real messages and also have access to a trusted party computing a subfunctionality for them. The modular sequential composition theorem of [7] states that replacing the trusted party computing the subfunctionality with a real secure protocol results in the same output distribution. When the subfunctionality is g, we say that the protocol works in the g-hybrid model.
Universal composability. Protocols that are proven secure in the universal composability framework [7] have the

property that they maintain their security when run in parallel and concurrently with other secure and insecure protocols. In [17, Theorem 1.5], it was shown that any protocol that is proven secure with a black-box non-rewinding simulator and also has the property that the inputs of all parties are ﬁxed before the execution begins (called input availability or start synchronization in [17]), is also secure under universal composability. Since the input availability property holds for all of our protocols and subprotocols, it is suﬃcient to prove security in the classic stand-alone setting and automatically derive universal composability from [17]. We remark that this also enables us to call the protocol and subprotocols that we use in parallel and concurrently (and not just sequentially), enabling us to achieve more eﬃcient computation (e.g., by running many executions in parallel or by running each layer of a circuit in parallel).

Proof outline. We denote a protocol π in the g-hybrid

model by πg, and the real protocol obtained by replacing

calls to g by invocations of subprotocol ρ by πρ. We abuse

notation and write πg ≡ f to say that π securely computes f

in the g-hybrid model, and write πρ ≡ f to say that the real

protocol πρ securely computes f . Denote by σ the protocol

that computes the correlated randomness functionality Fcr, by ρ the protocol that computes the multiplication function-

ality Fmult in the Fcr-hybrid model, and by π the protocol

that Our

computes goal is to

the functionality prove that πρσ

f in the Fmult-hybrid securely computes f

model. in the

presence of one static semi-honest corrupted party.

Let f be a 3-ary functionality. We begin by proving that

πFmult computes f with perfect security in the presence of

one static semi-honest party. Next, we prove that ρFcr com-

putes Fmult with perfect security in the presence of one static semi-honest party in the Fcr-hybrid model. Finally, we prove that σ computes Fcr with computational security in the presence of one static semi-honest party. The reason for

achieving only computational security for the correlated ran-

domness protocol is that we use a pseudorandom function to

compute the random values. The proof in this case, thereby,

works by making a reduction to a distinguisher between a

pseudorandom function and a random function.

Once we have proved that f ≡ πFmult , that Fmult ≡ ρFcr c
and that Fcr ≡ σ, we can apply the composition theorem of [7] (using the fact that universal composability is implied

via [17]) to conclude that πρFcr ≡ f ; that is, πρσ computes

f with computationl security in the presence of one static

semi-honest adversary.

3.2 Computing f in the Fmult-Hybrid Model
We deﬁne the multiplication functionality Fmult that receives input shares of two values va, vb as input and outputs shares of the product vavb, according to the secret-sharing scheme described in Section 2.3. Intuitively, Fmult should be deﬁned by receiving the shares of all parties, reconstructing the values v1, v2 from the shares, and then generating a random resharing of the v1v2. Indeed, if secure coin tossing were used instead of the method that we use for correlated randomness, then Fmult would be deﬁned in this natural way. However, this would require additional communication and would aﬀect performance. We therefore need to deﬁne a more complex multiplication functionality. In order to understand why this is needed, recall the real protocol and

consider the speciﬁc case that P1 is corrupted. In order to simplify this explanation, consider the Boolean case.
Party P1 computes r1 = x1y1 ⊕ a1b1 ⊕ α and receives r3 from P3. Observe that α is not random to the corrupted P1 and is ﬁxed by a very speciﬁc computation (speciﬁcally, Fk1 (id) ⊕ Fk2 (id); see Section 2.2). Thus, P1’s computation of r1 is deterministic. Now, P1’s output from the multiplication protocol is the pair (z1, c1) where z1 = r1 ⊕ r3 and c1 = r1. Since r3 is received from P3 and is masked with the correlated randomness that P3 receives (which is generated using a pseudorandom function with a key not known to P1) this value is random. However, c1 is ﬁxed (since it equals r1). Stated diﬀerently, given that r1 is ﬁxed, there are exactly two possible values for (z1, c1) based on z1 = 0 or z1 = 1. In contrast, a random secret sharing has four possible values for (z1, c1), with all four combinations of z1, c1 ∈ {0, 1}. Thus, it is not true that the multiplication protocol generates a new random sharing of the product.
In order to solve this problem, we take a diﬀerent approach. We allow the corrupted party to completely determine its share (zi, ci). The functionality Fmult then determines the other parties’ shares based on (zi, ci) and the product vavb. Interestingly, in this secret sharing method, a single share together with the secret fully determines all other shares. This is because each ci = zi−1 − vavb. Thus, (zi, ci) and vavb determines zi−1 = ci + vavb, which in turn determines zi+1 since z1 + z2 + z3 = 0. Finally, all z values together with vavb determine all c values. Formally:
FUNCTIONALITY 3.3 (Fmult – multiplication).
1. Fmult receives ((xj , aj ), (yj , bj )) from each Pj and receives a pair (zi, ci) ∈ Z2n × Z2n from the adversary controlling Pi.
2. Fmult computes va = x1 − a2 and vb = y1 − b2 and vc = vavb.
3. Fmult sets zi−1 = ci + vc and zi+1 = −zi − zi−1, and sets ci−1 = zi+1 − vc and ci+1 = zi − vc.
4. Fmult sends each Pj the pair (zj , cj ) (for j ∈ {1, 2, 3}).
We denote the protocol for securely computing f that is deﬁned in Section 2.3 by Protocol 2.3. We now prove the security of Protocol 2.3 according to Deﬁnition 3.2.
Theorem 3.4. Let f : ((Z2n )∗)3 → ((Z2n )∗)3 be a 3-ary functionality. Then, Protocol 2.3 computes f with perfect security in the Fmult-hybrid model, in the presence of one semi-honest corrupted party.
Proof Sketch: Since the circuit C computes functionality f the ﬁrst (correctness) requirement of Deﬁnition 3.2 is immediately fulﬁlled. We now proceed to the second (privacy) requirement of the deﬁnition. Intuitively, the protocol is private since the corrupted party receives nothing in the execution beyond shares on the input wires which are uniformly distributed and the shares on the output wires. In particular, addition gates consist of local computation only, and multiplication gates are computed using the Fmult functionality. However, in Fmult, the adversary deﬁnes the corrupted party’s share (zi, ci) as it likes and receives nothing back (formally, it receives back (zi, ci) but this is already known). Thus, this can reveal nothing whatsoever about the actual values on the wires in the computation. Finally, for each output wires in which Pi receives output, given its share (zi, ci) on the output wire and given the real output

value v, the simulator can generate the exact shares that Pi would receive from the other parties. This is due to the fact mentioned above that a single share plus the actual secret fully determines the other two shares (and can be computed eﬃciently in the same way as the functionality). It follows that we can construct a simulator that simply deﬁnes the view of the corrupted party to be shares of arbitrary values for the input wires, and provide the shares received on the output wires (after running the adversary and receiving the shares it chooses for its output wires). By Lemma 2.1, the simulator-generated view of the corrupted party is identically distributed to that of a real execution.
3.3 Computing Fmult in the Fcr-Hybrid Model
In this section, we prove that the multiplication protocol described in Section 2.3 computes the Fmult functionality with perfect security in the presence of one semi-honest corrupted party. Recall that we use correlated randomness in the form of random α1, α2, α3 such that α1 + α2 + α3 = 0.
Background – correlated randomness. First, we formally deﬁne the ideal functionality Fcr. A naive deﬁnition would be to have the ideal functionality choose α1, α2, α3 and send αi to Pi for i ∈ {1, 2, 3}. However, securely realizing such a functionality would require interaction (as in the information-theoretic method ﬁrst described in Section 2.2). In order to model our computational method described in Section 2.2 (which is the same as used for the ring case) we need to take into account that the corrupted party’s value is generated in a very speciﬁc way using a pseudorandom function. In order for the Fmult protocol to be secure, all that is needed is that the corrupted party knows nothing about the honest party’s values (beyond the given constraint that all values sum to zero). In particular, there is no requirement regarding how the corrupted party’s value is generated. Recall that in our protocol each party holds two keys which are used to locally compute the correlated randomness. In order for the view of the corrupted party to be like in the real protocol, we deﬁne the functionality Fcr so that it generates the corrupted party’s value in this exact same way (i.e., Fk(id) − Fk (id) for keys k, k ; see Section 2.3). As we have mentioned, the honest parties’ values are chosen randomly, under the constraint that all values sum to zero.
The functionality is described formally in Functionality 3.5. The functionality chooses two keys k, k for a pseudorandom function F and sends them to the corrupted party. We denote by κ the computational security parameter, and thus the length of the keys k, k .
FUNCTIONALITY 3.5 (Fcr – corr. randomness). Let F : {0, 1}∗ × {0, 1}∗ → Z2n be a keyed function. Upon invocation, Fcr chooses a pair of keys k, k ∈ {0, 1}κ and sends them to the adversary controlling party Pi. Then:
• Upon receiving input id from all parties, functionality Fcr computes αi = Fk(id)−Fk (id) and chooses random values αi−1, αi+1 ∈ Z2n under the constraint that α1 + α2 + α3 = 0 mod 2n. Fcr sends αj to Pj for every j.
The multiplication protocol. A formal description of the protocol that securely computes the multiplication functionality Fmult in the Fcr-hybrid model appears in Protocol 3.6.

PROTOCOL 3.6 (Computing Fmult).

• Inputs: Each party Pj (with j ∈ {1, 2, 3}) holds two

pairs of values (xj , aj ) , (yj , bj ) which are valid

3 2

-

sharings of the values that are on the input wires.

• Auxiliary input: The parties hold the same unique identiﬁer id (in the protocol using Fmult this identiﬁer can be the index of the multiplication gate being computed).

• The protocol:

1. Correlated randomness: Each party Pj (with j ∈ {1, 2, 3}) sends id to Fcr and receives back αj from Fcr.

2. Local computation: Each party Pj locally com-

putes:

rj

=

aj

bj −xj 3

yj +αj

.

3. Communication: Party Pj sends rj to party Pj+1 (recall that Pj+1 = P1 when j = 3).

• Output: Each Pj outputs (zj , cj ) where zj = rj−1 − rj and cj = −2rj−1 − rj ; recall rj−1 = r3 when j = 1.

We now prove that the protocol is secure in the presence of one static semi-honest corrupted party.
Theorem 3.7. Protocol 3.6 computes Fmult with perfect security in the Fcr-hybrid model in the presence of one semihonest corrupted party.
Proof. In the protocol, the corrupted party receives a single message. This message is an element from Z2n which is uniformly distributed over Z2n , due to the fact that each party masks its message using a random value received from the Fcr functionality. Intuitively, the protocol is secure because all the corrupted party sees is a random element. (Note that the corrupted party also receives output from Fcr but this is fully determined to be αi = Fk(id)−Fk (id).) We now prove this claim formally.
The Fmult functionality as we have deﬁned it is deterministic, and we therefore prove security via the simpler Deﬁnition 3.2. In order to show correctness, we need to show that the actual values (z1, c1), (z2, c2), (z3, c3) output by all three parties from Protocol 3.6 are exactly the same values as those computed by Fmult. In order to see that this holds, recall that in Section 2.3 we showed that
z1 + z2 + z3 = 0 and ∀j ∈ {1, 2, 3} cj = zj−1 − vavb. (4)
We claim that given a ﬁxed (zi, ci) and vavb, Eq. (4) implies that all values zi−1, ci−1, zi+1, ci+1 are fully determined. Speciﬁcally, let (zi, ci) be ﬁxed and let vavb be the output value. Since for all j ∈ {1, 2, 3} we have cj = zj−1 − vavb, this implies that zi−1 = ci + vavb is determined, which in turn determines zi+1 = −zi − zi−1. Finally, this determines ci+1 = zi − vavb and ci−1 = zi+1 − vavb. This is exactly the way that Fmult computes the output values, and thus these are identical in the protocol and in the functionality output.
We now prove privacy by deﬁning the simulator. The simulator S receives the input and output of the corrupted party Pi from Fmult as well as the auxiliary input id and (k, k ), and needs to compute the messages Pi sees during the execution. The input of the corrupted party Pi consists of two pair of shares (xi, ai), (yi, bi) and it has no output. Intuitively, S chooses a random element ri−1 ∈ Z2n and uses it to deﬁne the pair (zi, ci) that it sends to the trusted party comput-

ing Fmult. Formally, the simulator receives (((xi, ai), (yi, bi)) and works as follows:

1. S chooses a random ri−1 ∈ Z2n .

2.

S

sets ri

=

ai bi −xi yi +αi 3

where αi

= Fk(id) − Fk (id) as

would be computed by Fcr in the protocol.

3. S sets zi = ri−1 = ri and ci = −2ri−1 − ri.

4. S sends (zi, ci) to Fmult. 5. S adds αi and ri−1 to the view of the corrupted party.

The values αi and ri are computed by S exactly as by

Pi in a real execution. The only diﬀerence is how ri−1 is

computed; Pi

receives ri−1 =

ai−1 bi−1 −xi−1 yi−1 +αi−1 3

from

Pi−1 in a real execution, whereas S chooses ri−1 ∈ Z2n uni-

formly at random in the simulation. The distribution over

these two values is identical by the fact that Fcr chooses αi−1, αi+1. Speciﬁcaly, Fcr chooses these at random under the constraint that α1 + α2 + α3 = 0. However, this is equiv-

alent to choosing αi−1 ∈ Z2n uniformly at random and then

setting αi+1 = −αi − αi−1. Now, since αi−1 is uniformly

random, this implies that ri−1 is uniformly random (since

it is independent of all other values used in the generation

of ri−1). Thus, the distribution over the real ri−1 received

by Pi in the protocol execution and over the simulated ri−1

generated by S is identical. This completes the proof.

3.4 Computing Fcr in the Plain Model
In this section, we prove that our protocol privately computes the Fcr functionality in the presence of one semihonest corrupted party. We have already presented the Fcr functionality in Functionality 3.5. The protocol for computing it appears in Protocol 3.8.
PROTOCOL 3.8 (Computing Fcr).
• Auxiliary input: Each party holds a security parameter κ, a description of a pseudorandom function F : {0, 1}κ × {0, 1}κ → Z2n .
• Setup (executed once): 1. Each party Pj chooses randomly kj ∈ {0, 1}κ. 2. Each party Pj sends kj to party Pj+1.
• Generating randomness: Upon input id, each party Pj computes αj = Fkj (id) − Fkj−1 (id) and outputs it.

Theorem 3.9. If Fk() is a pseudorandom function, then Protocol 3.8 computes Fcr with computational security in the plain model, in the presence of 1 semi-honest corrupted party.
Proof Sketch: Since the functionality is probabilistic, we need to use Deﬁnition 3.1. Unlike the previous security proofs we have seen, the security of this protocol is computational and it relies on the assumption that Fk is a pseudorandom function. Thus, we will show that the ability to distinguish between the outputs in the real and ideal executions can be used to distinguish between the pseudorandom function and a truly random function, in contradiction to the assumption.
Let Pi be the corrupted party. We deﬁne the simulator S who simulates Pi’s view. S is invoked on the security parameter 1κ and works as follows:
1. S receives k, k from Fcr when it is ﬁrst invoked (see Functionality 3.5).

2. S sets the random tape of Pi (used by Pi to sample ki) to be the key k received from Fcr.
3. S simulates the setup phase by writing the key k as the key ki−1 received by Pi from Pi−1.
4. From this point on, every time that Pi receives id for input, S sends it to the trusted party computing Fcr. (Pi receives back αi but this equals Fk(id) − Fk (id) = Fki (id) − Fki−1 (id) and is known to Pi. Also, this value is computed locally by Pi in the protocol and not received. Thus, S does not include it in Pi’s view.)
It is easy to see that the view generated by the simulator which consists of the Pi’s random tape and the incoming message ki−1 is distributed identically to its view in a real execution. However, this is not suﬃcient, as we need to prove indistinguishability of the joint distribution of both the corrupted party’s view and the honest parties’ outputs. Observe that in the real protocol execution, the honest parties’ outputs are generated using the pseudorandom function, whereas in the ideal world they are chosen randomly by Fcr.
Intuitively, the proof follows from the fact that both Pi−1 and Pi+1 generate their values using the pseudorandom function F with key ki+1 that is independent of ki and ki−1. Thus, replacing Fki+1 with a truly random function f results in Pi−1 and Pi+1 generating values αi−1 and αi+1 that are random under the constraint that α1 + α2 + α3 = 0. (Speciﬁcally, Pi−1 generates αi−1 = Fki−1 (id) − f (id) and Pi+1 generates αi+1 = f (id) − Fki (id). Thus, αi−1 + αi+1 = Fki−1 (id) − f (id) + f (id) − Fki (id) = Fki−1 (id) − Fki (id) = −αi, as required.) The full proof follows via a straightforward reduction.
3.5 Wrapping Up
In the previous sections, we have proven that Protocol 2.3 computes any 3-ary functionality with perfect security in the Fmult-hybrid model, and that Protocol 3.6 computes the Fmult functionality with perfect security in the Fcr-hybrid model. Finally, we have proved that Protocol 3.8 computes Fcr with computational security (in the plain model) under the assumption that pseudorandom functions exist. (All of the above holds for a single corrupted party in the semihonest model.) Using the fact that all our protocols are UC secure from [17] and thus applying the UC composition theorem of [7], we conclude with the following theorem:
Theorem 3.10. Assume that F is a pseudorandom function, and let f be a 3-ary functionality. Then, Protocol 2.3 computes f with computational security, in the presence of one semi-honest corrupted party.
4. PRIVACY: MALICIOUS ADVERSARIES IN THE CLIENT-SERVER MODEL
In this section, we consider the “client-server” model where the parties running the multiparty computation protocol are servers who receive the input shares of multiple clients and compute the output for them. This is the model used by Cybernetica in their Sharemind product [4]. In this model, the servers do not see any of the inputs nor any of the outputs. Rather, they receive shares of the inputs and send the clients

shares of their output. Since the parties running the multiparty protocol do not have any input or output, it is possible to formulate an indistinguishability-based deﬁnition of security, saying that a corrupted server learns nothing. In this section, we present such a deﬁnition, and we prove that our protocol fulﬁlls this deﬁnition of privacy even in the presence of a malicious corrupted party. We believe that this formalization is of independent interest, and could be used to make similar claims regarding other information-theoretic protocols like [2] and [4, 5]; namely, that although they are only secure in the presence of semi-honest adversaries, they are in fact private in the presence of malicious adversaries.
Before proceeding, we stress that a deﬁnition of privacy is strictly weaker than standard deﬁnitions of security for malicious adversaries. Most notably, correctness is not guaranteed and a malicious server may tamper with the output. In settings where the adversary may receive some feedback about the output, this may also reveal information about the input. Thus, our claim of privacy is only with respect to a malicious server who receives no information about the output.

Deﬁning security. Let ViewA,I,π(v, κ) denote the view of

an adversary A who controls parties {Pi}i∈I (with I ⊂ [n])

in a real execution of the n-party protocol π, with inputs

v = (v1, . . . , vN ) and security parameter κ. We stress that

in this setting, the vector of inputs v is of length N and N

may be much longer (or shorter) than the number of par-

ties n running the protocol. This is because N refers to

the number of inputs and so the number of clients, whereas

n denotes the number of servers running the actual proto-

col. In addition, the servers do not receive for input any of

the values in v but rather they each receive secret shares of

the value. Formally, one should specify the secret sharing

method. However, for generality, we do not deﬁne any spe-

ciﬁc secret sharing scheme and rather deﬁne that for every

vj in v, random vj1, . . . , vjn are chosen under the constraint

that

n =1

vj

=

vj ,

and

each

server

Pj

is

given

the

share

vj

(for every 1 ≤ j ≤ N ).

Loosely speaking, a protocol is private in the presence of

one malicious corrupted party if the view of the corrupted

party when the input is v is computationally indistinguish-

able from its view when the input is v . In order to rule

out a trivial protocol where nothing is exchanged, we also

require correctness, which means that when all parties are

honest they obtain the correct output.

Definition 4.1. Let f : ({0, 1}∗)N → ({0, 1}∗)N be an N -party functionality and let π be an n-party protocol. We say that π t-privately computes f in the client-server model in the presence of malicious adversaries if it is correct and if for every non-uniform probabilistic polynomial-time adversary A, every I ⊂ [n] with |I| ≤ t, and every two series of lengthN vectors V1 = {vκ1 }, V2 = {vκ2 }

ViewA,I,π(vκ1 , κ)

c
≡
κ∈N

ViewA,I,π(vκ2 , κ) κ∈N

where for every κ ∈ N, vκ1 , vκ2 ∈ ({0, 1}∗)N and all elements of vκ1 and vκ2 are of the same length.

We now prove that Protocol 2.3 fulﬁlls Deﬁnition 4.1, when making the appropriate changes to the input (converting vectors of length N into 3-way additive shares for the parties running Protocol 2.3).

Theorem 4.2. Let f : ((Z2n )∗) → ((Z2n )∗) be an N party functionality and deﬁne the 3-party functionality gf to be the function that receives 3 length-N input vectors that constitute additive-shares of the input vector v to f and outputs 3 length-N vectors that constitute additive-shares of f (v). If F is a pseudorandom function, then Protocol 2.3 applied to function gf 1-privately computes f in the clientserver model in the presence of malicious adversaries.
Proof Sketch: Correctness is also required for the semi-honest setting and this is therefore already implied by Theorem 3.4. In order to prove privacy, we need to show that the view of a malicious A controlling one party when the input is v is indistinguishable from its view when the input is v . We ﬁrst prove that the views are identical when information-theoretic correlated randomness is used (as described in the beginning of Section 2.2).
First, intuitively, the views are identical with informationtheoretic correlated randomness since all the adversary sees in every rounds is a random share. In order to see that this holds even when A is malicious, observe that each share sent to the adversary is masked by a new value obtained from the correlated randomness. Thus, irrespective of what A sends in every round, the value that it receives is a random element. Thus, its view is actually independent of the values that it sends.
Second, consider the view when Protocol 3.8 is used for computing Fcr. In the setup phase, A sends some value ki and receives ki−1. However, the security of the protocol is proven based on the pseudorandomness of the function keyed by ki+1 that A does not see. Importantly to this case of malicious adversaries, ki+1 is chosen independently of what A sends. Furthermore, the parties generate randomness from this point on using local computation only. Thus, the values generated by the honest parties are pseudorandom, irrespective of what A sent. More formally, consider a reduction where Fki+1 is replaced by a truly random function f . Then, Pi−1 computes αi−1 = Fki−1 (id) − f (id) and Pi+1 computes αi+1 = f (id)−Fki (id). Since ki and ki−1 are ﬁxed and independent of f , it follows that αi−1, αi+1 are random under the constraint that αi−1 +αi+1 = −(Fki (id)−Fki−1 (id)) = −αi, as required. As we have stated, this holds irrespective of what value ki that A sent, and A cannot inﬂuence the αi−1, αi+1 values computed since they involve local computation by the honest parties alone. Thus, the view in this case is indistinguishable from the view when the parties use information-theoretic correlated randomness.
5. EXPERIMENTAL RESULTS
5.1 Implementation and Bit-Slicing
We implemented the protocol for Boolean circuits in C++ using standard optimizations known for multiparty computation. One speciﬁc optimization that we found to be of great importance was the use of Intel intrinsics for bit slicing operations; we describe this in more detail here. Since our protocol is extremely simple, running a single computation is very wasteful both with respect to CPU and network utilization. A signiﬁcant portion of this waste is due to the fact that our protocol processes single bits only, whereas modern processors work on larger objects. We ran our protocol on 12800 operations in parallel by batching 128 operations

together and running 100 of these in parallel. This batching works by bit-slicing: the ith bit of input in 128 diﬀerent inputs are sliced into a single string of length 128 (for each i). Likewise, the batched output bits need to be de-sliced into 128 separate outputs. This is a type of “matrix transpose” – see Figure 1 – and turns out to be very expensive. Indeed, a straightforward implementation of this bit slicing and de-slicing turned out to greatly dominate the overall execution time. Hence, we implemented fast bit-slicing and bit-deslicing methods using Intel SIMD intrinsics in order to reduce this cost.
Figure 1: Bit-slice The unit of our bit-slicing is 16 messages of length 8 bytes each (overall 128 bytes). Thus, we start with: m0 = (m0,0, m0,1, m0,2, m0,3, m0,4, m0,5, m0,6, m0,7) m1 = (m1,0, m1,1, m1,2, m1,3, m1,4, m1,5, m1,6, m1,7)
... m15 = (m15,0, m15,1, m15,2, m15,3, m15,4, m15,5, m15,6, m15,7). Then, we apply the Intel intrinsics “unpack” instruction 32 times to obtain 8 messages, each of length 16 bytes:
m0 = (m0,0, m1,0, . . . , m15,0) m1 = (m0,1, m1,0, . . . , m15,1)
... m7 = (m0,7, m1,7, . . . , m15,7). The unpack instruction treats the 128 bit register as 16 single-byte values (8 low and 8 high), and has instructions to interleave either the low or the high bytes. This process is actually byte-slicing (since the “transpose”-type operation is carried out at the byte level and not the bit level). See Figure 2 for a graphic description of this operation.
Figure 2: Unpack operation of AVX instruction set The next step is to further slice the messages to the bit level. We do this applying the Intel movmskb 64 times to

obtain the bit-sliced inputs. This instruction creates a 16-bit mask from the most signiﬁcant bits of 16 signed or unsigned 8-bit integers in a register and zeroes the upper bits. Thus, we are able to take the MSB of 16 bytes in a register in a single cycle, which is very fast. The movmskb instruction is depicted in Fig. 3.

Thus, the approximate 100,000 AES computations per core per second are achieved in this way.
See Figures 4 and 5 for graphs showing the behavior of the implementation as higher throughputs are achieved.

Figure 3: Moving masked bit operation of AVX instruction set

We apply the movmskb operation to each mi from the ﬁrst step (note that each mi consists of 16 bytes, exactly as needed for movmskb). These optimizations were crucial for obtaining the high performance reported in this paper.
5.2 Fast AES
We ran our implementation on a cluster of three mid-level servers connected by a 10Gbps LAN with a ping time of 0.13 ms. Each server has two Intel Xeon E5-2650 v3 2.3GHz CPUs with a total of 20 cores. We ran the implementation utilizing a diﬀerent number of cores, from 1 through to 20. Each core was given 12800 computations which were carried out in parallel. (Since Intel intrinsics works on 128-bit registers, this means that inputs were sliced together in groups of 128 and then 100 of these were run in parallel by each core.) These computations can be with diﬀerent keys since each MPC can have diﬀerent inputs; this will be used in Section 5.3.
Observe that up to 10 cores, the throughput is stable at approximately 100,000 AES/sec per core. However, beyond 10 cores this begins to deteriorate. This is due to queuing between the kernel and the Network Interface Card (NIC). Speciﬁcally, when a single process utilizing a single CPU is used, that process has full control over the NIC. However, when multiple processes are run, utilizing high bandwidth, requests from each process are handled in a queue between the kernel and the NIC. This queuing increases network latency, and as each process spends more time waiting for communication, CPU usage drops by a noticeable percentage. It is possible to overcome this by bypassing the kernel layer and communicating directly with the NIC. One approach for achieving this appeared in [20].
We ran each experiment 5 times; this was suﬃcient due to the very low variance as can be seen in Table 2. The results represent a 95% conﬁdence interval.

Cores 1 5 10 16 20

AES/sec 100,103 ± 1632 530,408 ± 7219 975,237 ± 3049 1,242,310 ± 4154 1,324,117 ± 3721

Latency 128.5 ± 2.1 121.2 ± 1.7 131.9 ± 0.4 165.7 ± 0.4 194.2 ± 0.9

CPU % 73.3% 62.2% 54.0% 49.5% 49.6%

Network 0.572 2.99 5.47 6.95 7.38

Table 2: Experiment results running AES-CTR. The CPU column shows the average CPU utilization per core, and the network column is in Gbps per server. Latency is given in milliseconds.

Recall that each core processed 12800 AES computations in parallel, and observe that with a latency of 129ms approximately 7 calls can be processed per second by each core.

Figure 4: Throughput per core (AES computations)

Figure 5: Latency versus throughput (AES)

Microbenchmarking. We measured the time spent on each part of the protocol, with the following results.

Protocol part Server bitslice and deslice AND and XOR gate computation Randomness generation Comm. delays between MPC servers Communication delays for input/output

Percentage 8.70% 49.82% 9.54% 27.87% 4.07%

We remark that the long communication delays are due to the fact that the communication topology of our implementation is a ring. Thus, each party waits for two other messages to be processed before it receives its next message. In order to reduce this waste, the randomness generation is run during this delay. Thus, if the randomness generation was “free”, the communication delay would increase to 37.41% and it would not be any faster. This demonstrates that the eﬃciency improvements could be achieved by communicating in every step.
5.3 Kerberos KDC with Shared Passwords
In order to demonstrate the potential of our protocol, we incorporate it into a real application. Kerberos is used for user authentication in many systems, most notably it is used by all Windows systems since Windows 2000. Kerberos

uses the hashed user password as a key to encrypt a TicketGranting-Ticket (TGT) which contains a high-entropy cryptographic key which is used for all communications after the user logs in. In Kerberos, a server breach is particularly devastating since the hashed password is all that is needed for impersonating a user. This is because the TGT is encrypted with the hashed user password and sent to the user. Thus, an attacker knowing the hashed password alone can decrypt the TGT. Microsoft’s Active Directory has suﬀered breaches in the past, and such a breach enables an attacker to impersonate every user in the organization.
In order to mitigate this risk, we consider a system where the hashed user passwords are XOR-shared between two servers (with diﬀerent administrators), and secure multiparty computation is used to carry out the login authentication without ever reconstructing the hashed password. This makes it harder for an attacker to steal hashed passwords (needing to breach both servers) and also mitigates insider threats since no single administrator has access to the hashed user passwords. Since the ticket-granting-server’s long-term key is also very sensitive, this is also protected in the same way. The architecture of the Kerberos solution is depicted in Figure 6.
Figure 6: The Kerberos authentication using MPC
We took the Open Source MIT Kerberos and modiﬁed the encryption mode used to encrypt the TGT to counter mode. This is important since CBC mode does not enable parallel encryption and this would slow the encryption down signiﬁcantly. In more detail, the authentication process in Kerberos has the following steps:
1. Pre-authentication: We use the pa-enc-timestamp method, which means that the user encrypts the date using his hashed password as the key. This is a single AES block (and so ECB is used).
2. TGT encryption: A session key to be used by the user and ticket-granting server (TGS) to communicate later is generated. Then, the TGT (containing the client information and the session key) is generated and encrypted under the long-term key of the TGS. The TGT is 15 blocks of AES.
3. Session-key and TGT encryption: The session key and TGS are AES-encrypted with the user’s hashed password.

Overall, the number of encryption blocks for a single user authentication is 33: one block for pre-authentication, 15 blocks for TGT encryption under the long-term key of the TGS, and 17 blocks for session-key and TGT encryption under the user key (this last encryption is 17 blocks due to the addition of the session key and header information).
In all of the above encryptions, when using the Kerberos encryption type aes128-cts-hmac-sha1-96, all of the encryption above is without HMAC authentication. (HMAC is only used for communication following these initial steps.) As we have mentioned, we implemented a Kerberos extension that uses counter mode instead of CBC (cts is CBC mode with ciphertext stealing). This is important for two reasons. First, CBC encryption cannot be parallelized and so each block must be encrypted after the previous block has been encrypted. In addition, the TGT cannot be encrypted under the user key until it has been encrypted under the long-term key of the TGS. However, when using counter mode, all of the AES computations can be carried out in parallel. Speciﬁcally, upon receiving a user authentication request together with a pre-authentication ciphertext, the following is carried out:
1. The servers running the secure computation protocol load the shares of the long-term key of the TGS and the shares of the user’s key i.e., hash of the user’s password).
2. Two random counters ctr1 and ctr2 are chosen.
3. 33 AES computations are run in parallel: a single AES decryption of the pre-authentication ciphertext, 15 AES encryptions of ctr1 + 1, . . . , ctr1 + 15, and 17 AES encryptions of ctr2 + 1, . . . , ctr2 + 16.
4. The preauthentication value is veriﬁed; if it is valid, then the server proceeds to the next step.
5. The output of the 15 AES encryptions using ctr1 is XORed with the TGT.
6. The encrypted TGT from the previous step is concatenated with the session key and some header information. This is treated as a plaintext and XORed with the result of the 17 AES encryptions using ctr2.
7. The result of the previous step along with ctr1 and ctr2 is sent to the user.
This ﬂow enables all of the AES computations to be carried out in parallel, yielding a latency of approximately 120 milliseconds. We remark that in order for the server to be able to process requests in bulk, a new set of AES encryptions is begun every 100 milliseconds. Thus, authentication requests are queued for at most 100 milliseconds (and on average 50ms) and then processed. This ensures that the overall latency (of a client) of processing an authentication request is approximately 200 milliseconds. This is a very reasonable time for an application like Kerberos where a user is involved in the authentication process.
Experimental results. In order to test our implementation, we ran the complete Kerberos login using the aforementioned cluster of three servers computing AES. The number of logins per second with a single core was 2,970, with 10 cores was 28,723 and with 16 cores was 36,521. Thus, our Kerberos implementation (that incorporates the extension

described above in MIT-Kerberos) is able to support a signiﬁcant login storm of over 35,000 user logins per second. This is suﬃcient even for very large organizations (if more is needed, then this can be achieved by simply using two clusters instead of one). Beyond the number of logins per second, it is important to ensure that the latency is low; otherwise, users will have to wait too long at login. This is the reason that we designed the TGT-generation process in a way that enables full parallelism of the AES operations. Our results give an average latency of the AES encryption via MPC at 110ms, and an average latency at the client (over a LAN) of 232ms. The increased time in the client is due to additional work carried out both by the client and the KDC, and due to the fact that requests are processed every 100ms.
Acknowledgements
We express our thank to Assi Barak and Felipe Zimmerle for their crucial help and contribution to the implementation and experimental results.
6. REFERENCES
[1] G. Asharov and Y. Lindell. A Full Proof of the BGW Protocol for Perfectly-Secure Multiparty Computation. To appear in J. of Cryptology.
[2] M. Ben-Or, S. Goldwasser, A. Wigderson. Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation. STOC 1988 : 1-10
[3] D. Beaver, S. Micali, and P. Rogaway. The round complexity of secure protocols. In the 22nd STOC, pages 503–513, 1990.
[4] D. Bogdanov, S. Laur and J. Willemson. Sharemind: A framework for fast privacy-preserving computations. In ESORICS 2008, Springer (LNCS 5283), 192–206, 2008.
[5] D. Bogdanov, M. Niitsoo, T. Toft, J. Willemson. High-performance secure multi-party computation for data mining applications. Int. J. Inf. Sec. 11(6): 403-418, 2012.
[6] R. Canetti. Security and Composition of Multiparty Cryptographic Protocols. In the Journal of Cryptology, 13(1):143-202, 2000.
[7] R. Canetti. Universally Composable Security: A New Paradigm for Cryptographic Protocols. In 42nd FOCS, pages 136–145, 2001.
[8] D. Chaum, C. Cr´epeau and I. Damg˚ard. Multi-party Unconditionally Secure Protocols. In 20th STOC, pages 11–19, 1988.
[9] R. Cramer, I. Damg˚ard and Y. Ishai. Share Conversion, Pseudorandom Secret-Sharing and Applications to Secure Computation. In the 2nd TCC, Springer (LNCS 3378), pages 342–362, 2005.
[10] I. Damg˚ard and M. Keller. Secure multiparty AES. In Financial Cryptography, Springer (LNCS 6052), pages 367–374, 2010.
[11] O. Goldreich: Foundations of Cryptography Volume 2, Basic Applications. Cambridge University Press 2004.
[12] O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game. 19th STOC, 218–229, 1987.

[13] S. Gueron, Y. Lindell, A. Nof and B. Pinkas. Fast Garbling of Circuits Under Standard Assumptions. In 22nd ACM CCS, pages 567–578, 2015.
[14] Y. Ishai and E. Kushilevitz. On the Hardness of Information-Theoretic Multiparty Computation. In EUROCRYPT 2004, Springer (LNCS 3027), pages 439–455, 2004.
[15] M. Keller, E. Orsini and P. Scholl. Actively Secure OT Extension with Optimal Overhead. In CRYPTO 2015, Springer (LNCS 9215), pages 724–741, 2015.
[16] L. Kerik, P. Laud and J. Randmets. Optimizing MPC for robust and scalable integer and ﬂoating-point arithmetic. In 4th WAHC, 2016.
[17] E. Kushilevitz, Y. Lindell and T. Rabin. Information-Theoretically Secure Protocols and Security Under Composition. In the SIAM Journal on Computing, 39(5): 2090-2112, 2010.
[18] J. Launchbury, I.S. Diatchki, T. DuBuisson and A. Adams-Moran. Eﬃcient lookup-table protocol in secure multiparty computation. In ACM ICFP’12, pages 189–200, 2012.
[19] S. Laur, R. Talviste and J. Willemson. From Oblivious AES to Eﬃcient and Secure Database Join in the Multiparty Setting. In ACNS’13, Springer (LNCS 7954), pages 84–101, 2013.
[20] J. Perry, A. Ousterhout, H. Balakrishnan, D. Shah and H Fugal. Fastpass: a centralized “zero-queue” datacenter network. In SIGCOMM 2014, pages 307–318, 2014
[21] T. Rabin, M. Ben-Or. Veriﬁable Secret Sharing and Multiparty Protocols with Honest Majority (Extended Abstract). STOC 1989 : 73-85
[22] J. Randmets. Personal comm. – AES performance on the new Sharemind cluster. May, 2016.
[23] R. Talviste. Applying Secure Multi-Party Computation in Practice. Ph.D dissertation, Univ. of Tartu, 2016.
[24] A. Shamir. How to Share a Secret. Communications of the ACM, 22(11):612–613, 1979.
[25] A. Yao. How to Generate and Exchange Secrets. In the 27th FOCS, pages 162–167, 1986.
[26] S. Zahur, M. Rosulek and D. Evans. Two Halves Make a Whole - Reducing Data Transfer in Garbled Circuits Using Half Gates. EUROCRYPT, pages 220–250, 2015.
[27] Sharemind, Cybernetica. https://sharemind.cyber.ee.

