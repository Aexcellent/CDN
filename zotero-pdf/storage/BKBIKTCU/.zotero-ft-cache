A Pragmatic Introduction to Secure Multi-Party Computation
David Evans University of Virginia evans@virginia.edu Vladimir Kolesnikov Georgia Institute of Technology kolesnikov@gatech.edu
Mike Rosulek Oregon State University rosulekm@eecs.oregonstate.edu
Boston — Delft

A Pragmatic Introduction to Secure Multi-Party Computation
David Evans1, Vladimir Kolesnikov2 and Mike Rosulek3 1University of Virginia; evans@virginia.edu 2Georgia Institute of Technology; kolesnikov@gatech.edu 3Oregon State University, rosulekm@eecs.oregonstate.edu
ABSTRACT Secure multi-party computation (MPC) has evolved from a theoretical curiosity in the 1980s to a tool for building real systems today. Over the past decade, MPC has been one of the most active research areas in both theoretical and applied cryptography. This book introduces several important MPC protocols, and surveys methods for improving the eﬃciency of privacy-preserving applications built using MPC. Besides giving a broad overview of the ﬁeld and the insights of the main constructions, we overview the most currently active areas of MPC research and aim to give readers insights into what problems are practically solvable using MPC today and how diﬀerent threat models and assumptions impact the practicality of diﬀerent approaches.
David Evans, Vladimir Kolesnikov and Mike Rosulek, A Pragmatic Introduction to Secure MultiParty Computation. NOW Publishers, 2018. (This version: April 5, 2021)

Contents

1 Introduction

5

1.1 Outsourced Computation . . . . . . . . . . . . . . . . . . . . . 6 1.2 Multi-Party Computation . . . . . . . . . . . . . . . . . . . . . 7 1.3 MPC Applications . . . . . . . . . . . . . . . . . . . . . . . . 8 1.4 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

2 Deﬁning Multi-Party Computation

15

2.1 Notations and Conventions . . . . . . . . . . . . . . . . . . . . 15 2.2 Basic Primitives . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.3 Security of Multi-Party Computation . . . . . . . . . . . . . . . 19 2.4 Speciﬁc Functionalities of Interest . . . . . . . . . . . . . . . . 28 2.5 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 31

3 Fundamental MPC Protocols

32

3.1 Yao’s Garbled Circuits Protocol . . . . . . . . . . . . . . . . . 33 3.2 Goldreich-Micali-Wigderson (GMW) Protocol . . . . . . . . . . 37 3.3 BGW protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 3.4 MPC From Preprocessed Multiplication Triples . . . . . . . . . 44 3.5 Constant-Round Multi-Party Computation: BMR . . . . . . . . . 47 3.6 Information-Theoretic Garbled Circuits . . . . . . . . . . . . . . 50

3

3.7 Oblivious Transfer . . . . . . . . . . . . . . . . . . . . . . . . 54 3.8 Custom Protocols . . . . . . . . . . . . . . . . . . . . . . . . . 59 3.9 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 63

4 Implementation Techniques

65

4.1 Less Expensive Garbling . . . . . . . . . . . . . . . . . . . . . 66 4.2 Optimizing Circuits . . . . . . . . . . . . . . . . . . . . . . . . 74 4.3 Protocol Execution . . . . . . . . . . . . . . . . . . . . . . . . 79 4.4 Programming Tools . . . . . . . . . . . . . . . . . . . . . . . . 83 4.5 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 85

5 Oblivious Data Structures

87

5.1 Tailored Oblivious Data Structures . . . . . . . . . . . . . . . . 88 5.2 RAM-Based MPC . . . . . . . . . . . . . . . . . . . . . . . . 92 5.3 Tree-Based RAM-MPC . . . . . . . . . . . . . . . . . . . . . . 93 5.4 Square-Root RAM-MPC . . . . . . . . . . . . . . . . . . . . . 96 5.5 Floram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 5.6 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 101

6 Malicious Security

102

6.1 Cut-and-Choose . . . . . . . . . . . . . . . . . . . . . . . . . 102 6.2 Input Recovery Technique . . . . . . . . . . . . . . . . . . . . 107 6.3 Batched Cut-and-Choose . . . . . . . . . . . . . . . . . . . . 109 6.4 Gate-level Cut-and-Choose: LEGO . . . . . . . . . . . . . . . 110 6.5 Zero-Knowledge Proofs . . . . . . . . . . . . . . . . . . . . . 113 6.6 Authenticated Secret Sharing: BDOZ and SPDZ . . . . . . . . . 116 6.7 Authenticated Garbling . . . . . . . . . . . . . . . . . . . . . . 121 6.8 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 124

7 Alternative Threat Models

126

7.1 Honest Majority . . . . . . . . . . . . . . . . . . . . . . . . . . 127 7.2 Asymmetric Trust . . . . . . . . . . . . . . . . . . . . . . . . . 131 7.3 Covert Security . . . . . . . . . . . . . . . . . . . . . . . . . . 133 7.4 Publicly Veriﬁable Covert (PVC) Security . . . . . . . . . . . . 137

4

7.5 Reducing Communication in Cut-and-Choose Protocols . . . . . 141 7.6 Trading Oﬀ Leakage for Eﬃciency . . . . . . . . . . . . . . . . 142 7.7 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . 145

8 Conclusion

148

Acknowledgements

152

References

154

1
Introduction
Secure multi-party computation (MPC) protocols enable a group to jointly perform a computation without disclosing any participant’s private inputs. The participants agree on a function to compute, and then can use an MPC protocol to jointly compute the output of that function on their secret inputs without revealing them. Since its introduction by Andrew Yao in the 1980s, multi-party computation has developed from a theoretical curiosity to an important tool for building large-scale privacy-preserving applications.
This book provides an introduction to multi-party computation for practitioners interested in building privacy-preserving applications and researchers who want to work in the area. We provide an introduction to the foundations of MPC and describe the current state of the art. Our goal is to enable readers to understand what is possible today, and what may be possible in the future, and to provide a starting point for building applications using MPC and for developing MPC protocols, implementations, tools, and applications. As such, we focus on practical aspects, and do not provide formal proofs.
The term secure computation is used to broadly encompass all methods for performing computation on data while keeping that data secret. A computation method may also allow participants to conﬁrm the result is indeed the output of the function on the provided inputs, which is known as veriﬁable computation.
5

6

Introduction

There are two main types of secure and veriﬁable computation: outsourced computation and multi-party computation. Our focus is on multi-party computation, but ﬁrst we brieﬂy describe outsourced computation to distinguish it from multi-party computation.
1.1 Outsourced Computation
In an outsourced computation, one party owns the data and wants to be able to obtain the result of computation on that data. The second party receives and stores the data in an encrypted form, performs computation on the encrypted data, and provides the encrypted results to the data owner, without learning anything about the input data, intermediate values, or ﬁnal result. The data owner can then decrypt the returned results to obtain the output.
Homomorphic encryption allows operations on encrypted data, and is a natural primitive to implement outsourced computation. With partiallyhomomorphic encryption schemes, only certain operations can be performed. Several eﬃcient partially-homomorphic encryption schemes are known (Paillier, 1999; Naccache and Stern, 1998; Boneh et al., 2005). Systems built on them are limited to specialized problems that can be framed in terms of the supported operations.
To provide fully homomorphic encryption (FHE), it is necessary to support a universal set of operations (e.g., both addition and multiplication, along with constants 0 and 1) so that any ﬁnite function can be computed. Although the goal of FHE was envisioned by Rivest et al. (1978), it took more than 30 years before the ﬁrst FHE scheme was proposed by Gentry (2009), building on lattice-based cryptography. Although there has been much recent interest in implementing FHE schemes Gentry and Halevi (2011), Halevi and Shoup (2015), and Chillotti et al. (2016), building secure, deployable, scalable systems using FHE remains an elusive goal.
In their basic forms, FHE and MPC address diﬀerent aspects of MPC, and as such shouldn’t be directly compared. They do, however, provide similar functionalities, and there are ways to adapt FHE to use multiple keys that enables multi-party computation using FHE (Asharov et al., 2012; LópezAlt et al., 2012; Mukherjee and Wichs, 2016). FHE oﬀers an asymptotic communication improvement in comparison with MPC, but at the expense of computational eﬃciency. State-of-the-art FHE implementations (Chillotti

1.2. Multi-Party Computation

7

et al., 2017) are thousands of times slower than two-party and multi-party secure computation in typical applications and settings considered in literature. Ultimately, the relative performance of FHE and MPC depends on the relative costs of computation and bandwidth. For high-bandwidth settings, such as where devices connected within a data center, MPC vastly outperforms FHE. As FHE techniques improve, and the relative cost of bandwidth over computation increases, FHE-based techniques may eventually become competitive with MPC for many applications.
We do not speciﬁcally consider outsourcing computation or FHE further in this book, but note that some of the techniques developed to improve multi-party computation also apply to FHE and outsourcing. Shan et al. (2017) provide a survey of work in the area of outsourcing.
1.2 Multi-Party Computation
The goal of secure multi-party computation (MPC) is to enable a group of independent data owners who do not trust each other or any common third party to jointly compute a function that depends on all of their private inputs. MPC diﬀers from outsourced computation in that all of the protocol participants are data owners who participate in executing a protocol. Chapter 2 provides a more formal deﬁnition of MPC, and introduces the most commonly considered threat models.
Brief history of MPC. The idea of secure computation was introduced by Andrew Yao in the early 1980s (Yao, 1982). That paper introduced a general notion of secure computation, in which m parties want to jointly compute a function f (x1, x2, . . . , xm) where xi is the ith party’s private input. In a series of talks over the next few years (but not included in any formal publication), Yao introduced the Garbled Circuits Protocol which we describe in detail in Section 3.1. This protocol remains the basis for many of the most eﬃcient MPC implementations.
Secure computation was primarily of only theoretical interest for the next twenty years; it was not until the 2000s that algorithmic improvements and computing costs had reached a point where it became realistic to think about building practical systems using general-purpose multi-party computation.

8

Introduction

Fairplay (Malkhi et al., 2004) was the ﬁrst notable implementation of a generalpurpose secure computation system. Fairplay demonstrated the possibility that a privacy-preserving program could be expressed in a high level language and compiled to executables that could be run by the data-owning participants as a multi-party protocol. However, its scalability and performance limited its use to toy programs — the largest application reported in the Fairplay paper was computing the median two sorted arrays where each party’s input is ten 16-bit numbers in sorted order, involving execution of 4383 gates and taking over 7 seconds to execute (with both parties connected over a LAN). Since then, the speed of MPC protocols has improved by more than ﬁve orders of magnitude due to a combination of cryptographic, protocol, network and hardware improvements. This enabled MPC applications to scale to a wide range of interesting and important applications.
Generic and specialized MPC. Yao’s garbled circuits protocol is a generic protocol—it can be used to compute any discrete function that can be represented as a ﬁxed-size circuit. One important sub-area of MPC focuses on speciﬁc functionalities, such as private set intersection (PSI). For speciﬁc functionalities, there may be custom protocols that are much more eﬃcient than the best generic protocols. Speciﬁc functionalities can be interesting in their own right, but also can be natural building blocks for use in other applications. We focus mostly on generic MPC protocols, but include discussion of private set intersection (Section 3.8.1) as a particularly useful functionality.
1.3 MPC Applications
MPC enables privacy-preserving applications where multiple mutually distrusting data owners cooperate to compute a function. Here, we highlight a few illustrative examples of privacy-preserving applications that can be built using MPC. This list is far from exhaustive, and is meant merely to give an idea of the range and scale of MPC applications.
Yao’s Millionaires Problem. The toy problem that was used to introduce secure computation is not meant as a useful application. Yao (1982) introduces it simply: “Two millionaires wish to know who is richer; however, they do not want to ﬁnd out inadvertently any additional information about each other’s

1.3. MPC Applications

9

wealth.” That is, the goal is to compute the Boolean result of x1 ≤ x2 where x1 is the ﬁrst party’s private input and x2 is the second party’s private input. Although it is a toy problem, Yao’s Millionaires Problem can still be useful for illustrating issues in MPC applications.
Secure auctions. The need for privacy in auctions is well understood. Indeed, it is crucial for all participants, both bidders and sellers, to be able to rely on the privacy and non-malleability of bids. Bid privacy requires that no player may learn any other player’s bid (other than perhaps revealing the winning bid upon the completion of the auction). Bid non-malleability means that a player’s bid may not be manipulated to generate a related bid. For example, if a party generates a bid of $n, then another party should not be able to use this bid to produce a bid of $n + 1. Note that bid privacy does not necessarily imply bid non-malleability — indeed it is possible to design auction protocols that would hide a bid of $n while still allowing others to generate a related bid $n + 1.
These properties are crucial in many standard bidding processes. For example, a sealed bid auction is an auction where bidders submit private (sealed) bids in attempts to purchase property, selling to the highest bidder. Clearly, the ﬁrst bidder’s bid value must be kept secret from other potential bidders to prevent those bidders from having an unfair advantage. Similarly, bid malleability may allow a dishonest bidder Bob to present a bid just slightly over Alice’s bid, again, gaining an unfair advantage. Finally, the auction itself must be conducted correctly, awarding the item to the highest bidder for the amount of their bid.
A Vickrey auction is a type of sealed-bid auction where instead paying the value of their own bid, the highest bidder wins but the price paid is the value of the second-highest bid. This type of auction gives bidders an incentive to bid their true value, but requires privacy and non-malleability of each bid, and correctness in determining the winner and price.
MPC can be used to easily achieve all these features since it is only necessary to embed the desired properties into the function used to jointly execute the auction. All the participants can verify the function and then rely on the MPC protocol to provide high conﬁdence that the auction will be conducted conﬁdentially and fairly.

10

Introduction

Voting. Secure electronic voting, in a simple form, is simply computation of the addition function which tallies the vote. Privacy and non-malleability of the vote (properties discussed above in the context of auctions) are essential for similar technical reasons. Additionally, because voting is a fundamental civil process, these properties are often asserted by legislation.
As a side note, we remark that voting is an example of an application which may require properties not covered by the standard MPC security deﬁnitions. In particular, the property of coercion resistance is not standard in MPC (but can be formally expressed and achieved (Küsters et al., 2012)). The issue here is the ability of voters to prove to a third party how they voted. If such a proof is possible (e.g., a proof might exhibit the randomness used in generating the vote, which the adversary may have seen), then voter coercion is also possible. We don’t delve into the speciﬁc aspects of secure voting beyond listing it here as a natural application of MPC.
Secure machine learning. MPC can be used to enable privacy in both the inference and training phases of machine learning systems.
Oblivious model inference allows a client to submit a request to a server holding a pre-trained model, keeping the request private from the server S and the model private from the client C. In this setting, the inputs to the MPC are the private model from S, and the private test input from C, and the output (decoded only for C) is the model’s prediction. An example of recent work in this setting include MiniONN (Liu et al., 2017), which provided a mechanism for allowing any standard neural network to be converted to an oblivious model service using a combination of MPC and homomorphic encryption techniques.
In the training phase, MPC can be used to enable a group of parties to train a model based on their combined data without exposing that data. For the large scale data sets needed for most machine learning applications, it is not feasible to perform training across private data sets as a generic many-party computation. Instead, hybrid approaches have been designed that combine MPC with homomorphic encryption (Nikolaenko et al., 2013b; Gascón et al., 2017) or develop custom protocols to perform secure arithmetic operations eﬃciently (Mohassel and Zhang, 2017). These approaches can scale to data sets containing many millions of elements.

1.3. MPC Applications

11

Other applications. Many other interesting applications have been proposed for using MPC to enable privacy. A few examples include privacy-preserving network security monitoring (Burkhart et al., 2010), privacy-preserving genomics (Wang et al., 2015a; Jagadeesh et al., 2017), private stable matching (Doerner et al., 2016), contact discovery (Li et al., 2013; De Cristofaro et al., 2013), ad conversion (Kreuter, 2017), and spam ﬁltering on encrypted email (Gupta et al., 2017).
1.3.1 Deployments
Although MPC has seen much success as a research area and in experimental use, we are still in the early stages of deploying MPC solutions to real problems. Successful deployment of an MPC protocol to solve a problem involving independent and mutually distrusting data owners requires addressing a number of challenging problems beyond the MPC execution itself. Examples of these problems include building conﬁdence in the system that will execute the protocol, understanding what sensitive information might be inferred from the revealed output of the MPC, and enabling decision makers charged with protecting sensitive data but without technical cryptography background to understand the security implications of participating in the MPC.
Despite these challenges, there have been several successful deployments of MPC and a number of companies now focus on providing MPC-based solutions. We emphasize that in this early stage of MPC penetration and awareness, MPC is primarily deployed as an enabler of data sharing. In other words, organizations are typically not seeking to use MPC to add a layer of privacy in an otherwise viable application (we believe this is yet forthcoming). Rather, MPC is used to enable a feature or an entire application, which otherwise would not be possible (or would require trust in specialized hardware), due to the value of the shared data, protective privacy legislation, or mistrust of the participants.
Danish sugar beets auction. In what is widely considered to be the ﬁrst commercial application of MPC, Danish researchers collaborated with the Danish government and stakeholders to create an auction and bidding platform for sugar beet production contracts. As reported in Bogetoft et al. (2009), bid privacy and auction security were seen as essential for auction participants.

12

Introduction

The farmers felt that their bids reﬂected their capabilities and costs, which they did not want to reveal to Danisco, the only company in Denmark that processed sugar beets. At the same time, Danisco needed to be involved in the auction as the contracts were securities directly aﬀecting the company.
The auction was implemented as a three-party MPC among representatives for Danisco, the farmer’s association (DKS) and the researchers (SIMAP project). As explained by Bogetoft et al. (2009), a three party solution was selected, partly because it was natural in the given scenario, but also because it allowed using eﬃcient information theoretic tools such as secret sharing. The project led to the formation of a company, Partisia, that uses MPC to support auctions for industries such as spectrum and energy markets, as well as related applications such as data exchange (Gallagher et al., 2017).
Estonian students study. In Estonia, a country with arguably the most advanced e-government and technology awareness, alarms were raised about graduation rates of IT students. Surprisingly, in 2012, nearly 43% of IT students enrolled in the previous ﬁve years had failed to graduate. One potential explanation considered was that the IT industry was hiring too aggressively, luring students away from completing their studies. The Estonian Association of Information and Communication Technology wanted to investigate by mining education and tax records to see if there was a correlation. However, privacy legislation prevented data sharing across the Ministry of Education and the Tax Board. In fact, k-anonymity-based sharing was allowed, but it would have resulted in low-quality analysis, since many students would not have had suﬃciently large groups of peers with similar qualities.
MPC provided a solution, facilitated by the Estonian company Cybernetica using their Sharemind framework (Bogdanov et al., 2008a). The data analysis was done as a three-party computation, with servers representing the Estonian Information System’s Authority, the Ministry of Finance, and Cybernetica. The study, reported in Cybernetica (2015) and Bogdanov (2015), found that there was no correlation between working during studies and failure to graduate on time, but that more education was correlated with higher income.
Boston wage equity study. An initiative of the City of Boston and the Boston Women’s Workforce Council (BWWC) aims to identify salary inequities

1.3. MPC Applications

13

across various employee gender and ethnic demographics at diﬀerent levels of employment, from executive to entry-level positions. This initiative is widely supported by the Boston area organizations, but privacy concerns prevented direct sharing of salary data. In response, Boston University researchers designed and implemented a web-based MPC aggregation tool, which allowed employers to submit the salary data privately and with full technical and legal protection, for the purposes of the study.
As reported by Bestavros et al. (2017), MPC enabled the BWWC to conduct their analysis and produce a report presenting their ﬁndings. The eﬀort included a series of meetings with stakeholders to convey the risks and beneﬁts of participating in the MPC, and considered the importance of addressing usability and trust concerns. One indirect result of this work is inclusion of secure multi-party computation as a requirement in a bill for student data analysis recently introduced in the United States Senate (Wyden, 2017).
Key management. One of the biggest problems faced by organizations today is safeguarding sensitive data as it is being used. This is best illustrated using the example of authentication keys. This use case lies at the core of the product oﬀering of Unbound Tech (Unbound Tech, 2018). Unlike other uses of MPC where the goal is to protect data owned by multiple parties from exposure, here the goal is to protect from compromise the data owned by a single entity.
To enable a secure login facility, an organization must maintain private keys. Let’s consider the example of shared-key authentication, where each user has shared a randomly chosen secret key with the organization. Each time the user U authenticates, the organization’s server S looks up the database of keys and retrieves U’s public key skU , which is then used to authenticate and admit U to the network by running key exchange.
The security community has long accepted that it is nearly impossible to operate a fully secure complex system, and an adversary will be able to penetrate and stealthily take control over some of the network nodes. Such an advanced adversary, sometimes called Advanced Persistent Threat (APT), aims to quietly undermine the organization. Naturally, the most prized target for APT and other types of attackers is the key server.
MPC can play a signiﬁcant role in hardening the key server by splitting its functionality into two (or more) hosts, say, S1 and S2, and secret-sharing

14

Introduction

key material among the two servers. Now, an attacker must compromise both S1 and S2 to gain access to the keys. We can run S1 and S2 on two diﬀerent software stacks to minimize the chance that they will both be vulnerable to the exploit available to the malware, and operate them using two diﬀerent sub-organizations to minimize insider threats. Of course, routine execution does need access to the keys to provide authentication service; at the same time, key should never be reconstructed as the reconstructing party will be the target of the APT attack. Instead, the three players, S1, S2, and the authenticating user U, will run the authentication inside MPC, without ever reconstructing any secrets, thus removing the singular vulnerability and hardening the defense.
1.4 Overview
Because MPC is a vibrant and active research area, it is possible to cover only a small fraction of the most important work in this book. We mainly discuss generic MPC techniques, focusing mostly on the two-party scenario, and emphasizing a setting where all but one of the parties may be corrupted. In the next chapter, we provide a formal deﬁnition of secure multi-party computation and introduce security models that are widely-used in MPC. Although we do not include formal security proofs in this book, it is essential to have clear deﬁnitions to understand the speciﬁc guarantees that MPC provides. Chapter 3 describes several fundamental MPC protocols, focusing on the most widely-used protocols that resist any number of corruptions. Chapter 4 surveys techniques that have been developed to enable eﬃcient implementations of MPC protocols, and Chapter 5 describes methods that have been used to provide sub-linear memory abstractions for MPC.
Chapters 3–5 target the weak semi-honest adversary model for MPC (deﬁned in Chapter 2), in which is it assumed that all parties follow the protocol as speciﬁed. In Chapter 6, we consider how MPC protocols can be hardened to provide security against active adversaries, and Chapter 7 explores some alternative threat models that enable trade-oﬀs between security and eﬃciency. We conclude in Chapter 8, outlining the trajectory of MPC research and practice, and suggesting possible directions for the future.

2
Deﬁning Multi-Party Computation
In this chapter, we introduce notations and conventions we will use throughout, deﬁne some basic cryptographic primitives, and provide a security deﬁnition for multi-party computation. Although we will not focus on formal security proofs or complete formal deﬁnitions, it is important to have clear security deﬁnitions to understand exactly what properties protocols are designed to provide. The protocols we discuss in later chapters have been proven secure based on these deﬁnitions.
2.1 Notations and Conventions
We will abbreviate Secure Multi-Party Computation as MPC, and will use it to denote secure computation among two or more participants. The term secure function evaluation (SFE) is often used to mean the same thing, although it can also apply to contexts where only one party provides inputs to a function that is evaluated by an outsourced server. Because two-party MPC is an important special case, which received a lot of targeted attention, and because two-party protocols are often signiﬁcantly diﬀerent from the general n-party case, we will use 2PC to emphasize this setting when needed.
We assume existence of direct secure channels between each pairs of
15

16

Deﬁning Multi-Party Computation

participating players. Such channels could be achieved inexpensively through
a variety of means, and are out of scope in this book. We denote encryption and decryption of a message m under key k as
Enck(m) and Deck(m). We will refer to protocol participants interchangeably also as parties or players, and will usually denote them as P1, P2, etc. We will denote the adversary by A.
A negligible function ν : N → R is any function that approaches zero
asymptotically faster than any inverse polynomial. In other words, for any polynomial p, ν(n) < 1/p(n) for all but ﬁnitely many n.
We will denote computational and statistical security parameters by κ and σ respectively. The computational security parameter κ governs the hardness
of problems that can be broken by an adversary’s oﬄine computation — e.g., breaking an encryption scheme. In practice κ is typically set to a value like
128 or 256. Even when we consider security against computationally bounded
adversaries, there may be some attacks against an interactive protocol that are
not made easier by oﬄine computation. For example, the interactive nature of
a protocol may give the adversary only a single opportunity to violate security
(e.g., by sending a message that has a special property, like predicting the
random value that an honest party will chose in the next round). The statistical security parameter σ governs the hardness of these attacks. In practice, σ is
typically set to a smaller value like 40 or 80. The correct way to interpret
the presence of two security parameters is that security is violated only with probability 2−σ + ν(κ), where ν is a negligible function that depends on the resources of the adversary. When we consider computationally unbounded adversaries, we omit κ and require ν = 0.
We will use symbol ∈R to denote uniformly random sampling from a distribution. For example we write “choose k ∈R {0, 1}κ” to mean that k is a uniformly chosen κ-bit long string. More generally, we write “v ∈R D” to denote sampling according to a probability distribution D. Often the distribution in question is the output of a randomized algorithm. We write “v ∈R A(x)” to denote that v is the result of running randomized algorithm A on input x.
Let D1 and D2 be two probability distributions indexed by a security parameter, or equivalently two algorithms that each take a security parameter as input.1 We say that D1 and D2 are indistinguishable if, for all algorithms A
1In the literature, D1 and D2 are often referred to as an ensemble of distributions.

2.2. Basic Primitives

17

there exists a negligible function ν such that:
Pr[A(D1(n)) = 1] − Pr[A(D2(n)) = 1] ≤ ν(n)
In other words, no algorithm behaves more than negligibly diﬀerently when given inputs sampled according to D1 vs D2. When we consider only nonuniform, polynomial-time algorithms A, the deﬁnition results in computational indistinguishability. When we consider all algorithms without regard to their computational complexity, we get a deﬁnition of statistical indistinguishability. In that case, the probability above is bounded by the statistical distance (also known as total variation distance) of the two distributions, which is deﬁned as:
∆(D1(n), D2(n)) = 1 Pr[x = D1(n)] − Pr[x = D2(n)] 2x
Throughout this work, we use computational security to refer to security against adversaries implemented by non-uniform, polynomial-time algorithms. We use information-theoretic security (also known as unconditional or statistical security) to mean security against arbitrary adversaries (even those with unbounded computational resources).

2.2 Basic Primitives

Here, we provide deﬁnitions of a few basic primitives we use in our presentation. Several other useful primitives are actually special cases of MPC (i.e., they are deﬁned as MPC of speciﬁc functions). These are deﬁned in Section 2.4.

Secret Sharing. Secret sharing is an essential primitive, that is at the core of many MPC approaches. Informally, a (t, n)-secret sharing scheme splits the secret s into n shares, such that any t − 1 of the shares reveal no information about s, while any t shares allow complete reconstruction of the secret s. There
are many variants of possible security properties of secret sharing schemes;
we provide one deﬁnition, adapted from Beimel and Chor (1993), next.

Deﬁnition 2.1. Let D be the domain of secrets and D1 be the domain of

shares.

Let

Shr

:

D

→

Dn
1

be

a

(possibly

randomized)

sharing

algorithm,

and

Rec

:

Dk
1

→

D

be

a

reconstruction

algorithm.

A

(t,

n)-secret

sharing

scheme

is a pair of algorithms (Shr, Rec) that satisﬁes these two properties:

18

Deﬁning Multi-Party Computation

• Correctness. Let (s1, s2, . . . , sn) = Shr(s). Then,
Pr[∀k ≥ t, Rec(si1, . . . , sik ) = s] = 1.
• Perfect Privacy. Any set of shares of size less than t does not reveal anything about the secret in the information theoretic sense. More formally, for any two secrets a, b ∈ D and any possible vector of shares v = v1, v2, ..., vk, such that k < t,
Pr[v = Shr(a)|k] = Pr[v = Shr(b)|k],
where |k denotes appropriate projection on a subspace of k elements.
In many of our discussions we will use (n, n)-secret sharing schemes, where all n shares are necessary and suﬃcient to reconstruct the secret.
Random Oracle. Random Oracle (RO) is a heuristic model for the security of hash functions, introduced by Bellare and Rogaway (1993). The idea is to treat the hash function as a public, idealized random function. In the random oracle model, all parties have access to the public function H : {0, 1}∗ → {0, 1}κ, implemented as a stateful oracle. On input string x ∈ {0, 1}∗, H looks up its history of calls. If H(x) had never been called, H chooses a random rx ∈ {0, 1}κ, remembers the pair x, rx and returns rx. If H(x) had been called before, H returns rx. In this way, the oracle realizes a randomly-chosen function {0, 1}∗ → {0, 1}κ.
The random oracle model is a heuristic model, because it captures only those attacks that treat the hash function H as a black-box. It deviates from reality in that it models a public function (e.g., a standardized hash function like SHA-256) as an inherently random object. In fact, it is possible to construct (extremely contrived) schemes that are secure in the random oracle model, but which are insecure whenever H is instantiated by any concrete function (Canetti et al., 1998).
Despite these shortcomings, the random oracle model is often considered acceptable for practical applications. Assuming a random oracle often leads to signiﬁcantly more eﬃcient constructions. In this work we will be careful to state when a technique relies on the random oracle model.

2.3. Security of Multi-Party Computation

19

2.3 Security of Multi-Party Computation
Informally, the goal of MPC is for a group of participants to learn the correct output of some agreed-upon function applied to their private inputs without revealing anything else. We now provide a more formal deﬁnition to clarify the security properties MPC aims to provide. First, we present the real-ideal paradigm which forms the conceptual core of deﬁning security. Then we discuss two diﬀerent adversary models commonly used for MPC. Finally, we discuss issues of composition—namely, whether security preserved in the natural way when a secure protocol invokes another subprotocol.
2.3.1 Real-Ideal Paradigm
A natural way to deﬁne security is to come up with a kind of a “laundry list” of things that constitute a violation of security. For example, the adversary should not be able to learn a certain predicate of another party’s input, the adversary should not be able to induce impossible outputs for the honest parties, and the adversary should not be able to make its inputs depend on honest parties’ inputs. Not only is this a tedious approach, but it is cumbersome and error-prone. It is not obvious when the laundry list could be considered complete.
The real-ideal paradigm avoids this pitfall completely by introducing an “ideal world” that implicitly captures all security guarantees, and deﬁning security in relation to this ideal world. Although they used diﬀerent terminology, the deﬁnition of probabilistic encryption by Goldwasser and Micali (1984) is widely considered to be the ﬁrst instance of using this approach to deﬁne and prove security.
Ideal World. In the ideal world, the parties securely compute the function F by privately sending their inputs to a completely trusted party T , referred to as the functionality. Each party Pi has an associated input xi, which is sent to T , who simply computes F (x1, . . . , xn) and returns the result to all parties. Often we will make a distinction between F as a trusted party (functionality) and the circuit C that such a party computes on the private inputs.
We can imagine an adversary attempting to attack the ideal-world interaction. An adversary can take control over any of the parties Pi, but not T (that is the sense in which T is described as a trusted party). The simplicity

20

Deﬁning Multi-Party Computation

of the ideal world makes it easy to understand the eﬀect of such an attack. Considering our previous laundry list: the adversary clearly learns no more than F (x1, . . . , xn) since that is the only message it receives; the outputs given to the honest parties are all consistent and legal; the adversary’s choice of inputs is independent of the honest parties’.
Although the ideal world is easy to understand, the presence of a fullytrusted third party makes it imaginary. We use the ideal world as a benchmark against which to judge the security of an actual protocol.
Real World. In the real world, there is no trusted party. Instead, all parties communicate with each other using a protocol. The protocol π speciﬁes for each party Pi a “next-message” function πi. This function takes as input a security parameter, the party’s private input xi, a random tape, and the list of messages Pi has received so far. Then, πi outputs either a next message to send along with its destination, or else instructs the party to terminate with some speciﬁc output.
In the real world, an adversary can corrupt parties—corruption at the beginning of the protocol is equivalent to the original party being an adversary. Depending on the threat model (discussed next), corrupt parties may either follow the protocol as speciﬁed, or deviate arbitrarily in their behavior.
Intuitively speaking, the real world protocol π is considered secure if any eﬀect that an adversary can achieve in the real world can also be achieved by a corresponding adversary in the ideal world. Put diﬀerently, the goal of a protocol is to provide security in the real world (given a set of assumptions) that is equivalent to that in the ideal world.
2.3.2 Semi-Honest Security
A semi-honest adversary is one who corrupts parties but follows the protocol as speciﬁed. In other words, the corrupt parties run the protocol honestly but they may try to learn as much as possible from the messages they receive from other parties. Note that this may involve several colluding corrupt parties pooling their views together in order to learn information. Semi-honest adversaries are also considered passive in that they cannot take any actions other than attempting to learn private information by observing a view of a protocol execution. Semi-honest adversaries are also commonly called honest-but-curious.

2.3. Security of Multi-Party Computation

21

The view of a party consists of its private input, its random tape, and the list of all messages received during the protocol. The view of an adversary consists of the combined views of all corrupt parties. Anything an adversary learns from running the protocol must be an eﬃciently computable function of its view. That is, without loss of generality we need only consider an “attack” in which the adversary simply outputs its entire view.
Following the real-ideal paradigm, security means that such an “attack” can also be carried out in the ideal world. That is, for a protocol to be secure, it must be possible in the ideal world to generate something indistinguishable from the real world adversary’s view. Note that the adversary’s view in the ideal world consists of nothing but inputs sent to T and outputs received from T . So, an ideal-world adversary must be able to use this information to generate what looks like a real-world view. We refer to such an ideal-world adversary as a simulator, since it generates a “simulated” real-world view while in the ideal-world itself. Showing that such a simulator exists proves that there is nothing an adversary can accomplish in the real world that could not also be done in the ideal world.
More formally, let π be a protocol and F be a functionality. Let C be the set of parties that are corrupted, and let Sim denote a simulator algorithm. We deﬁne the following distributions of random variables:
• Realπ(κ, C; x1, . . . , xn): run the protocol with security parameter κ, where each party Pi runs the protocol honestly using private input xi. Let Vi denote the ﬁnal view of party Pi, and let yi denote the ﬁnal output of party Pi. Output {Vi | i ∈ C}, (y1, . . . , yn).
• IdealF,Sim(κ, C; x1, . . . , xn): Compute (y1, . . . , yn) ← F (x1, . . . , xn). Output Sim(C, {(xi, yi) | i ∈ C}), (y1, . . . , yn).
A protocol is secure against semi-honest adversaries if the corrupted parties in the real world have views that are indistinguishable from their views in the ideal world:
Deﬁnition 2.2. A protocol π securely realizes F in the presence of semi-honest adversaries if there exists a simulator Sim such that, for every subset of corrupt parties C and all inputs x1, . . . , xn, the distributions
Realπ(κ, C; x1, . . . , xn)

22

Deﬁning Multi-Party Computation

and IdealF,Sim (κ, C; x1, . . . , xn)
are indistinguishable (in κ).
In deﬁning Real and Ideal we have included the outputs of all parties, even the honest ones. This is a way of incorporating a correctness condition into the deﬁnition. In the case that no parties are corrupt (C = ∅), the output of Real and Ideal simply consists of all parties’ outputs in the two interactions. Hence, the security deﬁnition implies that protocol gives outputs which are distributed just as their outputs from the ideal functionality (and this is true even when F is randomized). Because the distribution of y1, . . . , yn in Real does not depend on the set C of corrupted parties (no matter who is corrupted, the parties all run honestly), it is not strictly necessary to include these values in the case of C ∅, but we choose to include it to have a uniﬁed deﬁnition.
The semi-honest adversary model may at ﬁrst glance seem exceedingly weak—simply reading and analyzing received messages barely even seems like an attack at all! It is reasonable to ask why such a restrictive adversary model is worth considering at all. In fact, achieving semi-honest security is far from trivial and, importantly, semi-honest protocols often serve as a basis for protocols in more robust settings with powerful attackers. Additionally, many realistic scenarios do correspond to semi-honest attack behavior. One such example is computing with players who are trusted to act honestly, but cannot fully guarantee that their storage might not be compromised in the future.
2.3.3 Malicious Security
A malicious (also known as active) adversary may instead cause corrupted parties to deviate arbitrarily from the prescribed protocol in an attempt to violate security. A malicious adversary has all the powers of a semi-honest one in analyzing the protocol execution, but may also take any actions it wants during protocol execution. Note that this subsumes an adversary that can control, manipulate, and arbitrarily inject messages on the network (even through throughout this book we assume direct secure channels between each pair of parties). As before, security in this setting is deﬁned in comparison to the ideal world, but there are two important additions to consider:

2.3. Security of Multi-Party Computation

23

Eﬀect on honest outputs. When the corrupt parties deviate from the protocol, there is now the possibility that honest parties’ outputs will be aﬀected. For example, imagine an adversary that causes two honest parties to output diﬀerent things while in the ideal world all parties get identical outputs. This condition is somewhat trivialized in the previous deﬁnition — while the deﬁnition does compare real-world outputs to ideal-world outputs, these outputs have no dependence on the adversary (set of corrupted parties). Furthermore, we can/should make no guarantees on the ﬁnal outputs of corrupt parties, only of the honest parties, since a malicious party can output whatever it likes.
Extraction. Honest parties follow the protocol according to a well-deﬁned input, which can be given to T in the ideal world as well. In contrast, the input of a malicious party is not well-deﬁned in the real world, which leads to the question of what input should be given to T in the ideal world. Intuitively, in a secure protocol, whatever an adversary can do in the real world should also be achievable in the ideal world by some suitable choice of inputs for the corrupt parties. Hence, we leave it to the simulator to choose inputs for the corrupt parties. This aspect of simulation is called extraction, since the simulator extracts an eﬀective ideal-world input from the real-world adversary that “explains” the input’s real-world eﬀect. In most constructions, it is suﬃcient to consider black-box simulation, where the simulator is given access only to the oracle implementing the real-world adversary, and not its code.
When A denotes the adversary program, we write corrupt(A) to denote the set of parties that are corrupted, and use corrupt(Sim) for the set of parties that are corrupted by the ideal adversary, Sim. As we did for the semi-honest security deﬁnition, we deﬁne distributions for the real world and ideal world, and deﬁne a secure protocol as one that makes those distributions indistinguishable:
• Realπ, A(κ; {xi | i corrupt(A)}): run the protocol on security parameter κ, where each honest party Pi (for i corrupt(A)) runs the protocol honestly using given private input xi, and the messages of corrupt parties are chosen according to A (thinking of A as a protocol next-message function for a collection of parties). Let yi denote the output of each

24

Deﬁning Multi-Party Computation

honest party Pi and let Vi denote the ﬁnal view of party Pi. Output ({Vi | i ∈ corrupt(A)}, {yi | i corrupt(A)}).
• IdealF,Sim(κ; {xi | i corrupt(A)}): Run Sim until it outputs a set of inputs {xi | i ∈ corrupt(A)}. Compute (y1, . . . , yn) ← F (x1, . . . , xn). Then, give {yi | i ∈ corrupt(A)} to Sim.2 Let V∗ denote the ﬁnal output of Sim (a set of simulated views). Output (V∗, {yi | i corrupt(Sim)}).

Deﬁnition 2.3. A protocol π securely realizes F in the presence of malicious adversaries if for every real-world adversary A there exists a simulator Sim with corrupt(A) = corrupt(Sim) such that, for all inputs for honest parties {xi | i corrupt(A)}, the distributions
Realπ, A(κ; {xi | i corrupt(A)})

and IdealF,Sim (κ; {xi | i
are indistinguishable (in κ).

corrupt(Sim)})

Note that the deﬁnition quantiﬁes only over the inputs of honest parties {xi | i corrupt(A)}. The interaction Real does not consider the corrupt parties to have any inputs, and the inputs of the corrupt parties in Sim is only determined indirectly (by the simulator’s choice of what to send to F on the corrupt parties’ behalf). While it would be possible to also deﬁne inputs for corrupt parties in the real world, such inputs would merely be “suggestions” since corrupt parties could choose to run the protocol on any other input (or behave in a way that is inconsistent with all inputs).

Reactive functionalities. In the ideal world, the interaction with the func-
tionality consists of just a single round: inputs followed by outputs. It is possible to generalize the behavior of F so that it interacts with the parties over many
rounds of interaction, keeping its own private internal state between rounds. Such functionalities are called reactive.
2To be more formal, we can write the simulator Sim as a pair of algorithms Sim = (Sim1, Sim2) which capture this two-phase process. Sim1 (on input κ) outputs {xi | i ∈ corrupt(A)} and arbitrary internal state Σ. Then Sim2 takes input Σ and {yi | i ∈ corrupt(A)}, and gives output V∗.

2.3. Security of Multi-Party Computation

25

One example of a reactive functionality is as the dealer in a poker game. The functionality must keep track of the state of all cards, taking input commands and giving outputs to all parties in many rounds.
Another example is an extremely common functionality called commitment. This functionality accepts a bit b (or more generally, a string) from P1 and gives output “committed” to P2, while internally remembering b. At some later time, if P1 sends the command “reveal” (or “open”) to the functionality, it gives b to P2.
Security with abort. In any message-based two-party protocol, one party will learn the ﬁnal output before the other. If that party is corrupt and malicious, they may simply refuse to send the last message to the honest party and thereby prevent the honest party from learning the output. However, this behavior is incompatible with our previous description of the ideal world. In the ideal world, if corrupt parties receive output from the functionality then all parties do. This property is called output fairness and not all functions can be computed with this property (Cleve, 1986; Gordon et al., 2008; Asharov et al., 2015a).
Typical results in the malicious setting provide a weaker property known as security with abort, which requires slightly modifying the ideal functionality as follows. First, the functionality is allowed to know the identities of the corrupt parties. The functionality’s behavior is modiﬁed to be slightly reactive: after all parties have provided input, the functionality computes outputs and delivers the outputs to the corrupt parties only. Then the functionality awaits either a “deliver” or “abort” command from the corrupted parties. Upon receiving “deliver”, the functionality delivers the outputs to all the honest parties. Upon receiving “abort”, the functionality delivers an abort output (⊥) to all the honest parties.
In this modiﬁed ideal world, an adversary is allowed to learn the output before the honest parties and to prevent the honest parties from receiving any output. It is important to note, however, that whether an honest party aborts can depend only on the corrupt party’s outputs. In particular, it would violate security if the honest party’s abort probability depends on its own input.
Usually the possibility of blocking outputs to honest parties is not written explicitly in the description of the functionality. Instead, it is generally understood that when discussing security against malicious adversaries, the

26

Deﬁning Multi-Party Computation

adversary has control over output delivery to honest parties and output fairness is not expected.
Adaptive corruption. We have deﬁned both the real and ideal worlds so that the identities of the corrupted parties are ﬁxed throughout the entire interaction. This provides what is known as security against static corruption. It is also possible to consider scenarios where an adversary may choose which parties to corrupt during the protocol execution, possibly based on what it learns during the interaction. This behavior is known as adaptive corruption.
Security against adaptive corruption can be modeled in the real-ideal paradigm, by allowing the adversary to issue a command of the form “corrupt Pi”. In the real world, this results in the adversary learning the current view (including private randomness) of Pi and subsequently taking over control of its protocol messages. In the ideal world, the simulator learns only the input and outputs of the party upon corruption, and must use this information to generate simulated views. Of course, the views of parties are correlated (if Pi sends a message to Pj, then that message is included in both parties’ views). The challenge of adaptive security is that the simulator must produce views piece-by-piece. For example, the simulator may be asked to produce a view of Pi when that party is corrupted. Any messages sent by Pj to Pi must be simulated without knowledge of Pj’s private input. Later, the simulator might be asked to provide a view of Pj (including its private randomness) that “explains” its protocol messages as somehow consistent with whatever private input it had.
In this work we consider only static corruption, following the vast majority of work in this ﬁeld.
2.3.4 Hybrid Worlds and Composition
In the interest of modularity, it is often helpful to design protocols that make use of other ideal functionalities. For example, we may design a protocol π that securely realizes some functionality F , where the parties of π also interact with another functionality G in addition to sending messages to each other. Hence, the real world for this protocol includes G, while the ideal world (as usual) includes only F . We call this modiﬁed real world the G-hybrid world.

2.3. Security of Multi-Party Computation

27

A natural requirement for a security model is composition: if π is a Ghybrid protocol that securely realizes F (i.e., parties in π send messages and also interact with an ideal G), and ρ is a protocol that securely realizes G, then composing π and ρ in the natural way (replacing every invocation of G with a suitable invocation of ρ) also results in a secure protocol for F . While we have not deﬁned all of the low-level details of a security model for MPC, it may be surprising that some very natural ways of specifying the details do not guarantee composability of secure protocols!
The standard way of achieving guaranteed composition is to use the universal composability (UC) framework from Canetti (2001). The UC framework augments the security model that we have sketched here with an additional entity called the environment, which is included in both the ideal and real worlds. The purpose of the environment is to capture the “context” in which the protocol executes (e.g., the protocol under consideration is invoked as a small step in some larger calling protocol). The environment chooses inputs for the honest party and receives their outputs. It also may interact arbitrarily with the adversary.
The same environment is included in the real and ideal worlds, and its “goal” is to determine whether it is instantiated in the real or ideal world. Previously we deﬁned security by requiring certain real and ideal views to be indistinguishable. In this setting, we can also absorb any distinguisher of these views into the environment itself. Hence, without loss of generality, the environment’s ﬁnal output can be just a single bit which can be interpreted as the environment’s “guess” of whether it is instantiated in the real or ideal world.
Next, we deﬁne the real and ideal executions, where Z is an environment:
• Realπ, A,Z (κ): run an interaction involving adversary A and environment Z. When Z generates an input for an honest party, the honest party runs protocol π, and gives its output to Z. Finally, Z outputs a single bit, which is taken as the output of Realπ, A,Z (κ).
• IdealF,Sim,Z (κ): run an interaction involving adversary (simulator) Sim and environment Z. When Z generates an input for an honest party, the input is passed directly to functionality F and the corresponding output is given to Z (on behalf of that honest party). The output bit of Z is taken as the output of IdealF,Sim,Z (κ).

28

Deﬁning Multi-Party Computation

Deﬁnition 2.4. A protocol π UC-securely realizes F if for all real-world adversaries A there exists a simulator Sim with corrupt(A) = corrupt(Sim) such that, for all environments Z:
Pr[Realπ, A,Z (κ) = 1] − Pr[IdealF,Sim,Z (κ) = 1] is negligible (in κ).
Since the deﬁnition quantiﬁes over all environments, we can always consider absorbing the adversary A into the environment Z, so that what is left over is the so-called “dummy adversary” (which simply forwards protocol messages as instructed by Z).
In other (non UC-composable) security models, the ideal-world adversary (simulator) can depend arbitrarily on the real-world adversary. In particular, the simulator can do things like internally run the adversary and repeatedly rewind that adversary to a previous internal state. Many protocols are proven in these weaker model where the composability may be restricted. Sequential composition security (i.e., security for protocols which call functionalities in a sequential manner) holds for all protocols discussed in this book.
In the UC model such rewinding is not possible since the adversary can be assumed to be absorbed into the environment, and the simulator is not allowed to depend on the environment. Rather, the simulator must be a straight-line simulator: whenever the environment wishes to send a protocol message, the simulator must reply immediately with a simulated response. A straight-line simulator must generate the simulated transcript in one pass, whereas the previous deﬁnitions allowed for the simulated transcript or view to be generated without any restrictions. Assuming the other primitives such as oblivious transfer (Section 2.4) and commitments (Section 2.4) used in these protocols provide UC-security, the malicious secure protocols described in this book are all UC-secure.
2.4 Speciﬁc Functionalities of Interest
Here, we deﬁne several functionalities that have been identiﬁed as particularly useful building blocks for building MPC protocols.
Oblivious Transfer. Oblivious Transfer (OT) is an essential building block for secure computation protocols. It is theoretically equivalent to MPC as

2.4. Speciﬁc Functionalities of Interest

29

P

:

1. Two parties: Sender S and Receiver R. S has two secrets, x0, x1 ∈ {0, 1}n, and R has a selection bit, b ∈ {0, 1}.

F

:

• R sends b to F OT, S sends x0, x1 to F OT. • R receives xb, S receives ⊥.
Figure 2.1: 1-out-of-2 OT functionality F OT.

shown by Kilian (1988): given OT, one can build MPC without any additional assumptions, and, similarly, one can directly obtain OT from MPC.
The standard deﬁnition of 1-out-of-2 OT involves two parties, a Sender S holding two secrets x0, x1 and a receiver R holding a choice bit b ∈ {0, 1}. OT is a protocol allowing R to obtain xb while learning nothing about the “other” secret x1−b. At the same time, S does not learn anything at all. More formally:
Deﬁnition 2.5. A 1-out-of-2 OT is a cryptographic protocol securely implementing the functionality F OT of Figure 2.1.
Many variants of OT may be considered. A natural variant is 1-out-of-k OT, in which S holds k secrets, and R has a choice selector in {0, . . . , k − 1}. We discuss protocols for implementing OT eﬃciently in Section 3.7.
Commitment. Commitment is a fundamental primitive in many cryptographic protocols. A commitment scheme allows a sender to commit to a secret value, and reveal it at some later time to a receiver. The receiver should learn nothing about the committed value before it is revealed by the sender (a property referred to as hiding), while the sender should not be able to change its choice of value after committing (the binding property).
Commitment is rather simple and inexpensive in the random oracle model. To commit to x, simply choose a random value r ∈R {0, 1}κ and publish the value y = H(x r). To later reveal, simply announce x and r.

30

Deﬁning Multi-Party Computation

P

:

1. Two parties: Sender S and Receiver R. S has a string s ∈ {0, 1}n.

F

:

• S sends s to F Comm. F Comm sends committed to R. • At some later time, S sends open to F Comm, and F Comm sends s to R.

Figure 2.2: Commitment functionality F Comm.

P

:

1. Two parties: Prover P and Veriﬁer V.

F

:

• P sends (C, x) to F zk, where C : {0, 1}n → {0, 1} is a Boolean circuit with 1 output bit, and x ∈ {0, 1}n. If C(x) = 1 then F zk sends (proven, C) to V. Otherwise, it sends ⊥ to V.

Figure 2.3: Zero-knowledge proof functionality F zk.

Deﬁnition 2.6. Commitment is a cryptographic protocol securely implementing the functionality F Comm of Figure 2.2.
Zero-Knowledge Proof. A zero-knowledge (ZK) proof allows a prover to convince a veriﬁer that it knows x such that C(x) = 1, without revealing any further information about x. Here C is a public predicate.
As a simple example, suppose G is a graph and that Alice knows a 3coloring χ for G. Then Alice can use a ZK proof to convince Bob that G is 3-colorable. She constructs a circuit CG that interprets its input as an encoding of a 3-coloring and checks whether it is a legal 3-coloring of G. She uses (CG, χ) as input to the ZK proof. From Bob’s point of view, he receives output (proven, CG) if and only if Alice was able to provide a valid 3-coloring of G. At the same time, Alice knows that Bob learned nothing about her 3-coloring

2.5. Further Reading

31

χ other than the fact that some legal χ exists.
Deﬁnition 2.7. A zero-knowledge proof is a cryptographic protocol implementing the functionality F zk of Figure 2.3.
There are several variants of ZK proofs identiﬁed in the literature. Our speciﬁc variant is more precisely a zero-knowledge argument of knowledge. The distinctions between these variants are not crucial for the level of detail we explore in this book.
2.5 Further Reading
The real-ideal paradigm was ﬁrst applied in the setting of MPC by Goldwasser et al. (1985), for the special case of zero-knowledge. Shortly thereafter the deﬁnition was generalized to arbitrary MPC by Goldreich et al. (1987). These deﬁnitions contain the important features of the real-ideal paradigm, but resulted in a notion of security (against malicious adversaries) that was not preserved under composition. In other words, a protocol could be secure according to these models when executed in isolation, but may be totally insecure when two protocol instances are run concurrently.
The deﬁnition of security that we have sketched in this book is the Universal Composition (UC) framework of Canetti (2001). Protocols proven secure in the UC framework have the important composition property described in Section 2.3.4, which in particular guarantees security of a protocol instance no matter what other protocols are executing concurrently. While the UC framework is the most popular model with this property, there are other models with similar guarantees (Pﬁtzmann and Waidner, 2000; Hofheinz and Shoup, 2011). The details of all such security models are extensive and subtle. However, a signiﬁcantly simpler model is presented by Canetti et al. (2015), which is equivalent to the full UC model for the vast majority of cases. Some of the protocols we describe are secure in the random oracle model. Canetti et al. (2014) describe how to incorporate random oracles into the UC framework.
Our focus in this book is on the most popular security notions — namely, semi-honest security and malicious security. The literature contains many variations on these security models, and some are a natural ﬁt for real-world applications. We discuss some alternative security models in Chapter 7.

3
Fundamental MPC Protocols

In this chapter we survey several important MPC approaches, covering the main protocols and presenting the intuition behind each approach.
All of the approaches discussed can be viewed as a form of computing under encryption, or, more speciﬁcally, as secret-sharing the input data and computing on the shares. For example, an encryption Enck(m) of a message m with a key k can be seen as secret-sharing m, where one share is k and the other is Enck(m). We present several fundamental protocols illustrating a variety of generic approaches to secure computation, as summarized in Table 3.1. All of the protocols of this section target the semi-honest adversary model (Section 2.3.2). We discuss malicious-secure variants in Chapter 6. All of these

protocol Yao’s GC (Section 3.1) GMW (Section 3.2) BGW (Section 3.3) BMR (Section 3.5) GESS (Section 3.6)

# parties 2 many many many 2

# rounds constant circuit depth circuit depth constant constant

circuit Boolean Boolean or arithmetic Boolean or arithmetic Boolean Boolean formula

Table 3.1: Summary of semi-honest MPC protocols discussed in this chapter.

32

3.1. Yao’s Garbled Circuits Protocol

33

protocols build on oblivious transfer, which we discuss how to implement eﬃciently in Section 3.7.
3.1 Yao’s Garbled Circuits Protocol
Yao’s Garbled Circuits protocol (GC) is the most widely known and celebrated MPC technique. It is usually seen as best-performing, and many of the protocols we cover build on Yao’s GC. While not having the best known communication complexity, it runs in constant rounds and avoids the costly latency associated with approaches, such as GMW (described in Section 3.2), where the number of communication rounds scales with the circuit depth.
3.1.1 GC Intuition
The main idea behind Yao’s GC approach is quite natural. Recall, we wish to evaluate a given function F (x, y) where party P1 holds x ∈ X and P2 holds y ∈ Y . Here X and Y are the respective domains for the inputs of P1 and P2.
Function as a look-up table. First, let’s consider a function F for which the input domain is small and we can eﬃciently enumerate all possible input pairs, (x, y). The function F can be represented as a look-up table T, consisting of |X | · |Y | rows, Tx,y = F (x, y) . The output of F (x, y) is obtained simply by retrieving Tx,y from the corresponding row.
This gives us an alternative (and much simpliﬁed!) view of the task at hand. Evaluating a look-up table can be done as follows. P1 will encrypt T by assigning a randomly-chosen strong key to each possible input x and y. That is, for each x ∈ X and each y ∈ Y , P1 will choose kx ∈R {0, 1}κ and ky ∈R {0, 1}κ. It will then encrypt T by encrypting each element Tx,y of T with both keys kx and ky, and send the encrypted (and randomly permuted!) table Enckx,ky (Tx,y) to P2.
Now our task is to enable P2 to decrypt (only) the entry Tx,y corresponding to players’ inputs. This is done by having P1 send to P2 the keys kx and ky. P1 knows its input x, and hence simply sends key kx to P2. The key ky is sent to P2 using a 1-out-of-|Y | Oblivious Transfer (Section 2.4). Once P2 receives kx and ky, it can obtain the output F (x, y) by decrypting Tx,y using those keys. Importantly, no other information is obtained by P2. This is because P2 only

34

Fundamental MPC Protocols

has a single pair of keys, which can only be used to open (decrypt) a single
table entry. We stress that, in particular, it is important that neither partial key, kx or ky, by itself can be used to obtain partial decryptions or even determine whether the partial key was used in the obtaining a speciﬁc encryption.1

Point-and-Permute. A careful reader may wonder how P2 knows which row of the table T to decrypt, as this information is dependent on the inputs of both

parties, and, as such, is sensitive.

The simplest way to address this is to encode some additional information

in the encrypted elements of T. For example, P1 may append a string of σ zeros

to each row of T. Decrypting the wrong row will produce an entry which has

low

probability

(p

=

1 2σ

)

of

ending

with

σ

zeros,

and

hence

will

be

rejected

by P2.

While the above approach works, it is ineﬃcient for P2, who expects to

need to decrypt half of the rows of the table T. A much better approach, often

called point-and-permute,2 was introduced by Beaver et al. (1990). The idea is

to interpret part of the key (namely, the last log |X | bits of the ﬁrst key and

the last log |Y | bits of the second key) as a pointer to the permuted table T,

where the encryption will be placed. To avoid collisions in table row allocation, P1 must ensure that the pointer bits don’t collide within the space of keys kx or within the space of ky; this can be done in a number of ways. Finally, strictly

speaking, key size must be maintained to achieve the corresponding level of

security. As a consequence, rather than viewing key bits as a pointer, players

will append the pointer bits to the key and maintain the desired key length.

In the subsequent discussions, we assume that the evaluator knows which

row to decrypt. In protocol presentations, we may or may not explicitly include

the point-and-permute component, depending on context.

1Consider a counter-example. Suppose P2 was able to determine that a key kx that it received from P1 was used in encrypting rx rows. Because some input combinations may be invalid, the encrypted look-up table T may have a unique number of rows relying on kx, which will reveal x to P2, violating the required security guarantees.
2This technique was not given a name by Beaver et al. (1990). Rather, this name came
to be widely used by the community around 2010, as GC research progressed and need for a name arose. This technique is diﬀerent from the permute and point technique introduced and
coined in the information-theoretic garbled circuit construction of Kolesnikov (2005), which
we discuss in Section 3.6.

3.1. Yao’s Garbled Circuits Protocol

35

Managing look-up table size. Clearly, the above solution is ineﬃcient as it scales linearly with the domain size of F . At the same time, for small functions,
such as those deﬁned by a single Boolean circuit gate, the domain has size 4,
so using a look-up table is practical. The next idea is to represent F as a Boolean circuit C and evaluate each
gate using look-up tables of size 4. As before, P1 generates keys and encrypts look-up tables, and P2 applies decryption keys without knowing what each key corresponds to. However, in this setting, we cannot reveal the plaintext output
of intermediate gates. This can be hidden by making the gate output also a key whose corresponding value is unknown to the evaluator, P2.
For each wire wi of C, P1 assigns two keys ki0 and ki1, corresponding to the two possible values on the wire. We will refer to these keys as wire labels, and to the plaintext wire values simply as wire values. During the execution,
depending on the inputs to the computation, each wire will be associated with
a speciﬁc plaintext value and a corresponding wire label, which we will call active value and active label. We stress that the evaluator can know only the active label, but not its corresponding value, and not the inactive label.
Then, going through C, for each gate G with input wires wi and wj, and output wire wt , P1 builds the following encrypted look-up table:

TG =

Encki0,k0j (ktG(0,0)) Encki0,k1j (ktG(0,1)) Encki1,k0j (ktG(1,0)) Encki1,k1j (ktG(1,1))

For example, if G is an AND gate, the look-up table will be:

TG =

Encki0,

k

0 j

(k

0 t

)

Encki0,

k

1 j

(k

0 t

)

Encki1,

k

0 j

(k

0 t

)

Encki1,

k

1 j

(k

1 t

)

Each cell of the look-up table encrypts the label corresponding to the output computed by the gate. Crucially, this allows the evaluator P2 to obtain the intermediate active labels on internal circuit wires and use them in the evaluation of F under encryption without ever learning their semantic value.

36

Fundamental MPC Protocols

P1 permutes the entries in each of the look-up tables (usually called garbled tables or garbled gates), and sends all the tables to P2. Additionally, P1 sends (only) the active labels of all wires corresponding to the input values to P2. For input wires belonging to P1’s inputs to F , this is done simply by sending the wire label keys. For wires belonging to P2’s inputs, this is done via 1-out-of-2 Oblivious Transfer.
Upon receiving the input keys and garbled tables, P2 proceeds with the evaluation. As discussed above, P2 must be able to decrypt the correct row of each garbled gate. This is achieved by the point-and-permute technique
described above. In our case of a 4-row garbled table, the point-and-permute
technique is particularly simple and eﬃcient — one pointer bit is needed for
each input, so there are two total pointer bits added to each entry in the garbled table. Ultimately, P2 completes evaluation of the garbled circuit and obtains the keys corresponding to the output wires of the circuit. These could be sent to P1 for decryption, thus completing the private evaluation of F .
We note that a round of communication may be saved and sending the output labels by P2 for decryption by P1 can be avoided. This can be done simply by P1 including the decoding tables for the output wires with the garbled circuit it sends. The decoding table is simply a table mapping each label on each output wire to its semantics (i.e. the corresponding plaintext value. Now, P2 obtaining the output labels will look them up in the decoding table and obtain the output in plaintext.
At an intuitive level, at least, it is easy to see that this circuit-based
construction is secure in the semi-honest model. Security against a corrupt P1 is easy, since (other than the OT, which we assume has been separately shown to satisfy the OT security deﬁnition) that party receives no messages in the protocol! For a corrupt P2, security boils down to the observation that the evaluator P2 never sees both labels for the same wire. This is obviously true for the input wires, and it holds inductively for all intermediate wires
(knowing only one label on each incoming wire of the gate, the evaluator can only decrypt one ciphertext of the garbled gate). Since P2 does not know the correspondence between plaintext values and the wire labels, it has no
information about the plaintext values on the wires, except for the output wires where the association between labels and values is explicitly provided by P1. To simulate P2’s view, the simulator SimP2 chooses random active labels for

3.2. Goldreich-Micali-Wigderson (GMW) Protocol

37

each wire, simulates the three “inactive” ciphertexts of each garbled gate as dummy ciphertexts, and produces decoding information that decodes the active output wires to the function’s output.
3.1.2 Yao’s GC Protocol
Figure 3.1 formalizes Yao’s gate generation, and Figure 3.2 summarizes Yao’s GC protocol. For simplicity of presentation, we describe the protocol variant based on Random Oracle (deﬁned in Section 2.2), even though a weaker assumption (the existence of pseudo-random functions) is suﬃcient for Yao’s GC construction. The Random Oracle, denoted by H, is used in implementing garbled row encryption. We discuss diﬀerent methods of instantiating H in Section 4.1.4. The protocol also uses Oblivious Transfer, which requires public-key cryptography.
For each wire label, a pointer bit, pi, is added to the wire label key following the point-and-permute technique described in Section 3.1.1. The pointer bits leak no information since they are selected randomly, but they allow the evaluator to determine which row in the garbled table to decrypt, based on the pointer bits for the two active wires it has for the inputs. In Section 4.1 we discuss several ways for making Yao’s GC protocol more eﬃcient, including reducing the size of the garbled table to just two ciphertexts per gate (Section 4.1.3) and enabling XOR gates to be computed without encryption (Section 4.1.2).
3.2 Goldreich-Micali-Wigderson (GMW) Protocol
As noted before, computation under encryption can be naturally viewed as operating on secret-shared data. In Yao’s GC, the secret sharing of the active wire value is done by having one player (generator) hold two possible wire labels wi0, wi1, and the other player (evaluator) hold the active label wib. In the GMW protocol (Goldreich et al., 1987; Goldreich, 2004), the secret-sharing of the wire value is more direct: the players hold additive shares of the active wire value.
The GMW protocol (or just “GMW”) naturally generalizes to more than two parties, unlike Yao’s GC, which requires novel techniques to generalize to more than two parties (see Section 3.5).

38

Fundamental MPC Protocols

P

:

Boolean circuit C implementing function F , security parameter κ.

GC

:

1. Wire Label Generation. For each wire wi of C, randomly choose wire

labels,

wib = (kib ∈R {0, 1}κ, pib ∈R {0, 1}),

such that pib = 1 − p1i −b.

2. Garbled Circuit Construction. For each gate Gi of C in topological order:

(a) Assume Gi is a 2-input Boolean gate implementing function gi: wc = gi(wa, wb), where input labels are wa0 = (ka0, p0a), wa1 = (ka1, p1a), wb0 = (kb0, p0b), wb1 = (kb1, p1b), and the output labels are wc0 = (kc0, p0c), wc1 = (kc1, p1c).
(b) Create Gi’s garbled table. For each of 22 possible combinations of Gi’s input values va, vb ∈ {0, 1}, set

eva,vb

=

H

(k

va a

||

kbvb

| | i) ⊕ wcgi (va,vb )

Sort entries e in the table by the input pointers, placing entry eva,vb in position pvaa, pvbb .

3. Output Decoding Table. For each circuit-output wire wi (the output of gate Gj) with labels wi0 = (ki0, p0i ), wi1 = (ki1, p1i ), create garbled output table for both possible wire values v ∈ {0, 1}. Set
ev = H(kiv || “out” || j) ⊕ v

(Because we are xor-ing with a single bit, we just use the lowest bit of the
output of H for generating the above ev.) Sort entries e in the table by the input pointers, placing entry ev in position piv. (There is no conﬂict, since p1i = p0i ⊕ 1.)

Figure 3.1: Yao’s Garbled Circuit protocol: GC generation

3.2. Goldreich-Micali-Wigderson (GMW) Protocol

39

P

: Parties P1 and P2 with inputs x ∈ {0, 1}n and y ∈ {0, 1}n

respectively. Boolean circuit C implementing function F .

P

:

1. P1 plays the role of GC generator and runs the algorithm of Figure 3.1. P1 then sends the obtained GC C (including the output decoding table) to P2.
2. P1 sends to P2 active wire labels for the wires on which P1 provides input.

3. For each wire wi on which P2 provides input, P1 and P2 execute an Oblivious Transfer (OT) where P1 plays the role of the Sender, and P2
plays the role of the Receiver:

(a) P1’s two input secrets are the two labels for the wire, and P2’s choice-bit input is its input on that wire.
(b) Upon completion of the OT, P2 receives active wire label on the wire.

4. P2 evaluates received C gate-by-gate, starting with the active labels on the input wires.
(a) For gate Gi with garbled table T = (e0,0, ...e1,1) and active input labels wa = (ka, pa), wb = (kb, pb), P2 computes active output label wc = (kc, pc):
wc = H(ka || kb || i) ⊕ epa,pb

5. Obtaining output using output decoding tables. Once all gates of C are
evaluated, using “out” for the second key to decode the ﬁnal output gates, P2 obtains the ﬁnal output labels which are equal to the plaintext output of the computation. P2 sends the obtained output to P1, and they both output it.

Figure 3.2: Yao’s Garbled Circuit Protocol

40

Fundamental MPC Protocols

3.2.1 GMW Intuition
The GMW protocol can work both on Boolean and arithmetic circuits. We
present the two-party Boolean version ﬁrst, and then brieﬂy explain how the
protocol can be generalized to more than two parties. As with Yao’s protocol, we assume players P1 with input x and P2 with input y have agreed on the Boolean circuit C representing the computed function F (x, y).
The GMW protocol proceeds as follows. For each input bit xi ∈ {0, 1} of x ∈ {0, 1}n, P1 generates a random bit ri ∈R {0, 1} and sends all ri to P2. Next, P1 obtains a secret sharing of each xi between P1 and P2 by setting its share to be xi ⊕ ri. Symmetrically, P2 generates random bit masks for its inputs yi and sends the masks to P1, secret sharing its input similarly.
P1 and P2 proceed in evaluating C gate by gate. Consider gate G with input wires wi and wj and output wire wk. The input wires are split into two shares, such that s1x ⊕ s2x = wx. Let P1 holds shares si1 and s1j on wi and wj, and P2 hold shares si2 and s2j on the two wires. Without loss of generality, assume C consists of NOT, XOR and AND gates.
Both NOT and XOR gates can be evaluated without any interaction. A NOT gate is evaluated by P1 ﬂipping its share of the wire value, which ﬂips the shared wire value. An XOR gate on wires wi and wj is evaluated by players xor-ing the shares they already hold. That is, P1 computes its output share as sk1 = si1 ⊕ s1j , and P2 correspondingly computes its output share as sk2 = si2 ⊕ s2j . The computed shares, sk1, sk2, indeed are shares of the active output value: sk1 ⊕ sk2 = (si1 ⊕ s1j ) ⊕ (si2 ⊕ s2j ) = (si1 ⊕ si2) ⊕ (s1j ⊕ s2j ) = wi ⊕ wj .
Evaluating an AND gate requires interaction and uses 1-out-of-4 OT a basic primitive. From the point of view of P1, its shares si1, s1j are ﬁxed, and P2 has two Boolean input shares, which means there are four possible options for P2. If P1 knew P2’s shares, then evaluating the gate under encryption would be trivial: P1 can just reconstruct the active input values, compute the active output value and secret-share it with P2. While P1 cannot do that, it can do the next best thing: prepare such a secret share for each of P2’s possible inputs,
and run 1-out-of-4 OT to transfer the corresponding share. Speciﬁcally, let
S = Ssi1,s1j (si2, s2j ) = (si1 ⊕ si2) ∧ (s1j ⊕ s2j )
be the function computing the gate output value from the shared secrets on the two input wires. P1 chooses a random mask bit r ∈R {0, 1} and prepares a

3.2. Goldreich-Micali-Wigderson (GMW) Protocol

41

table of OT secrets:

r ⊕ S(0, 0)

TG =

r ⊕ S(0, 1) r ⊕ S(1, 0)

r ⊕ S(1, 1)

Then P1 and P2 run an 1-out-of-4 OT protocol, where P1 plays the role of the sender, and P2 plays the role of the receiver. P1 uses table rows as each of the four input secrets, and P2 uses its two bit shares as the selection to choose the corresponding row. P1 keeps r as its share of the gate output wire value, and P2 uses the value it receives from the OT execution.
Because of the way the OT inputs are constructed, the players obtain a

secret sharing of the gate output wire. At the same time, it is intuitively clear

that the players haven’t learned anything about the other player’s inputs or the intermediate values of the computation. This is because eﬀectively only P2 receives messages, and by the OT guarantee, it learns nothing about the three

OT secrets it did not select. The only thing it learns is its OT output, which

is its share of a random sharing of the output value and therefore leaks no information about the plaintext value on that wire. Likewise, P1 learns nothing about the selection of P2.
After evaluating all gates, players reveal to each other the shares of the

output wires to obtain the output of the computation.

Generalization to more than two parties. We now sketch how to generalize this to the setting where n players P1, P2, . . . , Pn evaluate a boolean circuit F . As before, player Pj secret-shares its input by choosing ∀i j, ri ∈R {0, 1}, and sending ri to each Pi. The parties P1, P2, . . . , Pn proceed by evaluating C gate-by-gate. They evaluate each gate G as follows:
• For an XOR gate, the players locally add their shares. Like the two-party case, no interaction is required and correctness and security are assured.
• For an AND gate c = a ∧ b, let a1, . . . , an, b1, . . . , bn denote the shares

42

Fundamental MPC Protocols

of a, b respectively held by the players. Consider the identity

c = a ∧ b = (a1 ⊕ · · · ⊕ an) ∧ (b1 ⊕ · · · ⊕ bn)

n

=

ai ∧ bi ⊕

ai ∧ bj

i=1

ij

Each player Pj computes aj ∧bj locally to obtain a sharing of

n i=1

ai

∧bi

.

Further, each pair of players Pi, Pj jointly computes the shares of ai ∧ bj

as described above in the two-party GMW. Finally, each player outputs

the XOR of all obtained shares as the sharing of the result a ∧ b.

3.3 BGW protocol

One of the ﬁrst multi-party protocols for secure computation is due to Ben-Or, Goldwasser, and Wigderson (Ben-Or et al., 1988), and is known as the “BGW”
protocol. Another somewhat similar protocol of Chaum, Crépau, and Damgård was published concurrently (Chaum et al., 1988) with BGW, and the two
protocols are often considered together. For concreteness, we present here the BGW protocol for n parties, which is somewhat simpler.
The BGW protocol can be used to evaluate an arithmetic circuit over a
ﬁeld F, consisting of addition, multiplication, and multiplication-by-constant
gates. The protocol is heavily based on Shamir secret sharing (Shamir, 1979),
and it uses the fact that Shamir secret shares are homomorphic in a special
way—the underlying shared value can be manipulated obliviously, by suitable
manipulations to the individual shares. For v ∈ F we write [v] to denote that the parties hold Shamir secret shares
of a value v. More speciﬁcally, a dealer chooses a random polynomial p of degree at most t, such that p(0) = v. Each party Pi then holds value p(i) as their share. We refer to t as the threshold of the sharing, so that any collection of t shares reveals no information about v.
The invariant of the BGW protocol is that for every wire w in the arithmetic circuit, the parties hold a secret-sharing [vw] of the value vw on that wire. Next, we sketch the protocol with a focus on maintaining this invariant.

Input wires. For an input wire belonging to party Pi, that party knows the value v on that wire in the clear, and distributes shares of [v] to all the parties.

3.3. BGW protocol

43

Addition gate. Consider an addition gate, with input wires α, β and output wire γ. The parties collectively hold sharings of incoming wires [vα] and [vβ], and the goal is to obtain a sharing of [vα + vβ]. Suppose the incoming sharings correspond to polynomials pα and pβ, respectively. If each party Pi locally adds their shares pα(i) + pβ(i), then the result is that each party holds a point on the polynomial pγ(x) d=ef pα(x) + pβ(x). Since pγ also has degree at most t, these new values comprise a valid sharing pγ(0) = pα(0) + pβ(0) = vα + vβ.
Note that addition gates require no communication among the parties. All
steps are local computation. The same idea works to multiply a secret-shared
value by a public constant — each party simply locally multiplies their share
by the constant.
Multiplication gate. Consider a multiplication gate, with input wires α, β and output wire γ. The parties collectively hold sharings of incoming wires [vα] and [vβ], and the goal is to obtain a sharing of the product [vα · vβ]. As above, the parties can locally multiply their individual shares, resulting in each party holding a point on the polynomial q(x) = pα(x) · pβ(x). However, in this case the resulting polynomial may have degree as high as 2t which is too high.
In order to ﬁx the excessive degree of this secret sharing, the parties engage in a degree-reduction step. Each party Pi holds a value q(i), where q is a polynomial of degree at most 2t. The goal is to obtain a valid secret-sharing of q(0), but with correct threshold.
The main observation is that q(0) can be written as a linear function of the
party’s shares. In particular,
2t +1
q(0) = λiq(i)
i=1
where the λi terms are the appropriate Lagrange coeﬃcients. Hence the degree-reduction step works as follows:
1. Each party3 Pi generates and distributes a threshold-t sharing of [q(i)]. To simplify the notation, we do not give names to the polynomials that
underly these shares. However, it is important to keep in mind that each party Pi chooses a polynomial of degree at most t whose constant coeﬃcient is q(i).
3Technically, only 2t + 1 parties need to do this.

44

Fundamental MPC Protocols

2. The parties compute [q(0)] =

2t +1 i=1

λi

[q(i)],

using

local

computations.

Note that the expression is in terms of addition and multiplication-by-

constant applied to secret-shared values.

Since the values [q(i)] were shared with threshold t, the ﬁnal sharing of [q(0)] also has threshold t, as desired.
Note that multiplication gates in the BGW protocol require communication/interaction, in the form of parties sending shares of [q(i)]. Note also that we require 2t + 1 ≤ n, since otherwise the n parties do not collectively have enough information to determine the value q(0), as q may have degree 2t. For that reason, the BGW protocol is secure against t corrupt parties, for 2t < n
(i.e., an honest majority).

Output wires. For an output wire α, the parties will eventually hold shares of the value [vα] on that wire. Each party can simply broadcast its share of this value, so that all parties can learn vα.

3.4 MPC From Preprocessed Multiplication Triples

A convenient paradigm for constructing MPC protocols is to split the problem into a pre-processing phase (before the parties’ inputs are known) and an online phase (after the inputs are chosen). The pre-processing phase can produce correlated values for the parties, which they can later “consume” in the online phase. This paradigm is also used in some of the leading malicious-secure MPC protocols discussed in Chapter 6.

Intuition. To get an idea of how to defer some of the protocol eﬀort to the pre-processing phase, recall the BGW protocol. The only real cost in the protocol is the communication that is required for every multiplication gate. However, it is not obvious how to move any of the related costs to a pre-processing phase, since the costs are due to manipulations of secret values that can only be determined in the online phase (i.e., they are based on the circuit inputs). Nonetheless, Beaver (1992) showed a clever way to move the majority of the communication to the pre-processing phase.
A Beaver triple (or multiplication triple) refers to a triple of secret-shared values [a], [b], [c] where a and b are randomly chosen from the appropriate

3.4. MPC From Preprocessed Multiplication Triples

45

ﬁeld, and c = ab. In an oﬄine phase, such Beaver triples can be generated in a variety of ways, such as by simply running the BGW multiplication subprotocol on random inputs. One Beaver triple is then “consumed” for each multiplication gate in the eventual protocol.
Consider a multiplication gate with input wires α, β. The parties hold secret sharings of [vα] and [vβ]. To carry out the multiplication of vα and vβ using a Beaver triple [a], [b], [c], the parties do the following:
1. Using local computation, compute [vα − a] and publicly open d = vα − a (i.e., all parties announce their shares). While this value depends on the secret value vα, it is masked by the random value a and therefore reveals no information about vα.4
2. Using local computation, compute [vβ − b] and publicly open e = vβ − b.
3. Observe the following identity:
vαvβ = (vα − a + a)(vβ − b + b) = (d + a)(e + b) = de + db + ae + ab = de + db + ae + c
Since d and e are public, and the parties hold sharings of [a], [b], [c], they can compute a sharing of [vαvβ] by local computation only:
[vαvβ] = de + d[b] + e[a] + [c]
Using this technique, a multiplication can be performed using only two openings plus local computation. Overall, each party must broadcast two ﬁeld elements per multiplication, compared to n ﬁeld elements (across private channels) in the plain BGW protocol. While this comparison ignores the cost of generating the Beaver triples in the ﬁrst place, there are methods for generating triples in a batch where the amortized cost of each triple is a constant number of ﬁeld elements per party (Beerliová-Trubíniová and Hirt, 2008).

4Since a is used as essentially a one-time pad (and b similarly below), this triple [a], [b], [c] cannot be reused again in a diﬀerent multiplication gate.

46

Fundamental MPC Protocols

Abstraction. While the BGW protocol (speciﬁcally, its degree-reduction step) deals with the details of Shamir secret shares, the Beaver-triples approach conveniently abstracts these away. In fact, it works as long as the parties have an abstract “sharing mechanism” [v] with the following properties:
• Additive homomorphism: Given [x] and [y] and a public value z, parties can obtain any of [x + y], [x + z], [xz], without interaction.
• Opening: Given [x], parties can choose to reveal x to all parties.
• Privacy: An adversary (from whatever class of adversaries is being considered) can get no information about x from [x].
• Beaver triples: For each multiplication gate, the parties have a random triple [a], [b], [c] where c = ab.
• Random input gadgets: For each input wire belonging to party Pi, the parties have a random [r], where r is known only to Pi. During the protocol, when Pi chooses its input value x for this wire, it can announce δ = x − r to all parties (leaking nothing about x), and they can locally compute [x] = [r] + δ from the homomorphic properties.
As long as these properties are true of an abstract sharing mechanism, the Beaver-triples approach is secure. In fact, the paradigm is also secure in the presence of malicious adversaries, as long as the opening and privacy properties of the sharing mechanism hold against such adversaries. Speciﬁcally, a malicious adversary cannot falsify the opening of a shared value. We use this fact later in Section 6.6.

Instantiations. Clearly Shamir secret sharing gives rise to an abstract sharing scheme [·] that satisﬁes the above properties with respect to adversaries who corrupt at most t < n/2 parties.

Another suitable method of sharing is simple additive sharing over a ﬁeld F.

In additive sharing, [v] signiﬁes that each party Pi holds vi where

n i=1

vi

=

v.

This mechanism satisﬁes the appropriate homomorphic properties, and is

secure against n − 1 corrupt parties. When using F = {0, 1}, we obtain an

oﬄine-online variant of the GMW protocol (since the ﬁeld operations in this case correspond to AND and XOR). Of course, an arbitrary F is possible as

well, leading to a version of GMW for arithmetic circuits.

3.5. Constant-Round Multi-Party Computation: BMR

47

3.5 Constant-Round Multi-Party Computation: BMR
After Yao’s (two-party) GC protocol was proposed, several multi-party protocols appeared, including Goldreich-Micali-Wigderson (GMW) (Goldreich, 2004; Goldreich et al., 1987), presented in detail above in Section 3.2, Ben Or-Goldwasser-Wigderson (BGW) (Ben-Or et al., 1988), Chaum-CrepeauDamgård (CCD) (Chaum et al., 1988). All of these protocols have a number of rounds linear in the depth of the circuit C computing F . The Beaver-MicaliRogaway (BMR) protocol (Beaver et al., 1990) runs in a constant (in the depth of the circuit C) number of rounds, while achieving security against any t < n number of corruptions among the n participating parties.
3.5.1 BMR Intuition
The BMR protocols adapt the main idea of Yao’s GC to a multi-party setting. GC is chosen as a starting point due to its round-eﬃciency. However, a naïve attempt to port the GC protocol from the 2PC into the MPC setting gets stuck at the stage of sending the generated GC to the evaluators. Indeed, the circuit generator knows all the secrets (wire label correspondences), and if it colludes with any of the evaluators, the two colluding parties can learn the intermediate wire values and violate the security guarantees of the protocol.
The basic BMR idea is to perform a distributed GC generation, so that no single party (or even a proper subset of all parties) knows the GC generation secrets – the label assignment and correspondence. This GC generation can be done in parallel for all gates using MPC. This is possible by ﬁrst generating (in parallel) all wire labels independently, and then independently and in parallel generating garbled gate tables. Because of parallel processing for all gates and wires, the number of communication rounds for the GC generation is independent of the depth of the computed circuit C. As a result, the GC generation circuit CGEN is constant-depth for all computed circuits C (once the security parameter κ is ﬁxed). Even if the parties perform MPC evaluation of CGEN that depends on the depth of CGEN, the overall BMR protocol will still have constant rounds overall.
The MPC output, the GC produced by securely evaluating CGEN, may be delivered to a designated player, say P1, who will then evaluate it similarly to Yao’s GC. The ﬁnal technicality here is how to deliver the active input labels

48

Fundamental MPC Protocols

to P1. There are several ways how this may be achieved, depending on how exactly the MPC GC generation proceeded. Perhaps, it is conceptually simplest
to view this as part of the GC generation computation.
In concrete terms, the above approach is not appealing due to potentially
high costs of distributed generation of encryption tables, requiring the garbled
row encryption function (instantiated as a PRF or hash function) evaluation
inside MPC. Several protocols were proposed, which allow the PRF/hash
evaluation to be extracted from inside the MPC and instead be done locally
by the parties while providing the output of PRF/hash into the MPC. The
underlying idea of such an approach is to assign diﬀerent portions of each label to be generated by diﬀerent players. That is, a wire wa’s labels wav are a concatenation of sublabels wav, j each generated by Pj. Then, for a gate Gi with input labels wava, wbvb and the output label wcvc , the garbled row corresponding to input values va, vb and output value vc can simply be:

eva,vb = wcvc

(F(i, wav,aj ) ⊕ F(i, wbv,bj )),

j=1..n

(3.1)

where F is a PRF, indexed by the gate index, extending κ + 1 input bits into n · (κ + 1) bits.
The generation of the garbled table row is almost entirely done locally by each party. Each Pj computes F(i, wav,aj) ⊕ F(i, wbv,bj) and submits it to the MPC, which simply xors all the values to produce the garbled row.
However, we are not quite done. Recall that the GC evaluator P1 will reconstruct active labels. A careful reader would notice that knowledge of its
own contributed sublabel will allow it to identify which plaintext value the
active label corresponds to, violating the security guarantee. The solution is for each player Pj to add a “ﬂip” bit fa, j to each wire wa.
The xor of the n ﬂip bits, fa = j=1..n fa, j, determines which plaintext bit corresponds to the wire label wav. The ﬂip bits will be an additional input into the garbling MPC. Now, with the addition of the ﬂip bits, no subset of players
will know the wire ﬂip bit, and hence even the recognition and matching of the
sublabel will not allow the evaluator to match the label to plaintext value, or to
compute the inactive label in full.
We sketch a concrete example of an eﬃcient BMR garbling in Figure 3.3;
BMR evaluation is straightforward based on the garbling technique.

3.5. Constant-Round Multi-Party Computation: BMR

49

P

: Boolean circuit C implementing function F .

Let F : id, {0, 1}κ+1 → {0, 1}n·(κ+1) be a PRF.

P

: P1, P2, ..., Pn with inputs x1, ..., xn ∈ {0, 1}k.

GC

:

1. For each wire wi of C, each Pj randomly chooses wire sublabels, wib, j = (kib, j, pib, j ) ∈R {0, 1}κ+1, such that pib, j = 1 − p1i,−j b, and ﬂipbit shares fi, j ∈R {0, 1}. For each wire wi, Pj locally computes its

underlying-MPC input,

Ii, j = (F(i, wi0, j ), F(i, wi1, j ), p0i, j, fi, j ).

2. For each gate Gi of C in parallel, all players participate in n-party MPC to compute the garbled table, taking as input all players’ inputs x1, ..., xn as well as pre-computed values Ii, j, by evaluating the following function:

1. Assume Gi is a 2-input Boolean gate implementing function g, with input wires wa, wb and output wire wc.
2. Compute pointer bits p0a = j=1..n p0a, j, p0b = j=1..n p0b, j, p0c = j=1..n p0c, j , and set p1a = 1 − p0a, p1b = 1 − p0b, p1c = 1 − p0c.
Similarly compute ﬂip bits fa, fb, fc by xor-ing the corresponding
ﬂip bit shares submitted by the parties. Amend the semantics of the wires according to the ﬂip bits by xor-ing fa, fb, fc in the label
index as appropriate (included in the next steps).

3. Create Gi’s garbled table. For each of 22 possible combinations of Gi’s input values, va, vb ∈ {0, 1}, set

eva,vb = wcvc ⊕ fc

(F(i, wav,aj⊕ fa ) ⊕ F(i, wbv,bj⊕ fb )),

j=1..n

where wc0 = Sort entries e

wc0,1 | in the

| . . . || wc0,n || table, placing

p0c, wc1 = entry eva,

wc1,1 || . . . || vb in position

wc1,n || p1c . (pvaa, pvbb ).

4. Output to P1 the computed garbled tables, as well as active wire labels inputs of C, as selected by players’ inputs, x1, ..., xn.

Figure 3.3: BMR Multi-Party GC Generation

50

Fundamental MPC Protocols

3.6 Information-Theoretic Garbled Circuits
Yao’s GC and the GMW protocol present two diﬀerent ﬂavors of the use of secret sharing in MPC. In this section, we discuss a third ﬂavor, where the secrets are shared not among players, but among wires. This construction is also interesting because it provides information-theoretic security in the OT-hybrid setting, meaning that no computational hardness assumptions are used in the protocol beyond what is used in the underlying OT. An important practical reason to consider IT GC is that it presents a trade-oﬀ between communication bandwidth and latency: it needs to send less data than Yao GC at the cost of additional communication rounds. While most research on practical MPC focuses on low round complexity, we believe some problems which require very wide circuits, such as those that arise in machine learning, may beneﬁt from IT GC constructions.
Information-theoretic constructions typically provide stronger security at a higher cost. Surprisingly, this is not the case here. Intuitively, higher performance is obtained because information-theoretic encryption allows the encryption of a bit to be a single bit rather than a ciphertext whose length scales with the security parameter. Further, information-theoretic encryption here is done with bitwise XOR and bit shuﬄings, rather than with standard primitives such as AES.
We present the Gate Evaluation Secret Sharing (GESS) scheme of Kolesnikov (2005) (Kolesnikov (2006) provides details), which is the most eﬃcient information-theoretic analog of GC. The main result of Kolesnikov (2005) is a two-party protocol for a Boolean formula F with communication complexity ≈ di2, where di is the depth of the i-th leaf of F.
At a high level, GESS is a secret-sharing scheme, designed to allow evaluation under encryption of a Boolean gate G. The output wire labels of G are the two secrets from which P1 produces four secret shares, one corresponding to each of the wire labels of the two input wires. GESS guarantees that a valid combination of shares (one share per wire) can be used to reconstruct the corresponding label of the output wire. This is similar to Yao’s GC, but GESS does not require the use of garbled tables, and hence can be viewed as a generalization of Yao’s GC. Similarly to Yao’s GC approach, the secret sharing can be applied gate-by-gate without the need to decode or reconstruct the plaintext values.

3.6. Information-Theoretic Garbled Circuits

51

Consider a two-input Boolean gate G. Given the possible output values s0, s1 and the semantics of the gate G, P1 generates input labels (sh10, sh11), (sh20, sh21), such that each possible pair of encodings (sh1,i, sh2, j) where i, j ∈ {0, 1}, allows reconstructing G(i, j) but carries no other information. Now, if P2 obtains shares corresponding to gate inputs, it would be able to reconstruct the label on the output wire, and nothing else.
This mostly corresponds to our intuition of secret sharing schemes. Indeed,
the possible gate outputs play the role of secrets, which are shared and then
reconstructed from the input wires encodings (shares).
3.6.1 GESS for Two-Input Binary Gates
We present GESS for the 1-to-1 gate function G : {0, 1}2 → {00, 01, 10, 11}, where G(0, 0) = 00, G(0, 1) = 01, G(1, 0) = 10, G(1, 1) = 11. Clearly, this is a generalization of the Boolean gate functionality G : {0, 1}2 → {0, 1}.
Let the secrets domain be DS = {0, 1}n, and four (not necessarily distinct) secrets s00, ...s11 ∈ DS are given. The secret sij corresponds to the value G(i, j) of the output wire.
The intuition for the design of the GESS scheme is as follows (see illustration in Figure 3.4). We ﬁrst randomly choose two strings R0, R1 ∈R DS to be the shares sh10 and sh11 (corresponding to 0 and 1 of the ﬁrst input wire). Now consider sh20, the share corresponding to 0 of the second input wire. We want this share to produce either s00 (when combined with sh10) or s10 (when combined with sh11). Thus, the share sh20 will consist of two blocks. One, block s00 ⊕ R0, is designed to be combined with R0 and reconstruct s00. The other, s10 ⊕ R1, is designed to be combined with R1 and reconstruct s10. Share sh21 is constructed similarly, setting blocks to be s01 ⊕ R0 and s11 ⊕ R1.
Both leftmost blocks are designed to be combined with the same share R0, and both rightmost blocks are designed to be combined with the same share R1. Therefore, we append a 0 to R0 to tell Rec to use the left block of the second share for reconstruction, and append a 1 to R1 to tell Rec to use the right block of the second share for reconstruction. Finally, to hide information leaked by the order of blocks in shares, we randomly choose a bit b and if b = 1 we reverse the order of blocks in both shares of wire 2 and invert the
appended pointer bits of the shares of wire 1. Secret reconstruction proceeds
by xor-ing the wire-1 share (excluding the pointer bit) with the ﬁrst or second

52

Fundamental MPC Protocols

sh10, sh11

sh20, sh21

G

s0, s1

Figure 3.4: GESS for Boolean gate

half of the wire-2 share as indexed by the pointer bit.
3.6.2 Reducing Share Growth
Note the ineﬃciency of the above construction, causing the shares corresponding to the second input wire be double the size of the gate’s secrets. While, in some circuits we can avoid the exponential (in depth) secret growth by balancing the direction of greater growth toward more shallow parts of the circuit, a more eﬃcient solution is desirable. We discuss only AND and OR gates, since NOT gates are implemented simply by ﬂipping the wire label semantics by the Generator. GESS also enables XOR gates without any increase the share sizes. We defer discussion of this to Section 4.1.2, because the XOR sharing in GESS led to an important related improvement for Yao’s GC.
For OR and AND gates in the above construction, either the left or the right blocks of the two shares are equal (this is because s00 = s01 for the AND gate, and s10 = s11 for the OR gate). We use this property to reduce the size of the shares when the secrets are of the above form. The key idea is to view the

3.6. Information-Theoretic Garbled Circuits

53

shares of the second wire as being the same, except for one block.
Suppose each of the four secrets consists of n blocks and the secrets diﬀer only in the jth block, as follows:
s00 = ( t1 . . . tj−1 t0j 0 tj+1 . . . tn ), ...
s11 = ( t1 . . . tj−1 t1j 1 tj+1 . . . tn ),

where

∀i

=

1..n:

ti,

t0j 0,

t

0j 1,

t1j 0,

t

11 j

∈

{0, 1}k

for

some

k.

It

is

convenient

to consider the columns of blocks, spanning across the shares. Every column

(with the exception of the j-th) consists of four equal blocks, where the value

j is private.

For simplicity, we show the main ideas by considering a special case where the four secrets consist of n = 3 blocks each, and j = 2 is the index of

the column of distinct blocks. This intuition is illustrated on Figure 3.5. The

scheme naturally generalizes from this intuition; Kolesnikov (2005) provides a

formal presentation.

The idea is to share the secrets “column-wise”, treating each of the three

columns of blocks of secrets as a tuple of subsecrets and sharing this tuple

separately, producing the corresponding subshares. Consider sharing column 1.
All four subsecrets are equal (to t1), and we share them trivially by setting both subshares of the ﬁrst wire to a random string R1 ∈R DS, and both subshares of the second wire to be R1 ⊕ t1. Column 3 is shared similarly. We share column

2 as in previous construction (highlighted on the diagram), omitting the last

step of appending the pointers and applying the permutation. This preliminary

assignment of shares (still leaking information due to order of blocks) is shown

on Figure 3.5.

Note that the reconstruction of secrets is done by xor-ing the corresponding

blocks of the shares, and, importantly, the procedure is the same for both types

of sharing we use. For example, given shares sh10 and sh21, we reconstruct

the secret s01 = (R1 ⊕ (R1 ⊕ t1),

R2

⊕

(R2

⊕

t01),
2

R3 ⊕ (R3 ⊕ t3)).

The remaining permute-and-point step is to apply (the same) random

permutation π to reorder the four columns of both shares of wire 2 and to

append (log 4)-bit pointers to each block of the shares of wire 1, telling the

reconstructor which block of the second share to use. Note that the pointers

appended to both blocks of column 1 of wire 1 are the same. The same holds

54

Fundamental MPC Protocols

Figure 3.5: Improved GESS for Boolean gate
for column 3. Pointers appended to blocks of column 2 are diﬀerent. For example, if the identity permutation was applied, then we will append “1” to both blocks R1, “2” to R2, “3” to R2, and “4” to both blocks R3. This leads to the punchline: because G is either an OR or an AND gate, both tuples of shares maintain the property that all but one of the pairs of corresponding blocks are equal between the shares of the tuple. This allows repeated application (i.e., continuing sharing) of GESS for OR and AND gates.
Finally, to put it all together, we sketch the GESS-based MPC protocol. P1 represents the function F as a formula F. Then, starting with the output wires of F and taking the plaintext output wire labels as secrets, P1 applies GESS scheme repeatedly to all gates of the circuit, assigning the GESS shares to gates’ input wires until he assigns the labels to formula inputs. Then, P1 transfers to P2 active labels on the input wires, and P2 repeatedly uses GESS reconstruction procedure to obtain output labels of F.
3.7 Oblivious Transfer
Oblivious Transfer, deﬁned in Section 2.4, is an essential building block for secure computation protocols, and an inherently asymmetric primitive. Impagliazzo and Rudich (1989) showed that a reduction from OT to a symmetric-key primitive (one-way functions, PRF) implies that P NP. However, as ﬁrst observed by Beaver (1996), a batched execution of OT only needs a small number of public key operations. Beaver’s construction was non-black-box in the sense that a PRF needed to be represented as a circuit and evaluated as MPC. As a consequence, Beaver’s result was mainly of theoretical interest.

3.7. Oblivious Transfer

55

P

:

1. Two parties: Sender S and Receiver R. S has input secrets x1, x2 ∈ {0, 1}n, and R has a selection bit b ∈ {0, 1}.

P

:

1. R generates a public-private key pair sk, pk, and samples a random key, pk , from the public key space. If b = 0, R sends a pair (pk, pk ) to S. Otherwise (if b = 1), R sends a pair (pk , pk) to S.
2. S receives (pk0, pk1) and sends back to R two encryptions e0 = Encpk0 (x0), e1 = Encpk1 (x1).
3. R receives e0, e1 and decrypts the ciphertext eb using sk. R is unable to decrypt the second ciphertext as it does not have the corresponding secret key.

Figure 3.6: Public key-based semi-honest OT.

Ishai et al. (2003) changed the state of aﬀairs dramatically by proposing an extremely eﬃcient batched OT which only required κ of public key operations
for the entire batch and two or three hashes per OT.

3.7.1 Public Key-Based OT

We start with the basic public key-based OT in the semi-honest model. The

construction, presented in Figure 3.6, is very simple indeed.

The security of the construction assumes the existence of public-key

encryption with the ability to sample a random public key without obtaining

the corresponding secret key. The scheme is secure in the semi-honest model.

The Sender S only sees the two public keys sent by R, so cannot predict with

probability

better

than

1 2

which

key

was

generated

without

the

knowledge

of

the secret key. Hence, the view of S can be simulated simply by sending two

randomly-chosen public keys. The Receiver R sees two encryptions and has a secret key to decrypt only
one of them. The view of R is also easily simulated, given R’s input and

56

Fundamental MPC Protocols

output. SimS will generate the public-private key pair and a random public key, and set the simulated received ciphertexts to be 1) the encryption of the received secret under the generated keypair and 2) the encryption of zero under the randomly chosen key. The simulation goes through since the diﬀerence with the real execution is only in the second encryption, and distinguisher will not be a tell apart the encryption of zero from another value due to the encryption security guarantees. Note that this semi-honest protocol provides no security against a malicious receiver—the Receiver R can simply generate two public-private key pairs, (sk0, pk0) and (sk1, pk1) and send (pk0, pk1) to S, and decrypt both received ciphertexts to learn both x1 and x2.
3.7.2 Public Key Operations in OT
The simple protocol in Figure 3.6 requires one public key operation for both the sender and receiver for each selection bit. As used in a Boolean circuit-based MPC protocol such as Yao’s GC, it is necessary to perform an OT for each input bit of the party executing the circuit. For protocols like GMW, evaluating each AND gate requires an OT. Hence, several works have focused on reducing the number of public key operations to perform a large number of OTs.

Beaver’s non-black-box construction. Beaver (1996) proposed bootstrap-

ping Yao’s GC protocol to generate a polynomial number of OTs from a small

number of public key operations. As discussed in Section 3.1, the GC protocol

for computing a circuit C requires m OTs, where m is the number of input

bits provided by P2. Following the OT notation, we call P1 (the generator in

GC) the sender S, and P2 (the evaluator in GC) the receiver R. Let m be a

desired number of OTs that will now be performed as a batch. S’s input will be

m

pairs

of

secrets

(x0,
1

x1),
1

...,

(xm0 ,

xm1

),

and

R

’s

input

will

be

m-bit

selection

string b = (b1, ..., bm).

We now construct a circuit C that implements a function F which takes

only a small number of input bits from R, but outputs the result of polynomial

number of OTs to R. The input of R to F will be a randomly chosen κ-bit

string r. Let G be a pseudo-random generator expanding κ bits into m bits. R

will send to S its input string masked with the pseudo-random string, b ⊕ G(r).

Then,

S’s

input

to

F

will

be

m

pairs

of

secrets

(x0,
1

x1),
1

.

.

.

,

(xm0 ,

xm1 )

as

well

as

the m-bit string b ⊕ G(r). Given r, the function F computes the m-bit expansion

3.7. Oblivious Transfer

57

G(r) and unmasks the input b ⊕ G(r), obtaining the selection string b. Then F simply outputs to R the corresponding secrets xbi . Only κ input bits are provided by R, the circuit evaluator, so only a constant number of κ OTs are
needed to perform m OTs.

Reducing the number of public key operations. The construction of Beaver
(1996) shows a simple way to reduce the number of asymmetric operations required to perform m OTs to a ﬁxed security parameter, but is not eﬃcient in
practice because of the need to execute a large GC. Recall, our goal is to use a small number k of base-OTs, plus only symmetric-key operations, to achieve m k eﬀective OTs. Here, k is chosen depending on the computational security parameter κ; in the following we show how to choose k. Below we describe the OT extension by Ishai et al. (2003) that achieves m 1-out-of-2 OT
of random strings, in the presence of semi-honest adversaries.
We follow the notation of Kolesnikov and Kumaresan (2013), as it explicates the coding-theoretic framework for OT extension. Suppose the receiver R has choice bits r ∈ {0, 1}m. R chooses two m × k matrices (m rows, k columns), T and U. Let t j, u j ∈ {0, 1}k denote the j-th row of T and U, respectively. The
matrices are chosen at random, so that:

t j ⊕ u j = rj · 1k d=ef

1k 0k

if rj = 1 if rj = 0

The sender S chooses a random string s ∈ {0, 1}k. The parties engage in k instances of 1-out-of-2 string-OT, with their roles reversed, to transfer to sender S the columns of either T or U, depending on the sender’s bit si in the string s it chose. In the i-th OT, R provides inputs ti and ui, where these refer to the i-th column of T and U, respectively. S uses si as its choice bit and receives output qi ∈ {ti, ui }. Note that these are OTs of strings of length m k — the length of OT messages is easily extended, e.g., by encrypting and sending the two m-bit long strings, and using OT on short strings to send
the right decryption key. Now let Q denote the matrix obtained by the sender, whose columns are
qi. Let q j denote the jth row. The key observation is that

q j = t j ⊕ [rj · s] =

tj tj ⊕ s

if rj = 0 if rj = 1

(3.2)

58

Fundamental MPC Protocols

Let H be a Random Oracle (RO)5. Then S can compute two random strings H(q j) and H(q j ⊕ s), of which R can compute only one, via H(t j), of R’s choice. Indeed, following Equation 3.2, q j equals either t j or t j ⊕ s, depending on R’s choice bit rj. It is immediate then that t j equals either q j or q j ⊕ s, depending on R’s choice bit rj. Note that R has no information about s, so intuitively it can learn only one of the two random strings H(q j), H(q j ⊕ s). Hence, each of the m rows of the matrix can be used to produce a single
1-out-of-2 OT of random strings. To extend this to the more usual 1-out-of-2 OT of two given secrets s0, s1,
we add the following step to the above. S now additionally encrypts the two OT secrets with the two keys H(q j) and H(q j ⊕ s) and sending the two encryptions (e.g. H(q j) ⊕ s0 and H(q j ⊕ s) ⊕ s1) to R. As R can obtain exactly one of H(q j) and H(q j ⊕ s), he can obtain only the corresponding secret si.

Coding interpretation and cheaper 1-out-of-2 OT. In IKNP, the receiver prepares secret shares of T and U such that each row of T ⊕ U is either all
zeros or all ones. Kolesnikov and Kumaresan (2013) interpret this aspect of IKNP as a repetition code and suggest using other codes instead.
Consider how we might use the IKNP OT extension protocol to realize 1-out-of-2 OT. Instead of a choice bit rj for the receiver, rj will now be an -bit string. Let C be a linear error correcting code of dimension and codeword length k. The receiver will prepare matrices T and U so that t j ⊕ u j = C(rj).
Now, generalizing Equation 3.2 the sender S receives

q j = t j ⊕ [C(rj) · s]

(3.3)

where “·” now denotes bitwise-AND of two strings of length k. (Note that when C is a repetition code, this is exactly Equation 3.2.)
For each value r ∈ {0, 1} , the sender associates the secret value H(q j ⊕ [C(r ) · s]), which it can compute for all r ∈ {0, 1} . At the same time, the receiver can compute one of these values, H(t j). Rearranging Equation 3.3,
we have: H(t j) = H(q j ⊕ [C(rj) · s])

5As pointed out by Ishai et al. (2003), it is suﬃcient to assume that H is a correlation-robust
hash function, a weaker assumption than RO. A special assumption is required because the same s is used for every resulting OT instance.

3.8. Custom Protocols

59

Hence, the value that the receiver can learn is the secret value that the sender associates with the receiver’s choice string r = rj.
At this point, OT of random strings is completed. For OT of chosen strings, the sender will use each H(qi ⊕ [C(r) · s]) as a key to encrypt the r-th OT message. The receiver will be able to decrypt only one of these encryptions, namely one corresponding to its choice string rj.
To argue that the receiver learns only one string, suppose the receiver has choice bits rj but tries to learn also the secret H(q j ⊕ [C(r˜) · s]) corresponding to a diﬀerent choice r˜. We observe:
q j ⊕ [C(r˜) · s] = t j ⊕ [C(rj) · s] ⊕ [C(r˜) · s] = t j ⊕ [(C(rj) ⊕ C(r˜)) · s]
Importantly, everything in this expression is known to the receiver except for s. Now suppose the minimum distance of C is κ (the security parameter). Then C(rj) ⊕ C(r˜) has Hamming weight at least κ. Intuitively, the adversary would have to guess at least κ bits of the secret s in order to violate security. The protocol is secure in the RO model, and can also be proven under the weaker assumption of correlation robustness, following Ishai et al. (2003) and Kolesnikov and Kumaresan (2013).
Finally, we remark that the width k of the OT extension matrix is equal to the length of codewords in C. The parameter k determines the number of base OTs and the overall cost of the protocol.
The IKNP protocol sets the number of OT matrix columns to be k = κ. To achieve the same concrete security as IKNP OT, the KK13 protocol (Kolesnikov and Kumaresan, 2013) requires setting k = 2κ, to account for the larger space required by the more eﬃcient underlying code C.
3.8 Custom Protocols
All of the secure computation protocols discussed so far in this chapter are generic circuit-based protocols. Circuit-based protocols suﬀer from linear bandwidth cost in the size of the circuit, which can be prohibitive for large computations. There are signiﬁcant overheads with circuit-based computation on large data structures, compared to, say, a RAM (Random Access Machine) representation. In Chapter 5 we discuss approaches for incorporating sublinear data structures into generic circuit-based protocols.

60

Fundamental MPC Protocols

Another approach is to design a customized protocol for a particular problem. This has some signiﬁcant disadvantages over using a generic protocol. For one, it requires designing and proving the security of a custom protocol. It also may not integrate with generic protocols, so even if there is an eﬃcient custom protocol for computing a particular function, privacy-preserving applications often require additional pre-processing or post-processing around that function to be useful, so it may not be possible to use a custom protocol without also developing methods for connecting it with a generic protocol. Finally, although hardening techniques are known for generic protocols (Chapter 6), it may not be possible to (eﬃciently) harden a customized protocol to work in a malicious security setting.
Nevertheless, several specialized problems do beneﬁt from tailored solutions and the performance gains possible with custom protocols may be substantial. In this work we brieﬂy review one such practically important problem: private set intersection.
3.8.1 Private Set Intersection (PSI)
The goal of private set intersection (PSI) is to enable a group of parties to jointly compute the intersection of their input sets, without revealing any other information about those sets (other than upper bounds on their sizes). Although protocols for PSI have been built upon generic MPC (Huang et al., 2012a), more eﬃcient custom protocols can be achieved by taking advantage of the structure of the problem.
We will present current state-of-the art two-party PSI (Kolesnikov et al., 2016). It is built on the protocol of Pinkas et al. (2015), which heavily uses Oblivious PRF (OPRF) as a subroutine. OPRF is an MPC protocol which allows two players to evaluate a PRF F, where one of the players holds the PRF key k, and the other player holds the PRF input x, and the second player gets Fk(x). We ﬁrst describe how to obtain PSI from OPRF, and then we brieﬂy discuss the OPRF construction. The improvement of Kolesnikov et al. (2016) is due to developing a faster OPRF.
PSI from OPRF. We now describe the Pinkas-Schneider-Segev-Zohner (PSSZ) construction (Pinkas et al., 2015) building PSI from an OPRF. For concreteness, we describe the parameters used in PSSZ when the parties have

3.8. Custom Protocols

61

roughly the same number n of items.
The protocol relies on Cuckoo hashing (Pagh and Rodler, 2004) with 3 hash functions, which we brieﬂy review now. To assign n items into b bins using Cuckoo hashing, ﬁrst choose random functions h1, h2, h3 : {0, 1}∗ → [b] and initialize empty bins B[1, . . . , b]. To hash an item x, ﬁrst check to see whether any of the bins B[h1(x)], B[h2(x)], B[h3(x)] are empty. If so, then place x in one of the empty bins and terminate. Otherwise, choose a random i ∈ {1, 2, 3}, evict the item currently in B[hi(x)] and replace it with x, and
then recursively try to insert the evicted item. If this process does not terminate
after a certain number of iterations, then the ﬁnal evicted element is placed in a special bin called the stash.
PSSZ uses Cuckoo hashing to implement PSI. First, the parties choose 3 random hash functions h1, h2, h3 suitable for 3-way Cuckoo hashing. Suppose P1 has input set X and P2 has input set Y , where |X | = |Y | = n. P2 maps its items into 1.2n bins using Cuckoo hashing and a stash of size s. At this point, P2 has at most one item per bin and at most s items in its stash. P2 pads its
input with dummy items so that each bin contains exactly one item and the stash contains exactly s items.
The parties then run 1.2n + s instances of an OPRF, where P2 plays the role of receiver and uses each of its 1.2n + s items as input to the OPRF. Let F(ki, ·) denote the PRF evaluated in the i-th OPRF instance. If P2 has mapped item y to bin i via Cuckoo hashing, then P2 learns F(ki, y); if P2 has mapped y to position j in the stash, then P2 learns F(k1.2n+j, y).
On the other hand, P1 can compute F(ki, ·) for any i. So, P1 computes sets
of candidate PRF outputs:
H = {F(khi(x), x) | x ∈ X and i ∈ {1, 2, 3}} S = {F(k1.2n+j, x) | x ∈ X and j ∈ {1, . . . , s}}
P1 randomly permutes elements of H and elements of S and sends them to P2, who can identify the intersection of X and Y as follows. If P2 has an item y
mapped to the stash, it checks whether the associated OPRF output is present in S. If P2 has an item y mapped to a hashing bin, it checks whether its associated OPRF output is in H.
Intuitively, the protocol is secure against a semi-honest P2 by the PRF property. For an item x ∈ X \ Y , the corresponding PRF outputs F(ki, y) are

62

Fundamental MPC Protocols

pseudorandom. Similarly, if the PRF outputs are pseudorandom even under related keys, then it is safe for the OPRF protocol to instantiate the PRF instances with related keys.
The protocol is correct as long as the PRF does not introduce any further collisions (i.e., F(ki, x) = F(ki , x ) for x x ). We must carefully set the parameters required to prevent such collisions.
More eﬃcient OPRF from 1-out-of-∞ OT. Kolesnikov et al. (2016) developed an eﬃcient OPRF construction for the PSI protocol, by pushing on the coding idea from Section 3.7.2. The main technical observation is pointing out that the code C need not have many of the properties of error-correcting codes. The resulting pseudorandom codes enable an 1-out-of-∞ OT, which can be used to produce an eﬃcient PSI.
In particular,
1. it makes no use of decoding, thus the code does not need to be eﬃciently decodable, and
2. it requires only that for all possibilities r, r , the value C(r) ⊕ C(r ) has Hamming weight at least equal to the computational security parameter κ. In fact, it is suﬃcient even if the Hamming distance guarantee is only probabilistic — i.e., it holds with overwhelming probability over choice of C (we discuss subtleties below).
For ease of exposition, imagine letting C be a random oracle with suitably long output. Intuitively, when C is suﬃciently long, it should be hard to ﬁnd a near-collision. That is, it should be hard to ﬁnd values r and r such that C(r) ⊕ C(r ) has low (less than a computational security parameter κ) Hamming weight. A random function with output length k = 4κ suﬃces to make near-collisions negligible (Kolesnikov et al., 2016).
We refer to such a function C (or family of functions, in our standardmodel instantiation) as a pseudorandom code (PRC), since its coding-theoretic properties — namely, minimum distance — hold in a cryptographic sense.
By relaxing the requirement on C from an error-correcting code to a pseudorandom code, we remove the a-priori bound on the size of the receiver’s choice string! In essence, the receiver can use any string as its choice string; the sender can associate a secret value H(q j ⊕ [C(r ) · s]) for any string r . As

3.9. Further Reading

63

discussed above, the receiver is only able to compute H(t j) = H(q j ⊕ [C(r) · s]) — the secret corresponding to its choice string r. The property of the PRC is that, with overwhelming probability, all other values of q j ⊕ [C(r˜) · s] (that a polytime player may ever ask) diﬀer from t j in a way that would require the receiver to guess at least κ bits of s.
Indeed, we can view the functionality achieved by the above 1-out-of-∞ OT as a kind of OPRF. Intuitively, r → H(q ⊕ [C(r) · s]) is a function that the sender can evaluate on any input, whose outputs are pseudorandom, and which the receiver can evaluate only on its chosen input r.
The main subtleties in viewing 1-out-of-∞ OT as OPRF are:
1. the fact that the receiver learns slightly more than the output of this “PRF” — in particular, the receiver learns t = q ⊕ [C(r) · s] rather than H(t); and,
2. the fact that the protocol realizes many instances of this “PRF” but with related keys — s and C are shared among all instances.
Kolesnikov et al. (2016) show that this construction can be securely used in place of the OPRF in the PSSZ protocol, and can scale to support private intersections of sets (of any size element) with n = 220 over a wide area network in under 7 seconds.
Set intersection of multiple sets can be computed iteratively by computing pairwise intersections. However, extending the above 2PC PSI protocol to the multi-party setting is not immediate. Several obstacles need to be overcome, such as the fact that in 2PC computation one player learns the set intersection of the two input sets. In the multi-party setting this information must be protected. Eﬃcient extension of the above PSI protocol to the multi-party setting was proposed by Kolesnikov et al. (2017a).
3.9 Further Reading
In this book, we aim to provide an easy to understand and exciting introduction to MPC, so omit a lot of formalization and proofs. Yao’s GC, despite its simplicity, has several technical proof subtleties, which are ﬁrst noticed and written out in the ﬁrst formal account of Yao’s GC (Lindell and Pinkas, 2009). The GMW protocol was introduced by Goldreich et al. (1987), but Goldreich

64

Fundamental MPC Protocols

(2004) provides a cleaner and more detailed presentation. The BGW and CCD protocols were developed concurrently by Ben-Or et al. (1988) and Chaum et al. (1988). Beaver et al. (1990) considered constant-round multiparty protocols. A more detailed protocol presentation and discussion can be found in Phillip Rogaway’s Ph.D. thesis (Rogaway, 1991).
Recently, a visual cryptography scheme for secure computation without computers was designed based on the GESS scheme (D’Arco and De Prisco, 2014; D’Arco and De Prisco, 2016). The OT extension of Ishai et al. (2003) is indeed one of the most important advances in MPC, and there are several extensions. Kolesnikov and Kumaresan (2013) and Kolesnikov et al. (2016) propose random 1-out-of-n OT and 1-out-of-∞ OT at a cost similar to that of 1-out-of-2 OT. The above schemes are in the semi-honest model; maliciouslysecure OT extensions were proposed Asharov et al. (2015b) and Keller et al. (2015) (the latter is usually seen as simpler and more eﬃcient of the two).
Custom PSI protocols have been explored in many diﬀerent settings with diﬀerent computation vs. communication costs and a variety of trust assumptions. Hazay and Lindell (2008) presented a simple and eﬃcient private set intersection protocol that assumes one party would perform computations using a trusted smartcard. Kamara et al. (2014) present a server-aided private set intersection protocol, which, in the case of the semi-honest server, computes the private set intersection of billion-element sets in about 580 seconds while sending about 12.4 GB of data. This is an example of asymmetric trust, which we discuss further in Section 7.2.
There has been much research on custom protocols beyond PSI, but it is surprisingly rare to ﬁnd custom protocols that substantially outperform fast generic MPC implementations of the same problem.

4
Implementation Techniques
Although secure computation protocols (as described in Chapter 3) were known since the 1980s, the ﬁrst full implementation of a generic secure computation system was Fairplay (Malkhi et al., 2004). Fairplay compiles a high-level description of a function into a circuit, described using a custom-designed Secure Hardware Description Language (SHDL). This circuit could then be executed as a protocol by a generator program and an evaluator program running over a network.
As a rough indication of the costs of MPC with Fairplay, the largest benchmark reported for Fairplay was ﬁnding the median of two sorted input arrays containing ten 16-bit numbers from each party. This required executing 4383 gates, and took over 7 seconds on a local area network (the time was then dominated by the oblivious transfer, not the garbled circuit execution). Modern MPC frameworks can execute millions of gates per second, and scale to circuits computing complex functions on large inputs, with hundreds of billions of gates.
Perhaps a factor of ten of the improvement can be attributed to general improvements in computing and network bandwidth (the Fairplay results are on a LAN with 618 Mbps, compared to 4 Gbps routinely available today), but the rest of the 3–4 orders of magnitude improvements are due primarily to the
65

66

Implementation Techniques

advances in implementation techniques described in this chapter. These include optimizations that reduce the bandwidth and computational costs of executing a GC protocol (Section 4.1), improved circuit generation (Section 4.2), and protocol-level optimizations (Section 4.3). We focus on improvements to Yao’s GC protocol, as the most popular generic MPC protocol, although some of the improvements discussed apply to other protocols as well. Section 4.4 brieﬂy surveys tools and languages that have been developed for implementing privacy-preserving applications using MPC.

4.1 Less Expensive Garbling

The main costs of executing a garbled circuits protocol are the bandwidth required to transmit the garbled gates and the computation required to generate and evaluate the garbled tables. In a typical setting (LAN or WAN and moderate computing resources such as smartphone or a laptop), bandwidth is the main cost of executing GC protocols. There have been many improvements to the traditional garbling method introduced in Section 3.1.2; we survey the most signiﬁcant ones next. Table 4.1 summarizes the impact of garbing improvements on the bandwidth and computation required to generate and evaluate a garbled gate. We described point-and-permute in Section 3.1.1; the other techniques are described in the next subsections.

Technique

size

calls to H

XOR AND XOR AND

classical

4

point-and-permute (1990) (§3.1.1)

4

row reduction (GRR3) (1999) (§4.1.1) 3

FreeXOR + GRR3 (2008) (§4.1.2)

0

half gates (2015) (§4.1.3)

0

444 4 4, 1 4, 1 3 4, 1 4, 1 3 0 4, 1 2 0 4, 2

Table 4.1: Garbling techniques (based on Zahur et al. (2015)). Size is number of “ciphertexts” (multiples of κ bits) transmitted per gate. Calls to H is the number of evaluations of H needed
to evaluate each gate. When the number is diﬀerent for the generator and evaluator, the numbers shown are the generator calls, evaluator calls.

4.1. Less Expensive Garbling

67

4.1.1 Garbled Row Reduction

Naor et al. (1999) introduced garbled row reduction (GRR) as a way to reduce
the number of ciphertexts transmitted per gate. The key insight is that it is
not necessary for each ciphertext to be an (unpredictable) encryption of a
wire label. Indeed, one of the entries in each garbled table can be ﬁxed to a predetermined value (say 0κ), and hence need not be transmitted at all. For example, consider the garbled table below, where a and b are the input wires, and c is the output:

H(a1 H(a0 H(a1 H(a0

b0) ⊕ c0 b0) ⊕ c0 b1) ⊕ c1 b1) ⊕ c0

Since c0 and c1 are just arbitrary wire labels, we can select c0 = H(a1 b0). Thus, one of the four ciphertexts in each gate (say, the ﬁrst one when it is sorted according point-and-permute order) will always be the all-zeroes string and does not need to be sent. We call this method GRR3 since only three ciphertexts need to be transmitted for each gate.
Pinkas et al. (2009) describe a way to further reduce each gate to two ciphertexts, applying a polynomial interpolation at each gate. Because this is not compatible with the FreeXOR technique described next, however, it was rarely used in practice. The later half-gates technique (Section 4.1.3) achieves two-ciphertext AND gates and is compatible with FreeXOR, so supersedes the interpolation technique of Pinkas et al. (2009).

4.1.2 FreeXOR
One of the results of Kolesnikov (2005) was the observation that the GESS sharing for XOR gates can be done without any growth of the share sizes (Section 3.6). Kolesnikov (2005) found a lower bound for the minimum share sizes, explaining the necessity of the exponential growth for independent secrets. This bound, however, did not apply to XOR gates (or, more generally, to “even” gates whose truth table had two zeros and two ones).
As introduced in Section 3.6, XOR sharing for GESS can simply be done as follows. Let s0, s1 ∈ DS be the output wire secrets. Choose R ∈R DS and

68

Implementation Techniques

set the shares sh10 = R, sh11 = s0 ⊕ s1 ⊕ R, sh20 = s0 ⊕ R, sh21 = s1 ⊕ R. The share reconstruction procedure on input sh1i, sh2j, outputs sh1i ⊕ sh2j. It is easy to verify that this allows the evaluator to reconstruct the correct gate output secret. Indeed, e.g., sh11 ⊕ sh21 = (s0 ⊕ s1 ⊕ R) ⊕ (s1 ⊕ R) = s0.
Denoting s0 ⊕ s1 = ∆, we observe that this oﬀset ∆ is preserved for the labels of each wire: sh10 ⊕ sh11 = sh20 ⊕ sh21 = s0 ⊕ s1 = ∆.
Because the shares on all of the gate’s wires have the same oﬀset, the above GESS XOR gate construction cannot be directly plugged into Yao’s GC, since standard Yao’s GC requires wires to be independently random. This breaks both correctness and security of GC. Indeed, correctness is broken because GESS XOR will not produce the pre-generated output wire secrets. Standard GC security proofs fail since GESS XOR creates correlations across wire labels, which are encryption keys. Even more problematic with respect to security is the fact that keys and encrypted messages are related to each other, creating circular dependencies.
FreeXOR: Integrating GESS XOR into GC. FreeXOR is a GC technique introduced by Kolesnikov and Schneider (2008b). Their work is motivated by the fact that in GESS an XOR gate costs nothing (no garbled table needed, and share secrets don’t grow), while traditional Yao’s GC pays full price of generating and evaluating a garbled table for XOR gates. The GC FreeXOR construction enables the use of GESS XOR construction by adjusting GC secrets generation to repair the correctness broken by the naïve introduction of GESS XOR into GC, and observing that a strengthening of the assumptions on the encryption primitives used in the construction of GC garbled tables is suﬃcient for security of the new scheme.
FreeXOR integrates GESS XOR into GC by requiring that all the circuit’s wires labels are generated with the same oﬀset ∆. That is, we require that for each wire wi of GC C and its labels wi0, wi1, it holds that wi0 ⊕ wi1 = ∆, for a randomly chosen ∆ ∈R {0, 1}κ. Introducing this label correlation enables GESS XOR to correctly reconstruct output labels.
To address the security guarantee, FreeXOR uses Random Oracle (RO) for encryption of gates’ output labels, instead of the weaker (PRG-based) encryption schemes allowed by Yao GC. This is necessary since inputs to diﬀerent instances of H are correlated by ∆, and furthermore diﬀerent values

4.1. Less Expensive Garbling

69

masked by H’s output are also correlated by ∆. The standard security deﬁnition of a PRG does not guarantee that the outputs of H are pseudorandom in this case, but a random oracle does. Kolesnikov and Schneider mention that a variant of correlation robustness, a notion weaker than RO, is suﬃcient (Kolesnikov and Schneider, 2008b). In an important theoretical clariﬁcation of the FreeXOR required assumptions, Choi et al. (2012b) show that the standard notion of correlation robustness is indeed not suﬃcient, and pin down the speciﬁc variants of correlation robustness needed to prove the security of FreeXOR.
The full garbling protocol for FreeXOR is given in Figure 4.1. The FreeXOR GC protocol proceeds identically to the standard Yao GC protocols of Figure 3.2, except that in Step 4, P2 processes XOR gates without needing any ciphertexts or encryption: for an XOR-gate Gi with garbled input labels wa = (ka, pa), wb = (kb, pb), the output label is directly computed as (ka ⊕ kb, pa ⊕ pb).
Kolesnikov et al. (2014) proposed a generalization of FreeXOR called ﬂeXOR. In ﬂeXOR, an XOR gate can be garbled using 0, 1, or 2 ciphertexts, depending on structural and combinatorial properties of the circuit. FleXOR can be made compatible with GRR2 applied to AND gates, and thus supports two-ciphertext AND gates. The half gates technique described in the next section, however, avoids the complexity of ﬂeXOR, and reduces the cost of AND gates to two ciphertexts with full compatibility with FreeXOR.
4.1.3 Half Gates
Zahur et al. (2015) introduced an eﬃcient garbling technique that requires only two ciphertexts per AND gate and fully supports FreeXOR. The key idea is to represent an AND gate as XOR of two half gates, which are AND gates where one of the inputs is known to one of the parties. Since a half gate requires a garbled table with two entries, it can be transmitted using the garbled row reduction (GRR3) technique with a single ciphertext. Implementing an AND gate using half gates requires constructing a generator half gate (where the generator knows one of the inputs) and an evaluator half gate (where the evaluator knows one of the inputs). We describe each half gate construction next, and then show how they can be combined to implement an AND gate.
Generator Half Gate. First, consider the case of an AND gate where the input wires are a and b and the output wire is c. The generator half-AND gate

70

Implementation Techniques

P

:

Boolean Circuit C implementing function F , security parameter κ.

Let H : {0, 1}∗ → {0, 1}κ+1 be a hash function modeled by a RO.

P

:

1. Randomly choose global key oﬀset ∆ ∈R {0, 1}κ.

2. For each input wire wi of C, randomly choose its 0 label, wi0 = (ki0, p0i ) ∈R {0, 1}κ+1.

Set the other label wi1 = (ki1, p1i ) = (ki0 ⊕ ∆, p0i ⊕ 1). 3. For each gate Gi of C in topological order

(a) If Gi is an XOR-gate wc = XOR(wa, wb) with input labels wa0 = (ka0, p0a), wb0 = (kb0, p0b), wa1 = (ka1, p1a), wb1 = (kb1, p1b):
i. Set garbled output value wc0 = (ka0 ⊕ kb0, p0a ⊕ p0b) ii. Set garbled output value wc1 = (ka0 ⊕ kb0 ⊕ ∆, p0a ⊕ p0b ⊕ 1).
(b) If Gi is a 2-input gate wc = gi(wa, wb) with garbled labels wa0 = (ka0, p0a), wb0 = (kb0, p0b), wa1 = (ka1, p1a), wb1 = (kb1, p1b): i. Randomly choose output label wc0 = (kc0, p0c) ∈R {0, 1}κ+1 ii. Set output label wc1 = (kc1, p1c) = (kc0 ⊕ ∆, p0c ⊕ 1).
iii. Create Gi’s garbled table. For each of 22 possible combinations of Gi’s input values va, vb ∈ {0, 1}, set

eva,vb

=

H

(

k

va a

|

|

k

vb b

|

|i)

⊕

wcgi (va,vb ).

Sort entries e in the table by the input pointers, placing entry eva,vb in position pvaa, pvbb .

4. Compute the output tables, as in Figure 3.1.

Figure 4.1: FreeXOR Garbling

4.1. Less Expensive Garbling

71

computes vc = va ∧ vb, where va is somehow known to the circuit generator. Then, when va is false, the generator knows vc is false regardless of vb; when va is true, vc = vb. We use a0, b0, and c0 to denote the wire labels encoding false for wires a, b, and c respectively. Using the FreeXOR design, the wire label for b is either b0 or b1 = b0 ⊕ ∆. The generator produces the two ciphertexts:
H(b0) ⊕ c0 H(b1) ⊕ c0 ⊕ va · ∆
These are permuted according to the pointer bits of b0, according to the point-and-permute optimization.
To evaluate the half gate and obtain va ∧ vb, the evaluator takes a hash of its wire label for b (either b0 or b1) and decrypts the appropriate ciphertext. If the evaluator has b0, it can compute H(b0) and obtain c0 (the correct semantic false output) by xor-ing it with the ﬁrst ciphertext. If the evaluator has b1 = b0 ⊕ ∆, it computes H(b1) to obtain c0 ⊕ va · ∆. If va = 0, this is c0; if va = 1, this is c1 = c0 ⊕ ∆. Intuitively, the evaluator will never know both b0 and b1, hence the inactive ciphertext appears completely random. This idea was also used implicitly by Kolesnikov and Schneider, 2008b, Fig. 2, in the context of programming components of a universal circuit.
Crucially for performance, the two ciphertexts can be reduced to a single ciphertext by selecting c0 according to the garbled row-reduction (Section 4.1.1).
Evaluator Half Gate. For the evaluator half gate, vc = va ∧ vb, the evaluator knows the value of va when the gate is evaluated, and the generator knows neither input. Thus, the evaluator can behave diﬀerently depending on the known plaintext value of wire a. The generator provides the two ciphertexts:
H(a0) ⊕ c0 H(a1) ⊕ c0 ⊕ b0
The ciphertexts are not permuted here—since the evaluator already knows va, it is ﬁne (and necessary) to arrange them deterministically in this order. When va is false, the evaluator knows it has a0 and can compute H(a0) to obtain output wire c0. When va is true, the evaluator knows it has a1 so can compute H(a1) to obtain c0 ⊕ b0. It can then xor this with the wire label it has for b, to obtain either c0 (false, when b = b0) or c1 = c0 ⊕ ∆ (true, when b1 = b0 ⊕ ∆),

72

Implementation Techniques

without learning the semantic value of b or c. As with the generator half gate, using garbled row-reduction (Section 4.1.1) reduces the two ciphertexts to a single ciphertext. In this case, the generator simply sets c0 = H(a0) (making the ﬁrst ciphertext all zeroes) and sends the second ciphertext.
Combining Half Gates. It remains to show how the two half gates can be used to evaluate a gate vc = va ∧ vb, in a garbled circuit, where neither party can know the semantic value of either input. The trick is for the generator to generate a uniformly random bit r, and to transform the original AND gate into two half gates involving r:
vc = (va ∧ r) ⊕ (va ∧ (r ⊕ vb))
This has the same value as va ∧ vb since it distributes to va ∧ (r ⊕ r ⊕ vb). The ﬁrst AND gate (va ∧ r) can be garbled with a generator half-gate. The second AND gate (va ∧ (r ⊕ vb)) can be garbled with an evaluator half-gate, but only if r ⊕ vb is leaked to the evaluator. Since r is uniformly random and not known to the evaluator, this leaks no sensitive information to the evaluator. The generator does not know vb, but can convey r ⊕ vb to the evaluator without any overhead, as follows. The generator will choose r to be the point-and-permute pointer bit of the false wire label on wire b, which is already chosen uniformly randomly. Thus, the evaluator learns r ⊕ vb directly from the pointer bit on the wire it holds for b without learning anything about vb.
Since the XOR gates do not require generating and sending garbled tables by using FreeXOR, we can compute an AND gate with only two ciphertexts, two invocations of H, and two “free” XOR operations. Zahur et al. (2015) proved the security of the half-gates scheme for any H that satisﬁes correlation robustness for naturally derived keys. In all settings, including low-latency local area networks, both the time and energy cost of bandwidth far exceed the cost of computing the encryptions (see the next section for how H is computed in this and other garbling schemes), and hence the half-gates method is preferred over any other known garbling scheme. Zahur et al. (2015) proved that no garbling scheme in a certain natural class of “linear” schemes1 could
1See Zahur et al. (2015) for a precise formulation of this class. Roughly speaking, the half-gates scheme is optimal among schemes that are allowed to call a random oracle and perform ﬁxed linear operations on wire labels / garbled gate information / oracle outputs, where the choice of these operations depends only on standard point-and-permute (Section 3.1.1) bits.

4.1. Less Expensive Garbling

73

use fewer than two ciphertexts per gate. Hence, under these assumptions the half-gates scheme is bandwidth-optimal for circuits composed of two-input binary gates (see Section 4.5 for progress on alternatives).
4.1.4 Garbling Operation
Network bandwidth is the main cost for garbled circuits protocols in most practical scenarios. However, computation cost of GC is also substantial, and is dominated by calls to the encryption function implementing the random oracle H in garbling gates, introduced in Section 3.1.2. Several techniques have been developed to reduce that cost, in particular by taking advantage of built-in cryptographic operations in modern processors.
Since 2010, Intel cores have included special-purpose AES-NI instructions for implementing AES encryption, and most processors from other vendors include similar instructions. Further, once an AES key is set up (which involves AES round keys generation), the AES encryption is particularly fast. This combination of incentives motivated Bellare et al. (2013) to develop ﬁxed-key AES garbling schemes, where H is implemented using ﬁxed-key AES as a cryptographic permutation.
Their design is based on a dual-key cipher (Bellare et al., 2012), where two keys are both needed to decrypt a ciphertext. Bellare et al. (2012) show how a secure dual-key cipher can be built using a single ﬁxed-key AES operation under the assumption that ﬁxed-key AES is eﬀectively a random permutation. Since the permutation is invertible, it is necessary to combine the permutation with the key using the Davies-Meyer construction (Winternitz, 1984): ρ(K) = π(K) ⊕ K. Bellare et al. (2013) explored the space of secure garbling functions constructed from a ﬁxed-key permutation, and found the fastest garbling method using π(K ||T)[1 : k] ⊕ K ⊕ X where K ← 2A ⊕ 4B, A and B are the wire keys, T is a tweak, and X is the output wire.
Gueron et al. (2015) pointed out that the assumption that ﬁxed-key AES behaves like a random permutation is non-standard and may be questionable in practice (Biryukov et al., 2009; Knudsen and Rijmen, 2007). They developed a fast garbling scheme based only on the more standard assumption that AES is a pseudorandom function. In particular, they showed that most of the performance beneﬁts of ﬁxed-key AES can be obtained just by carefully pipelining the AES key schedule in the processor.

74

Implementation Techniques

Note also that the FreeXOR optimization also requires stronger than standard assumptions (Choi et al., 2012b), and the half-gates method depends on FreeXOR. Gueron et al. (2015) showed a garbling construction alternative to FreeXOR that requires only standard assumptions, but requires a single ciphertext for each XOR gate. Moreover, their construction is compatible with a scheme for reducing the number of ciphertexts needed for AND gates to two (without relying on FreeXOR, as is necessary for half gates). The resulting scheme has higher cost than the half-gates scheme because of the need to transmit one ciphertext for each XOR, but shows that it is possible to develop eﬃcient (within about a factor of two of the cost of half gates) garbling schemes based only on standard assumptions.
4.2 Optimizing Circuits
Since the main cost of executing a circuit-based MPC protocol scales linearly with the size of the circuit, any reduction in circuit size will have a direct impact on the cost of the protocol. Many projects have sought ways to reduce the sizes of circuits for MPC. Here, we discuss a few examples.
4.2.1 Manual Design
Several projects have manually designed circuits to minimize the costs of secure computation (Kolesnikov and Schneider, 2008b; Kolesnikov et al., 2009; Pinkas et al., 2009; Sadeghi et al., 2010; Huang et al., 2011b; Huang et al., 2012a), often focusing on reducing the number of non-free gates when FreeXOR is used. Manual circuit design can take advantage of opportunities that are not found by automated tools, but because of the eﬀort required to manually design circuits, is only suitable for widely-used circuits. We discuss one illustrative example next; similar approaches have been used to design common building blocks optimized for secure computation such as multiplexers and adders, as well as more complex functions like AES (Pinkas et al., 2009; Huang et al., 2011b; Damgård et al., 2012a).
Oblivious permutation. Shuﬄing an array of data in an oblivious permutation is an important building block for many privacy-preserving algorithms, including private set intersection (Huang et al., 2012a) and square-root ORAM

4.2. Optimizing Circuits

75

a1

a2

f

b1

b2

Figure 4.2: X switching block

(Section 5.4). A basic component of an oblivious permutation, as well as many other algorithms, is a conditional swapper (also called an X switching block
by Kolesnikov and Schneider (2008b) and Kolesnikov and Schneider (2008a)), which takes in two inputs, a1 and a2, and produces two outputs, b1 and b2. Depending on the value of the swap bit p, either the outputs match the inputs (b1 = a1 and b2 = a2) or the outputs are the inputs in swapped order (b1 = a2 and b2 = b1). The swap bit p is known to the circuit generator, but must not be revealed to the evaluator. Kolesnikov and Schneider (2008b) provided a design for a swapper that takes advantage of FreeXOR and requires only a two-row
garbled table (which can be reduced to a single ciphertext using garbled row
reduction from Section 4.1.1). The swapper is implemented as:

b1 = a1 ⊕ (p ∧ (a1 ⊕ a2)) b2 = a2 ⊕ (p ∧ (a1 ⊕ a2))

(4.1)

The swapper is illustrated in Figure 4.2. There the block f is set to 0 if no swapping is desired, and to 1 to implement swapping. The f block is implemented as a conjunction of the input with the programming bit p,
so Figure 4.2 corresponds to Equation 4.1. Since wire outputs can be reused, p ∧ (a1 ⊕ a2) only needs to be evaluated
once. Referring back to the half-gates garbling and the notation of Section 4.1.3, when p is known to the generator, this conjunction is a generator half gate.
As noted above, applying GRR3 allows this to be implemented with a single

76

Implementation Techniques

ciphertext.2 With the above conditional swapper, a random oblivious permutation can be produced by the circuit generator by selecting a random permutation and conﬁguring the swappers in a Waksman network (Waksman, 1968) as necessary to produce it (Huang et al., 2012a). Several permutation block designs, including truncated permutation blocks, are presented by Kolesnikov and Schneider (2008a).
Low-depth circuits: optimizing for GMW. For most of this chapter, we focus on Yao’s GC, where a single round of communication is suﬃcient and the cost of execution scales with the size of the circuit. While most of the circuit-based optimizations apply to other protocols also, it is important to consider variations in cost factors when designing circuits for other protocols. In particular, in the GMW protocol (Section 3.2) each AND gate evaluation requires an OT, and hence a round of communication. AND gates on the same level can be batched and executed in the same round. Thus, unlike Yao’s GC where the cost of execution is independent of its depth, for GMW protocol executions the cost depends heavily on the depth of the circuit.
Choi et al. (2012a) built an eﬃcient implementation of GMW by using OT precomputation (Beaver, 1995) to reduce the on-line computation to a simple XOR, and OT extension protocols (Section 3.7.2) to reduce the overall cost of OT. A communication round (two messages) is still required during evaluation for each level of AND gates, however, so circuit execution time depends on the depth of the circuit. Schneider and Zohner (2013) provided further optimizations to the OT protocols for use in GMW, and designed lowdepth circuits for several speciﬁc problems. Since GMW supports FreeXOR, the eﬀective depth of a circuit is the maximum number of AND gates on any path. Schneider and Zohner (2013) were able to produce results on low-latency networks with GMW that were competitive with Yao’s GC implementations by designing low-depth circuits for addition, squaring, comparison, and computing Hamming weight, and by using single-instruction multiple data (SIMD) instructions to pack operations on multiple bits, following on the approach used by Sharemind (Bogdanov et al., 2008a).

2Indeed, the idea for half-gates garbling (Section 4.1.3) came from this X switching block design from Kolesnikov and Schneider (2008b).

4.2. Optimizing Circuits

77

4.2.2 Automated Tools
Boolean circuits go back to the earliest days of computing (Shannon, 1937). Because they have core applications in computing (e.g., in hardware components), there are a number of tools that have been developed to produce eﬃcient Boolean circuits. The output of some of these tools can be adapted to circuit-based secure computation.
CBMC-GC. Holzer et al. (2012) used a model checking tool as the basis for a tool that compiles C programs into Boolean circuits for use in a garbled circuits protocol. CBMC (Clarke et al., 2004) is a bounded model checker designed to verify properties of programs written in ANSI C. It works by ﬁrst translating an input program (with assertions that deﬁne the properties to check) into a Boolean formula, and then using a SAT solver to test the satisﬁability of that formula. CBMC operates at the level of bits in the machine, so the Boolean formula it generates is consistent with the program semantics at the bit level. When used as a model checker, CBMC attempts to ﬁnd a satisfying assignment of the Boolean formula corresponding to the input program. If a satisfying assignment is found, it corresponds to a program trace that violates an assertion in the program. CBMC unrolls loops and inlines recursive function calls up to the given model-checking bound, removing cycles from the program. For many programs, CBMC can statically determine the maximum number of loop iterations; when it cannot, programmers can use annotations to state this explicitly. When used in bounded model checking, an assertion is inserted that will be violated if the unrolling was insuﬃcient. Variables are replaced by bit vectors of the appropriate size, and the program is converted to single-static assignment form so that fresh variables are introduced instead of assigning to a given variable more than once.
Normally, CBMC would convert the program to a Boolean formula, but internally it is represented as a circuit. Hence, CBMC can be used as a component in a garbled circuits compiler that translates an input program in C into a Boolean circuit. To build CBMC-GC, Holzer et al. (2012) modiﬁed CBMC to output a Boolean circuit which can be then executed in circuit-based secure computation framework (such as the one from Huang et al. (2011b), which was used by CBMC-GC). Since CBMC was designed to optimize circuits for producing Boolean formulas for SAT solvers, modiﬁcations were

78

Implementation Techniques

done to produce better circuits for garbled circuit execution. In particular, XOR gates are preferred in GC execution due to the FreeXOR technique (whereas the corresponding costs in model checking favor AND gates). To minimize the number of non-free gates, Holzer et al. (2012) replaced the built-in circuits CBMC would use for operations like addition and comparison, with designs that minimize costs with free XOR gates.
TinyGarble. Another approach to generating circuits for MPC is to leverage the decades of eﬀort that have been invested in hardware circuit synthesis tools. Hardware description language (HDL) synthesis tools transform a high-level description of an algorithm, which could be written in a programming language or common HDL language such as Verilog, into a Boolean circuit. A synthesis tool optimizes a circuit to minimize its size and cost, and then outputs a netlist, which is a straightforward description of a circuit as a list of logic gates with connected inputs and outputs.
Conventional hardware synthesis tools, however, do not generate circuits suitable for MPC protocols because they generate circuits that may have cycles and they are designed to optimize for diﬀerent costs that are encountered the MPC execution (in particular, they assume the cost of gates based on hardware implementations). With TinyGarble, Songhori et al. (2015) overcame these problems in adapting circuit synthesis tools for generating circuits for MPC, and Yao’s GC in particular.
The approach of TinyGarble is to use sequential logic in a garbled circuit. In a sequential circuit, instead of just connecting gates in a combinational way where each gate’s outputs depend only on its inputs and no cycles are permitted, a circuit also can maintain state. In hardware, state would be stored in a physical memory element (such as a ﬂip-ﬂop), and updated with each clock cycle. To execute (generate and send) a garbled circuit, TinyGarble instead unrolls a sequential circuit, so the stored state is an additional input to the circuit, and new garbled gates are generated for each iteration. This means the representation is compact, even for large circuit executions, which allows performance improvement due to the ability to store the circuit in processor cache and avoid expensive RAM accesses. This method trades oﬀ a slight increase in the number of garbled gates to execute for a reduction in the size of the circuit representation.

4.3. Protocol Execution

79

In addition, TinyGarble uses a custom circuit synthesis library to enable the circuit synthesis tool to produce cost-eﬃcient circuits for MPC. This includes a library of custom-designed circuits for common operations like a multiplexer, based on previous designs (Section 4.2.1). Another input to a circuit synthesis tool is a technology library, that describes the logic units available on the target platform and their costs and constraints, and use this to map a structural circuit to a gate-level netlist. To generate circuits that take advantage of FreeXOR, the custom library developed for TinyGarble sets the area of an XOR gate to 0, and the area of other gates to a cost that reﬂects the number of ciphertexts required. When the circuit synthesis tool is conﬁgured to minimize circuit area, this produces circuits with an optimized number of non-XOR gates.
Songhori et al. (2015) report a 67% reduction in the number of non-XOR gates in 1024-bit multiplication compared to automatically-generated circuits for same function. For a more diverse function set (implementing a MIPS processor), the circuit generation has modest performance improvement as compared to prior work (the synthesized MIPS CPU circuit reduces the number of non-XOR gates by less than 15% compared to a straightforward assembly of MIPS CPU from constituent blocks).
4.3 Protocol Execution
The main limit on early garbled circuit execution frameworks, starting with Fairplay (Malkhi et al., 2004), is that they needed to generate and store the entire garbled circuit. Early on, researchers focused on the performance for smaller circuits and developed tools that naïvely generate and store the entire garbled circuit. This requires a huge amount of memory for all but trivial circuits, and limited the size of inputs and complexity of functions that could be computed securely. In this section, we discuss various improvements to the way MPC protocols are executed that have overcome these scaling issues and eliminated much of the overhead of circuit execution.
Pipelined Execution. Huang et al. (2011b) introduced garbled circuit pipelining, which eliminated the need for either party to ever store the entire garbled circuit. Instead of generating the full garbled circuit and then sending it, the circuit generation and evaluation phases are interleaved. Before the circuit execution begins, both parties instantiate the circuit structure, which is small

80

Implementation Techniques

relative to the size of the full garbled circuit since it can reuse components and is made of normal gate representations instead of non-reusable garbled gates.
To execute the protocol, the generator produces garbled gates in an order that is determined by the topology of the circuit, and transmits the garbled tables to the evaluator as they are produced. As the client receives them, it associates each received garbled table with the corresponding gate of the circuit. Since the order of generating and evaluating the circuit is ﬁxed according to the circuit (and must not depend on the parties’ private inputs), keeping the two parties synchronized requires essentially no overhead. As it evaluates the circuit, the evaluator maintains a set of live wire labels and evaluates the received gates as soon as all their inputs are ready. This approach allows the storage for each gate to be reused after it is evaluated, resulting in much smaller memory footprint and greatly increased performance.
Compressing Circuits. Pipelining eliminates the need to store the entire garbled circuit, but still requires the full structural circuit to be instantiated. Sequential circuits, mentioned earlier in Section 4.2.2, are one way to overcome this by enabling the same circuit structure to be reused but require a particular approach to circuit synthesis and some additional overhead to maintain the sequential circuit state. Another approach, initiated by Kreuter et al. (2013), uses lazy generation from a circuit representation that supports bounded loops. Structural circuits are compactly encoded using a Portable Circuit Format (PCF), which is generated by a circuit compiler and interpreted as the protocol executes. The input to the the circuit compiler is intermediatelevel stack machine bytecode output by the LCC front-end compiler (Fraser and Hanson, 1995), enabling the system to generate MPC protocols from diﬀerent high-level programs. The circuit compiler takes in an intermediatelevel description of a program to execute as an MPC, and outputs a compressed circuit representation. This representation is then used as the input to interpreters that execute the generator and evaluator for a Yao’s GC protocol, although the same representation could be used for other interpreters to executed diﬀerent circuit-based protocols.
The key insight enabling PCF’s scalability is to evaluate loops without unrolling them by reusing the same circuit structure while having each party locally maintain the loop index. Thus, new garbled tables can be computed

4.3. Protocol Execution

81

as necessary for each loop execution, but the size of the circuit, and local memory needed, does not grow with the number of iterations. PCF represents Boolean circuits in a bytecode language where each input is a single bit, and the operations are simple Boolean gates. Additional operations are provided for duplicating wire values, and for making function calls (with a return stack) and indirect (only forward) jumps. Instructions that do not involve executing Boolean operators do not require any protocol operations, so can be implemented locally by each party. To support secure computation, garbled wire values are represented by unknown values, which cannot be used as the conditions for conditional branches. The PCF compiler implemented several optimizations to reduce the cost of the circuits, and was able to scale to circuits with billions of gates (e.g., over 42 billion gates, of which 15 billion were non-free, to compute 1024-bit RSA).
Mixed Protocols. Although generic MPC protocols such as Yao’s GC and GMW can execute any function, there are often much more eﬃcient ways to implement speciﬁc functions. For example, additively homomorphic encryption schemes (including Paillier (1999) and Damgård and Jurik (2001)) can perform large additions much more eﬃciently than can be done with Boolean circuits.
With homomorphic encryption, instead of jointly computing a function using a general-purpose protocol, P1 encrypts its input and sends it to P2. P2 then uses the encryption homomorphism to compute (under encryption) a function on the encrypted input, and sends the encrypted result back to P1. Unless the output of the homomorphic computation is the ﬁnal MPC result, its plaintext value cannot be revealed. Kolesnikov et al. (2010) and Kolesnikov et al. (2013) describe a general mechanism for converting between homomorphically-encrypted and garbled GC values. The party that evaluates the homomorphic encryption, P2, generates a random mask r, which is added to the output of the homomorphic encryption, Enc(x), before being sent to P1 for decryption. Thus the value received by P1 is Enc(x + r), which P1 can decrypt to obtain x + r. To enter x into the GC evaluation, P1 provides x + r and P2 provides r as their inputs into the GC. The garbled circuit performs the subtraction to cancel out the mask, producing a garbled representation of x. Several works have developed customized protocols for particular tasks that combine homomorphic encryption with generic MPC (Brickell et al., 2007;

82

Implementation Techniques

Huang et al., 2011c; Nikolaenko et al., 2013a; Nikolaenko et al., 2013b). The TASTY compiler (Henecka et al., 2010) provides a language for
describing protocols involving both homomorphic encryption and garbled circuits. It compiles a high-level description into a protocol combining garbled circuit and homomorphic encryption evaluation. The ABY (Arithmetic, Boolean, Yao) framework of Demmler et al. (2015) support Yao’s garbled circuits and two forms of secret sharing: arithmetic sharings based on Beaver multiplication triples (Section 3.4) and Boolean sharings based on GMW (Section 3.2). It provides eﬃcient methods for converting between the three secure encodings, and for describing a function that can be executed using a combination of the three protocols. Kerschbaum et al. (2014) developed automated methods for selecting which protocol performs best for diﬀerent operations in a secure computation.
Outsourcing MPC. Although it is possible to run MPC protocols directly on low-power devices, such as smartphones (Huang et al., 2011a), the high cost of bandwidth and the limited energy available for mobile devices makes it desirable to outsource the execution of an MPC protocol in a way that minimizes the resource needed for the end user device without compromising security. Several schemes have been proposed for oﬀ-loading most of the work of GC execution to an untrusted server including Salus (Kamara et al., 2012) and (Jakobsen et al., 2016).
We focus here on the scheme from Carter et al. (2016) (originally published earlier (Carter et al., 2013)). This scheme targets the scenario where a mobile phone user wants to outsource the execution of an MPC protocol to a cloud service. The other party in the MPC is a server that has high bandwidth and computing resources, so the primary goal of the design is to make the bulk of the MPC execution be between the server and cloud service, rather than between the server and mobile phone client. The cloud service may be malicious, but it is assumed not to collude with any other party. It is a requirement that no information about either the inputs or outputs of the secure function evaluation are leaked to the cloud service. This security notion of a non-colluding cloud is formalized by Kamara et al. (2012). The Carter et al. (2016) protocol supports malicious security, building on several techniques, some of which we discuss in Section 6.1. To obtain the inputs with lower

4.4. Programming Tools

83

resources from the client, the protocol uses an outsourced oblivious transfer protocol. To provide privacy of the outputs, a blinding circuit is added to the original circuit that masks the output with a random pad known only to the client and server. By moving the bulk of the garbled circuit execution cost to the cloud service, the costs for the mobile device can be dramatically reduced.
4.4 Programming Tools
Many programming tools have been developed for building privacy-preserving applications using MPC. These tools vary by the input languages they support, how they combine the input program into a circuit and how the output is represented, as well as the protocols they support. Table 4.2 provides a highlevel summary of selected tools for building MPC applications. We don’t attempt to provide a full survey of MPC programming tools here, but describe one example of a secure computation programming framework next.
Obliv-C. The Obliv-C language is a strict extension of C that supports all C features, along with new data types and control structures to support dataoblivious programs that will be implemented using MPC protocols. Obliv-C is designed to provide high-level programming abstractions while exposing the essential data-oblivious nature of such computations. This allows programmers to implement libraries for data-oblivious computation that include low-level optimizations without needing to specify circuits.
In Obliv-C, a datatype declared with the obliv type modiﬁer is oblivious to the program execution. It is represented in encrypted form during the protocol execution, so nothing in the program execution can depend on its semantic value. The only way any values derived from secret data can be converted back to a semantic value is by calling an explicit reveal function. When this function is invoked by both parties on the same variable, the value is decrypted by the executing protocol, and its actual value is now available to the program.
Control ﬂow of a program cannot depend on oblivious data since its semantic value is not available to the execution. Instead, Obliv-C provides oblivious control structures. For example, consider the following statement where x and y are obliv variables:
obliv if (x > y) x = y;

84

Implementation Techniques

Since the truth value of the x > y condition will not be known even at runtime, there is no way for the execution to know if the assignment occurs. Instead, every assignment statement inside an oblivious conditional context must use “multiplexer” circuits that select based on the semantic value of the comparison condition within the MPC whether to perform the update or have no eﬀect. Within the encrypted protocol, the correct semantics are implemented to ensure semantic values are updated only on the branch that would actually be executed based on the oblivious condition. The program executing the protocol (or an analyst reviewing its execution) cannot determine which path was actually executed since all of the values are encrypted within the MPC.
Updating a cleartext value z within an oblivious conditional branch would not leak any information, but would provide unexpected results since the update would occur regardless of whether or not the oblivious conditional is true. Obliv-C’s type system protects programmers from mistakes where non-obliv values are updated in conditional contexts. Note that the type checking is not necessary for security since the security of the obliv values is enforced at runtime by the MPC protocol. It only exists to help the programmers avoid mistakes by providing compile time errors for non-sensical code.
To implement low-level libraries and optimizations, however, it is useful for programmers to escape that type system. Obliv-C provides an unconditional block construct that can be used within an oblivious context but contains code that executes unconditionally. Figure 4.3 shows an example of how an unconditional block (denoted with ∼obliv(var)) can be used to implement oblivious data structures in Obliv-C. This is an excerpt of an implementation of a simple resizable array implemented using a struct that contains oblivious variables representing the content and actual size of the array, and an opaque variable representing its maximum possible size. While the current length of the array is unknown (since we might append() while inside an obliv if), we can still use an unconditional block to track a conservative upper bound of the length. We use this variable to allocate memory space for an extra element when it might be needed.
This simple example illustrates how Obliv-C can be used to implement low-level optimizations for complex oblivious data structures, without needing to implement them at the level of circuits. Obliv-C has been used to implement libraries for data-oblivious data structures supporting random access memory

4.5. Further Reading

85

typedef struct { obliv int ∗arr; obliv int sz; int maxsz;
} Resizeable;
void writeArray(Resizeable ∗r, obliv int index, obliv int val) obliv;
// obliv function, may be called from inside oblivious conditional context void append(Resizable ∗r, obliv int val) obliv {
∼obliv(_c) { r→arr = reallocateMem(r→arr, r→maxsz + 1); r→maxsz++;
} writeArray(r, r→sz, val); r→sz++; }
Figure 4.3: Example use of an unconditional block (extracted from Zahur and Evans (2015)).
including Square-Root ORAM (Section 5.4) and Floram (Section 5.5), and to implement some of the largest generic MPC applications to date including stable matching at the scale needed for the national medical residency match (Doerner et al., 2016), an encrypted email spam detector (Gupta et al., 2017), and a commercial MPC spreadsheet (Calctopia, Inc., 2017).
4.5 Further Reading
Many methods for improving garbling have been proposed beyond the ones covered in Section 4.1. As mentioned in Section 4.1.3, the half-gates scheme is bandwidth optimal under certain assumptions. Researchers have explored several ways to reduce bandwidth by relaxing those assumptions including garbling schemes that are not strictly “linear” in the sense considered in the optimality proof (Kempka et al., 2016), using high fan-in gates (Ball et al., 2016) and larger lookup tables (Dessouky et al., 2017; Kennedy et al., 2017). MPC protocols are inherently parallelizable, but additional circuit design eﬀort may be helpful for maximizing the beneﬁts of parallel execution (Buescher and Katzenbeisser, 2015). GPUs provide further opportunities for speeding up

86

Implementation Techniques

Tool / Input Language ABY / Custom low-level Demmler et al., 2015
EMP / C++ Library Wang et al., 2017a
Frigate / Custom (C-like) Mood et al., 2016
Obliv-C / C + extensions Zahur and Evans, 2015
PICCO / C + extensions Zhang et al., 2013

Output/Execution Virtual machine executes protocol Compiled to executable Interprets compact Boolean circuit Source-to-source (C) Source-to-source (C)

Protocols Arithmetic, Boolean sharings; GC (§4.3) Authenticated Garbling (§6.7), others Yao’s GC, malicioussecure with DUPLO Yao’s GC, Dual Execution (§7.6) 3+-party secretsharing

Table 4.2: Selected MPC Programming tools. In this table, we focus on tools that are recently or actively developed, and that provide state-of-the-art performance. The DUPLO extension is from (Kolesnikov et al., 2017b). All of the listed tools are available as open source code: ABY at https://github.com/encryptogroup/ABY; EMP at https://github.com/emp-toolkit; Frigate at https://bitbucket.org/bmood/frigaterelease; Obliv-C at https://oblivc.org; PICCO at https://github.com/PICCO-Team/picco.

MPC execution (Husted et al., 2013). Many other MPC programming tools have been developed. Wysteria (Ras-
togi et al., 2014) provides a type system that supports programs that combine local and secure computation. SCAPI (Bar-Ilan Center for Research in Applied Cryptography and Cyber Security, 2014; Ejgenberg et al., 2012) provides Java implementations of many secure computation protocols. We focused on tools mostly building on garbled circuit protocols, but many tools implement other protocols. For example, the SCALE-MAMBA system (Aly et al., 2018) compiles programs written in a custom Python-like language (MAMBA) to execute both the oﬄine and online phases of secure computation protocols built on BDOZ and SPDZ (Section 6.6.2). We focused on programming tools in the dishonest majority setting, but numerous tools have been built supporting other threat models. In particular, very eﬃcient implementations are possible with assuming three-party, honest-majority model, most notably Sharemind (Bogdanov et al., 2008b) and Araki et al. (2017) (Section 7.1.2).

5
Oblivious Data Structures
Standard circuit-based execution is not well-suited to programs relying on random access to memory. For example, executing a simple array access where the index is a private variable (we use the < z > notation to indicate that the variable z is private, with its semantic value protected by MPC),
a[<i>] = x requires a circuit that scales linearly in the size of the array a. A natural circuit consists of N multiplexers, as shown in Figure 5.1. This method, where every element of a data structure is touched to perform an oblivious read or an update, is known as linear scan. For practical computations on large data structures, it is necessary to provide sublinear access operations. However, any access that only touches a subset of the data potentially leaks information about protected data in the computation.
In this chapter, we discuss several extensions to circuit-based MPC designed to enable eﬃcient applications using large data structures. One strategy for providing sublinear-performance data structures in oblivious computation is to design data structures that take advantage of predictable access patterns. Indeed, it is not necessary to touch the entire data structure if the parts that are accessed do not depend on any private data (Section 5.1). A more general strategy, however, requires providing support for arbitrary memory access with sublinear
87

88

i

a[0]

== 0

x

i a[1]

== 1

Oblivious Data Structures

x

i a[2]

x

== 2

…

a'[0]

a'[1]

a'[2]

Figure 5.1: A single array access requiring N multiplexers.
a[0] a[1] a[N-1] ×2 ×2 … ×2 a'[0] a'[1] a'[N-1]
Figure 5.2: Oblivious array update with predictable access pattern.

cost. This cannot be achieved within a general-purpose MPC protocol, but can be achieved by combining MPC with oblivious RAM (Sections 5.2–5.5).
5.1 Tailored Oblivious Data Structures
In some programs the access patterns are predictable and known in advance, even though they may involve private data. As a simple example, consider this loop that doubles all elements of an array of private data:
for (i = 0; i < N; i++) { a[i] = 2 ∗ a[i]
}
Instead of requiring N linear scan array accesses for each iteration (with Θ(N2) total cost), the loop could be unrolled to update each element directly, as shown in Figure 5.2. Since the access pattern required by the algorithm is completely predictable, there is no information leakage in just accessing each element once to perform its update.
Most algorithms access data in a way that is not fully and as obviously predictable as in the above example. Conversely, usually it is done in a way that

5.1. Tailored Oblivious Data Structures

89

is not fully data-dependent. That is, it might be a priori known (i.e., known independently of the private inputs) that some access patterns are guaranteed to never occur in the execution. If so, an MPC protocol that does not include the accesses that are known to be impossible regardless of the private data may still be secure. Next, we describe oblivious data structures designed to take advantage of predictable array access patterns common in many algorithms.
Oblivious Stack and Queue. Instead of implementing a stack abstraction using an array, an eﬃcient oblivious stack takes advantage of the inherent locality in stack operations—they always involve the top of the stack. Since stack operations may occur in conditional contexts, though, the access pattern is not fully predictable. Hence, an oblivious stack data structure needs to provide conditional operations which take as an additional input a protected Boolean variable that indicates whether the operation actually occurs. For example, the <stack>.condPush(<b>, <v>) operation pushes v on the stack when the semantic value of b is true, but has no impact on the semantic state of the stack when b is false.
A naïve implementation of condPush would be to use a series of multiplexers to select for each element of the resulting stack either the current element, stack[i] when b is false, or the previous element, stack[i − 1] (or pushed value v, for the top element) when b is true. As with a linear scan array, however, this implementation would still require a circuit whose size scales with the maximum current size of the stack for each stack operation.
A more eﬃcient data structure uses a hierarchical design, dividing the stack representation into a group of buﬀers where each has some slack space so it is not necessary to touch the entire data structure for each operation. The design in Zahur and Evans (2013), inspired by Pippenger and Fischer (1979), divides the stack into buﬀers where the level-i buﬀer has 5 × 2i data slots. The top of the stack is represented by level 0. For each level, the data slots are managed in blocks/groups of 2i slots; thus, for level 1, each data is always added in a block of two data items. For each block, a single bit is maintained that tracks whether the block is currently empty. For each level, a 3-bit counter, t, keeps track of the location of the next empty block available (0–5).
Figure 5.3 depicts an example of a conditional stack which starts oﬀ with some data already inserted and two condPush operations are illustrated. The

90

Oblivious Data Structures

starting state in the ﬁgure depicts a state where none of the t values exceed 3, and hence there is guaranteed suﬃcient space for two conditional push operations. A multiplexer is used to push the new value into the correct slot based on the t0 value, similar to the naïve stack circuit design described above. However, in this case, the cost is low since this is applied to a ﬁxed 5-element array. After two conditional push operations, however, with the starting t0 = 3, the level 0 buﬀer could be full. Hence, it is necessary to perform a shift, which either has no impact (if t0 ≤ 3), or pushes one block from level 0 into level 1 (as shown in Figure 5.3). After the shift, two more conditional push operations can be performed. This hierarchical design can extend to support any size stack, with shifts for level i generated for every 2i condPush operations. A similar design can support conditional pop operations, where left shifts are required for level i after every 2i condPop operations. The library implementing the conditional stack keeps track of the number of stack operations to know the minimum and maximum number of possible elements at each level, and inserts the necessary shifts to prevent overﬂow and underﬂows.
For all circuit-based MPC protocols, the primary cost is the bandwidth required to execute the circuit, which scales linearly in the number of gates. The cost depends on the maximum possible number of elements at each point in the execution. For a stack known to have at most N elements, k operations access level i at most k/2i times since we need a right shift for level i after every 2i conditional push operations (and similarly, need a left shift after 2i conditional pop operations).
However, the operations at the deeper levels are more expensive since the size of each block of elements at level i is 2i, requiring Θ(2i) logic gates to move. So, we need Θ(2i × k/2i) = Θ(k)-sized circuits at level i. Thus, with Θ(log N) levels, the total circuit size for k operations is Θ(k log N) and the amortized cost for each conditional stack operation is Θ(log N).
Other Oblivious Data Structures. Zahur and Evans (2013) also present a similar oblivious hierarchical queue data structure, essentially combining two stacks, one of which only supports push operations and the other that only supports pop operations. Since these stacks only need to support one of the conditional operations, instead of using a 5-block buﬀer at each level they use a 3-block buﬀer. Moving data between the two stacks requires an additional

5.1. Tailored Oblivious Data Structures

91

Level 0

Level 1

293

t0 = 3

t1 = 2

condPush(True, 7)

7293

t0 = 4

t1 = 2

condPush(True, 8)

87293

t0 = 5

t1 = 2

shift(0)

827 t0 = 3

t1 = 3

93

47 54 47 54 47 54 47 54

Level 2
t2 = 1 t2 = 1 t2 = 1 t2 = 1

Figure 5.3: Illustration of two conditional push operations for oblivious stack. The shift(0) operation occurs after every two condPush operations.

multiplexer. Similarly to the oblivious stack, the amortized cost for operations on the oblivious queue is Θ(log N).
Data structures designed to provide sublinear-cost oblivious operations can be used for a wide range of memory access patterns, whenever there is suﬃcient locality and predictability in the code to avoid the need to provide full random access. Oblivious data structures may also take advantage of operations that can be batched to combine multiple updates into single data structure scan. For example, Zahur and Evans (2013) present an associative map structure where a sequence of reads and writes with no internal dependencies can be batched into one update. This involves constructing the new value of the data structure by sorting the original values and the updates into a array, and only keeping the most recent value of each key-value pair. This allows up to N updates to be performed with a circuit of size Θ(N log2 N), with an amortized cost per update of Θ(log2 N).
The main challenge is writing programs to take advantage of predictable memory access patterns. A sophisticated compiler may be able to identify predictable access patterns in typical code and perform the necessary transformations automatically, but this would require a deep analysis of the code and no suitable compiler currently exists. Alternatively, programmers can manually rewrite code to use libraries that implement the oblivious data structures and manage all of the bookkeeping required to carry out the necessary shift

92

Oblivious Data Structures

operations. Another strategy for building eﬃcient oblivious data structures is to build upon a general-purpose Oblivious RAM, which is the focus of the rest of this chapter.
5.2 RAM-Based MPC
Oblivious RAM (ORAM) was introduced by Goldreich and Ostrovsky (1996) as a memory abstraction that allows arbitrary read and write operations without leaking any information about which locations are accessed. The original ORAM targeted the client-server setting, where the goal is to enable a client to outsource data to an untrusted server and perform memory operations on that outsourced data without revealing the data or access patterns to the server.
Ostrovsky and Shoup (1997) ﬁrst proposed the general idea of using ORAM to support secure multi-party computation by splitting the role of the ORAM server between two parties. Gordon et al. (2012) were the ﬁrst to propose a speciﬁc method for adapting ORAM to secure computation (RAM-MPC, also often called RAM-SC). In (Gordon et al., 2012), the ORAM state is jointly maintained by both parties (client and server) within a secure computation protocol. The key idea is to have each party store a share of the ORAM’s state, and then use a general-purpose circuit-based secure computation protocol to execute the ORAM access algorithms.
An ORAM system speciﬁes an initialization protocol that sets up the (possibly already populated) storage structure, and an access protocol that implements oblivious read and write operations on the structure. To satisfy the oblivious memory goals, an ORAM system must ensure that the observable behaviors reveal nothing about the elements that are accessed. This means the physical access patterns produced by the access protocol for any same-length access sequences must be indistinguishable.
The initialization protocol takes as input an array of elements and initializes an oblivious structure with those elements without revealing anything about the initial values other than the number of elements. Assuming the access protocol is secure, it is always possible to implement the initialization protocol by performing the access protocol once for each input element. The costs of initializing an ORAM this way, however, may be prohibitive, especially as used in secure computation.

5.3. Tree-Based RAM-MPC

93

The RAM-MPC construction proposed by Gordon et al. (2012) implemented an ORAM-based secure multi-party computation. To implement an ORAM access, a circuit is executed within a 2PC that translates the oblivious logical memory location into a set of physical locations that must be accessed to perform the access. The physical locations are then revealed to the two parties, but the ORAM design guarantees that these leak no information about the logical location accessed. Each party then retrieves the data shares stored in those locations, and passes them into the MPC. To complete the access, a logical write occurs, as follows. The circuit executing within the MPC produces new data elements to be written back to each of the physical locations. These locations are output in plaintext, together with the data shares to be written into parties’ local physical storage.
Gordon et al. (2012) proved that combining semi-honest 2PC with the semi-honest ORAM protocol where ORAM state is split between the two parties and operations are implemented within the 2PC results in a secure RAM-based MPC in the semi-honest model.1
5.3 Tree-Based RAM-MPC
The construction of Gordon et al. (2012) builds on the tree-based ORAM design of Shi et al. (2011). The underlying data structure in the tree-based ORAM storing N elements is a binary tree of height log N, where each node in the tree holds log N elements. Each logical memory location is mapped to a random leaf node, and the logical index and value of the data element is stored in encrypted form in one of the nodes along the path between the tree root and that leaf. To access a data item, the client needs to map the item’s location to its associated leaf node and retrieve from the server all nodes along the path from the root to that node. Each of the nodes along the path is decrypted and scanned to check if it is the requested data element.
A careful reader will notice the following technical diﬃculty. Performing data look up requires mapping the logical location to the leaf node. However, the size of this map is linear in N, and hence the map cannot be maintained by the client with sublinear storage. The solution is to store the location map
1RAM-MPC can also be made to work in the malicious security model (Afshar et al., 2015), but care must be taken to ensure that data stored outside the MPC is not corrupted.

94

Oblivious Data Structures

by the server using another instance of tree-based ORAM. Importantly, since

the size of the index map is smaller than the size of the data, the size of the second ORAM tree can be smaller than N, as each item in the second tree can

store several mappings. To support larger ORAMs, a sequence of look-up trees

might be used, where only the smallest tree is stored by the client.

In RAM-MPC, the trees are secret-shared between the two parties. To

access an element, the parties execute a 2PC protocol that takes the shares of

the logical index and outputs (in shares to each party) the physical index for

the next level. A linear scan is used on the reconstructed elements along the

search path to identify the one corresponding to the requested logical index.

In the ﬁnal tree, the shares of the requested data element are output to the

higher-level MPC protocol. Note that the data in each node could also be stored

in an ORAM to avoid the need for a linear scan, but since the bucket sizes are

small here and (at least with this ORAM design) there is substantial overhead

required to support an ORAM, a simple linear scan is preferred.

To complete the data access procedure, we need to ensure that the subse-

quent access results in an oblivious access pattern, even if the same element is

accessed again. To achieve this in tree-based ORAMs, the accessed logical

location is re-mapped to a random leaf node, and the updated data value is

inserted into the root node in the tree, ensuring its availability in the subsequent access. To prevent the root node from overﬂowing, the protocol of Shi et al.

(2011) uses a balancing mechanism that pushes items down the tree after each ORAM access. Randomly-selected elements are evicted and are moved down

the tree by updating both of the child nodes of the selected nodes (this is done

to mask which leaf-path contains the evicted element).

Intuitively, the access pattern is indistinguishable from a canonical one,

and hence an adversary cannot distinguish between two accesses. Indeed, every

time an element is accessed, it is moved to a random-looking location. Further,

every access retrieves a complete path from the root to a leaf, so as long as the

mapping between logical locations and leaves is random and not revealed to

the server, the server learns no information about which element is accessed.

The scheme does have the risk that a node may overﬂow as evicted elements

are moved down the tree, and not be able to store all of the elements required.

The probability of an overﬂow after k ORAM accesses with each node holding

O(log(

kN δ

))

elements

is

shown

by

Shi

et

al.

(2011)

to

be

less

than

δ,

which

5.3. Tree-Based RAM-MPC

95

is why the number of elements in each node is set to O(log N) to make the overﬂow probability negligible. The constant factors matter, however. Gordon et al. (2012) simulated various conﬁgurations to ﬁnd that a binary search on a 216 element ORAM (that is, only 16 operations) could be implemented with less than 0.0001 probability of overﬂow with a bucket size of 32.
Variations on this design improved the performance of tree-based ORAM for MPC have focused on using additional storage (called a stash) to store overﬂow elements and reduce the sizes of the buckets needed to provide negligible failure probability, as well as on improving the eviction algorithm.
Path ORAM. Path ORAM (Stefanov et al., 2013) added a stash to the design as a ﬁxed-size auxiliary storage for overﬂow elements, which would be scanned on each request. The addition of a small stash enabled a more eﬃcient eviction strategy than the original binary-tree ORAM. Instead of selecting two random nodes at each level for eviction and needing to update both child nodes of the selected nodes to mask the selected element, Path ORAM performed evictions on the access path from the root to the accessed node, moving elements along this path from the root towards the leaves as much as possible. Since this path is already accessed by the request, no additional masking is necessary to hide which element is evicted. The Path ORAM design was adapted by Wang et al. (2014a) to provide a more eﬃcient RAM-MPC design, and they presented a circuit design for a more eﬃcient eviction circuit.
Circuit ORAM. Further advances in RAM-MPC designs were made both by adapting improvements in traditional client-server ORAM designs to RAMMPC, as well as by observing diﬀerences between the costs and design space options between the MPC and traditional ORAM setting and designing ORAM schemes focused on the needs of MPC.
Wang et al. (2014a) argued that the main cost metric for ORAM designs used in circuit-based secure computation should be circuit complexity, whereas client-server designs were primarily evaluated based on (client-server) bandwidth metrics. When used within an MPC protocol, the execution costs of an ORAM are dominated by the bandwidth costs of executing the circuits needed to carry out ORAM accesses and updates within the MPC protocol.
Wang et al. (2015b) proposed Circuit ORAM, an ORAM scheme designed

96

Oblivious Data Structures

speciﬁcally for optimal circuit complexity for use in RAM-MPC. Circuit

ORAM replaced the complex eviction method of Path ORAM with a more

eﬃcient design where the eviction can be completed with a single scan of the

blocks on the eviction path, incorporating both the selection and movement of

data blocks within a single pass. Their key insight is to perform two metadata

scans ﬁrst, so as to determine which blocks are to be moved, together with their

new locations. These scans can be run on the metadata labels, which are much

smaller than the full data blocks. After these scans have determined which

blocks to move, the actual data blocks can be moved using a single pass along

the path from the stash-root to the leaf, storing at most one block of data to

relocate as it proceeds.

Because the metadata scans are on much smaller data than the actual

blocks, the concrete total cost of the scan is minimized. Wang et al. (2015b)

proved that with block size of D = Ω(log2 N), Circuit ORAM can achieve

statistical

failure

probability

of

δ

for

block

by

setting

the

stash

size

to

O(log

1 δ

)

with

circuit

size

of

O(D(log

N

+

log

1 δ

)).

The

optimizations

in

Circuit

ORAM

reduce the eﬀective cost of ORAM (measured by the number of non-free gates

required in a circuit) by a factor of over 30 compared to the initial binary-tree

ORAM design for a representative 4GB data size with 32-bit blocks.

5.4 Square-Root RAM-MPC

Although the ﬁrst proposed ORAM designs were hierarchical, early RAMMPC designs did not adopt these constructions because their implementation seemed to require implementing a pseudo-random function (PRF) within the MPC, and using the outputs of that function to perform an oblivious sort. Both of these steps would be very expensive to do in a circuit-based secure computation circuit, so RAM-MPC designs favored ORAMs based on the binary-tree design which did not require sorting or a private PRF evaluation.
Zahur et al. (2016) observed that the classic square-root ORAM design of Goldreich and Ostrovsky (1996) could in fact be adapted to work eﬃciently in RAM-MPC by implementing an oblivious permutation where the PRF required for randomizing the permutation would be jointly computed by the two parties outside of the generic MPC. This led to a simple and eﬃcient ORAM design, which, unlike tree-based ORAMs, has zero statistical failure probability, since there is no risk that a block can overﬂow. The design maintains a public

5.4. Square-Root RAM-MPC

97

set, Used, of used physical locations (revealing no information since logical locations are assigned randomly to physical ones, and only accessed at most once), and an oblivious stash at each level that stores accessed blocks. Since the stash contains private data, it is stored in encrypted form as wire labels within the MPC. Unlike in the tree-based ORAM designs where the stash is used as a probabilistic mechanisms to deal with node overﬂows, in Square-Root ORAM the stash is used deterministically on each access. Each access adds one element to each of the level stashes, and all of the stashes must be linearly scanned on every access. If an accessed element is found in the stash, to preserve the obliviousness, the look-up continues with a randomly selected element. The size of each stash determines the number of accesses that can be done between reshuﬄings. Optimal results are obtained by setting the size to Θ( (N)), hence the name “square-root ORAM”. The oblivious shuﬄing is performed using a Waksman network (Waksman, 1968), which requires n log2 n − n + 1 oblivious swaps to permute n elements. Using the design from Huang et al. (2012a), this can be done with one ciphertext per oblivious swap.
One major advantage of the Square-Root ORAM design is its concrete performance, including initialization. All that is required to initialize is produce a random permutation and obliviously permute all the input data, generating the oblivious initial position map using the same method as the update protocol. Compared to earlier ORAM designs, where initialization was done with repeated writes, this approach dramatically reduces the cost of using the ORAM in practice. Without considering initialization, Square-Root ORAM has a per-access cost that is better than linear scan, once there are more than 32 blocks (for typical block sizes of 16 or 32 bytes), whereas Circuit ORAM is still more expensive than linear scanning up to 211 blocks. Although Square-Root ORAM has asymptotically worse behavior than Circuit ORAM, its concrete costs per access are better for ORAM sizes up to 216 blocks. For such large ORAMs, initialization costs become an important factor — initializing a Square-Root ORAM requires Θ(log N) network round trips, compared to Θ(N log N) for Circuit ORAM. Initializing a Circuit ORAM with N = 216 blocks would take several days, and its asymptotic beneﬁts would only be apparent for very expensive computations.

98

Oblivious Data Structures

5.5 Floram
Doerner and Shelat (2017) observed that even the sublinear-cost requirement, which was an essential design aspect of traditional ORAM systems, was not necessary to be useful in RAM-MPC. Since the cost of secure computation far exceeds the cost of standard computation, ORAM designs that have linear cost “outside of MPC”, but reduce the computation performed “inside MPC”, may be preferred to sublinear ORAM designs. With this insight, Doerner and Shelat (2017) revisited the Distributed Oblivious RAM approach of Lu and Ostrovsky (2013) and based a highly scalable and eﬃcient RAM-MPC scheme on two-server private information retrieval (PIR). The scheme, known as Floram (Function-secret-sharing Linear ORAM), can provide over 100× improvements over Square-Root ORAM and Circuit ORAM across a range of realistic parameters.
Distributed Oblivious RAM relaxes the usual security requirement of ORAM (the indistinguishability of server traces). Instead, the ORAM server is split into two non-colluding servers, and security requirement is that the memory access patterns are indistinguishable based on any single server trace (but allowed to be distinguishable if the traces of both servers are combined). We note that it is not immediately obvious how to use this primitive in constructing two-party MPC, since it requires two non-colluding servers in addition to the third player—the ORAM client.
Private information retrieval (PIR) enables a client to retrieve a selected item from a server, without revealing to the server which item was retrieved (Chor et al., 1995). Traditionally, PIR schemes are diﬀerent from ORAM in that they only provide read operations, and that they allow a linear server access cost whereas ORAM aims for amortized sublinear retrieval cost.
A point function is a function that outputs 0 for all inputs, except one:
Pα,β(x) = β if x = α 0, otherwise.
Gilboa and Ishai (2014) introduced the notion of distributed point functions (DPF), where a point function is secret-shared among two players with shares that have sizes sublinear in the domain of the function, hiding the values of both α and β. The output of each party’s evaluation of the secret-shared function is a share of the output and a bit indicating if the output is valid:

5.5. Floram

99

ypx = Ppα,β(x) (party p’s share output of the function), and tpx = (x = α) (a share of 1 if x = α, otherwise a share of 0). Gilboa and Ishai (2014) showed how this could be used to eﬃciently implement two-server private information retrieval, and Boyle et al. (2016b) improved the construction.
The Floram design uses secret-shared distributed point functions to implement a two-party oblivious write-only memory (OWOM) and both a two-party oblivious read-only memory (OROM). The ORAM is constructed by composing the OWOM and OROM, but since it is not possible to read from the write-only memory, Floram uses a linear-scan stash to store written elements until it is full, at which point the state of the ORAM is refreshed by converting the write-only memory into oblivious read-only memory, replacing the previous OROM and resetting the OWOM stash. In the OWOM, values are stored using XOR secret sharing. To write to an element, all elements are updated by xor-ing the current value with the output of a generated distributed point function—so, the semantic value of the update is 0 for all elements other than the one to be updated, and the diﬀerence between the current value and updated value for the selected element.

Reading. In the OROM, each stored value is masked by a PRF evaluated

at its index and the masked value is secret-shared between the two OROMs.

To

read

element

i

from

the

OROM,

each

party

obtains

k

i p

from

the

MPC

corresponding to its key for the secret-shared DPF. Then, it evaluates Pkpi (x)

on each element of its OROM and combines all the results with xor. For each

element other than x = i the output is its share of 0, so the resulting sum is

its share of the requested value, vpi . This value is input into the MPC, and

xor-ed

with

the

value

provided

by

the

other

party

to

obtain

Ri

=

vi
1

⊕

v2i .

To

obtain the actual value of element i, Ri is xor-ed with the output of PRFk(i),

computed within the MPC. The PRF masking is necessary to avoid leaking

any information when the OROM is refreshed. Each read requires generating a DPF (O(log N) secure computation and communication), O(N) local work for the DPF evaluation at each element, and constant-size (independent of N)

secure computation to compute the PRF for unmasking. In addition, each read

requires scanning the stash within the MPC using a linear scan in case the

requested element has been updated since the last refresh. Hence, the cost of

the scheme depends on how large a stash is needed to amortize the refresh cost.

